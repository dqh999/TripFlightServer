2025-01-07 20:56:22 - Starting airlineServerApplication using Java 23.0.1 with PID 12272 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-07 20:56:22 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-07 20:56:22 - No active profile set, falling back to 1 default profile: "default"
2025-01-07 20:56:23 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-07 20:56:23 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-07 20:56:23 - Finished Spring Data repository scanning in 89 ms. Found 10 JPA repository interfaces.
2025-01-07 20:56:23 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-07 20:56:23 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-07 20:56:23 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:56:23 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:56:23 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:56:23 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:56:23 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:56:23 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:56:23 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:56:23 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:56:23 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:56:23 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:56:23 - Finished Spring Data repository scanning in 20 ms. Found 0 Redis repository interfaces.
2025-01-07 20:56:24 - Tomcat initialized with port 8080 (http)
2025-01-07 20:56:24 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-07 20:56:24 - Starting service [Tomcat]
2025-01-07 20:56:24 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-07 20:56:24 - Initializing Spring embedded WebApplicationContext
2025-01-07 20:56:24 - Root WebApplicationContext: initialization completed in 1412 ms
2025-01-07 20:56:24 - HikariPool-1 - Starting...
2025-01-07 20:56:27 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@4348fa35
2025-01-07 20:56:27 - HikariPool-1 - Start completed.
2025-01-07 20:56:27 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-07 20:56:27 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-07 20:56:27 - HHH000026: Second-level cache disabled
2025-01-07 20:56:27 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-07 20:56:27 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-07 20:56:27 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-07 20:56:27 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-07 20:56:28 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-07 20:56:28 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-07 20:56:28 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-07 20:56:29 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-07 20:56:29 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-07 20:56:29 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-07 20:56:29 - Filter 'authenticationFilter' configured for use
2025-01-07 20:56:29 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-07 20:56:29 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-07 20:56:29 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-07 20:56:29 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-07 20:56:30 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-07 20:56:30 - Tomcat started on port 8080 (http) with context path '/'
2025-01-07 20:56:30 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-07 20:56:30 - initializing Kafka metrics collector
2025-01-07 20:56:30 - Kafka version: 3.9.0
2025-01-07 20:56:30 - Kafka commitId: 84caaa6e9da06435
2025-01-07 20:56:30 - Kafka startTimeMs: 1736258190479
2025-01-07 20:56:30 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-07 20:56:30 - Started airlineServerApplication in 8.284 seconds (process running for 8.759)
2025-01-07 20:56:30 - airlineServerApplication started
2025-01-07 20:56:31 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-07 20:56:31 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-07 20:56:31 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-07 20:56:32 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-1-535a7cbe-7330-4321-8710-8d9518548c22
2025-01-07 20:56:32 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-07 20:56:34 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully joined group with generation Generation{generationId=121, memberId='consumer-email-group-1-535a7cbe-7330-4321-8710-8d9518548c22', protocol='range'}
2025-01-07 20:56:34 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully synced group in generation Generation{generationId=121, memberId='consumer-email-group-1-535a7cbe-7330-4321-8710-8d9518548c22', protocol='range'}
2025-01-07 20:56:34 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Notifying assignor about the new Assignment(partitions=[email-topic-0])
2025-01-07 20:56:34 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Adding newly assigned partitions: email-topic-0
2025-01-07 20:56:35 - Setting offset for partition email-topic-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-07 20:56:35 - email-group: partitions assigned: [email-topic-0]
2025-01-07 20:56:45 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Revoke previously assigned partitions email-topic-0
2025-01-07 20:56:45 - email-group: partitions revoked: [email-topic-0]
2025-01-07 20:56:45 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Member consumer-email-group-1-535a7cbe-7330-4321-8710-8d9518548c22 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-07 20:56:45 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-07 20:56:45 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-07 20:56:45 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-07 20:56:45 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-07 20:56:45 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-07 20:57:06 - Starting airlineServerApplication using Java 23.0.1 with PID 3632 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-07 20:57:06 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-07 20:57:06 - No active profile set, falling back to 1 default profile: "default"
2025-01-07 20:57:07 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-07 20:57:07 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-07 20:57:07 - Finished Spring Data repository scanning in 92 ms. Found 10 JPA repository interfaces.
2025-01-07 20:57:07 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-07 20:57:07 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-07 20:57:07 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:57:07 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:57:07 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:57:07 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:57:07 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:57:07 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:57:07 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:57:07 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:57:07 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:57:07 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 20:57:07 - Finished Spring Data repository scanning in 22 ms. Found 0 Redis repository interfaces.
2025-01-07 20:57:07 - Tomcat initialized with port 8080 (http)
2025-01-07 20:57:07 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-07 20:57:07 - Starting service [Tomcat]
2025-01-07 20:57:07 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-07 20:57:07 - Initializing Spring embedded WebApplicationContext
2025-01-07 20:57:07 - Root WebApplicationContext: initialization completed in 1233 ms
2025-01-07 20:57:07 - HikariPool-1 - Starting...
2025-01-07 20:57:09 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@563843f1
2025-01-07 20:57:09 - HikariPool-1 - Start completed.
2025-01-07 20:57:09 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-07 20:57:09 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-07 20:57:09 - HHH000026: Second-level cache disabled
2025-01-07 20:57:10 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-07 20:57:10 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-07 20:57:10 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-07 20:57:10 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-07 20:57:11 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-07 20:57:11 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-07 20:57:11 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-07 20:57:11 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-07 20:57:11 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-07 20:57:11 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-07 20:57:12 - Filter 'authenticationFilter' configured for use
2025-01-07 20:57:12 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-07 20:57:12 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-07 20:57:12 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-07 20:57:12 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-07 20:57:13 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-07 20:57:13 - Tomcat started on port 8080 (http) with context path '/'
2025-01-07 20:57:13 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-07 20:57:13 - initializing Kafka metrics collector
2025-01-07 20:57:13 - Kafka version: 3.9.0
2025-01-07 20:57:13 - Kafka commitId: 84caaa6e9da06435
2025-01-07 20:57:13 - Kafka startTimeMs: 1736258233256
2025-01-07 20:57:13 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-07 20:57:13 - Started airlineServerApplication in 7.276 seconds (process running for 7.721)
2025-01-07 20:57:13 - airlineServerApplication started
2025-01-07 20:57:14 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-07 20:57:14 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-07 20:57:14 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-07 20:57:14 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-1-3d7fe61a-d438-45c8-93d3-453afe1e97a2
2025-01-07 20:57:14 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-07 20:57:16 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully joined group with generation Generation{generationId=123, memberId='consumer-email-group-1-3d7fe61a-d438-45c8-93d3-453afe1e97a2', protocol='range'}
2025-01-07 20:57:16 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully synced group in generation Generation{generationId=123, memberId='consumer-email-group-1-3d7fe61a-d438-45c8-93d3-453afe1e97a2', protocol='range'}
2025-01-07 20:57:16 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Notifying assignor about the new Assignment(partitions=[email-topic-0])
2025-01-07 20:57:16 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Adding newly assigned partitions: email-topic-0
2025-01-07 20:57:17 - Setting offset for partition email-topic-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-07 20:57:17 - email-group: partitions assigned: [email-topic-0]
2025-01-07 20:59:11 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-07 20:59:11 - Initializing Servlet 'dispatcherServlet'
2025-01-07 20:59:11 - Completed initialization in 2 ms
2025-01-07 20:59:11 - Securing POST /api/ticket
2025-01-07 20:59:11 - Secured POST /api/ticket
2025-01-07 20:59:12 - Start booking ticket with request: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@35ddb996
2025-01-07 20:59:14 - Ticket booking successful. Ticket ID: 7cea1b9da1d547a79f709a7f70bf5a15
2025-01-07 20:59:14 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-07 20:59:26 - Securing POST /api/ticket/7cea1b9da1d547a79f709a7f70bf5a15/confirm
2025-01-07 20:59:26 - Secured POST /api/ticket/7cea1b9da1d547a79f709a7f70bf5a15/confirm
2025-01-07 20:59:26 - Confirming ticket with ticketId=7cea1b9da1d547a79f709a7f70bf5a15
2025-01-07 20:59:26 - Ticket booked. Ticket: com.airline.domain.ticket.model.Ticket@66de9365
2025-01-07 20:59:32 - Ticket with ticketId=7cea1b9da1d547a79f709a7f70bf5a15 update available seats successfully for trainScheduleId=a9158e649e6445a8a56ec13184e47625.
2025-01-07 20:59:36 - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [dqhdev.io.vn:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = airlineServer-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-01-07 20:59:36 - initializing Kafka metrics collector
2025-01-07 20:59:36 - [Producer clientId=airlineServer-producer-1] Instantiated an idempotent producer.
2025-01-07 20:59:36 - Kafka version: 3.9.0
2025-01-07 20:59:36 - Kafka commitId: 84caaa6e9da06435
2025-01-07 20:59:36 - Kafka startTimeMs: 1736258376518
2025-01-07 20:59:37 - [Producer clientId=airlineServer-producer-1] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-07 20:59:37 - [Producer clientId=airlineServer-producer-1] ProducerId set to 5 with epoch 0
2025-01-07 20:59:37 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-07 20:59:37 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:661)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 20:59:37 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 6 for partition email-topic-0
2025-01-07 20:59:37 - Record in retry and not yet recovered
2025-01-07 20:59:38 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 20:59:38 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 6 for partition email-topic-0
2025-01-07 20:59:38 - Record in retry and not yet recovered
2025-01-07 20:59:39 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 20:59:39 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 6 for partition email-topic-0
2025-01-07 20:59:39 - Record in retry and not yet recovered
2025-01-07 20:59:40 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 20:59:40 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 6 for partition email-topic-0
2025-01-07 20:59:40 - Record in retry and not yet recovered
2025-01-07 20:59:41 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 20:59:41 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 6 for partition email-topic-0
2025-01-07 20:59:41 - Record in retry and not yet recovered
2025-01-07 20:59:41 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 20:59:41 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 6 for partition email-topic-0
2025-01-07 20:59:41 - Record in retry and not yet recovered
2025-01-07 20:59:42 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 20:59:42 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 6 for partition email-topic-0
2025-01-07 20:59:42 - Record in retry and not yet recovered
2025-01-07 20:59:43 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 20:59:43 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 6 for partition email-topic-0
2025-01-07 20:59:43 - Record in retry and not yet recovered
2025-01-07 20:59:44 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 20:59:44 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 6 for partition email-topic-0
2025-01-07 20:59:44 - Record in retry and not yet recovered
2025-01-07 20:59:44 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 20:59:44 - Backoff FixedBackOff{interval=0, currentAttempts=10, maxAttempts=9} exhausted for email-topic-0@6
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(com.airline.infrastructure.dataTransferObject.request.EmailRequest)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2982)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2889)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:489)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
Caused by: org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	... 10 common frames omitted
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 21:08:17 - Securing GET /
2025-01-07 21:08:17 - Secured GET /
2025-01-07 21:08:17 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-07 21:10:40 - Securing POST /api/ticket
2025-01-07 21:10:40 - Secured POST /api/ticket
2025-01-07 21:10:40 - Start booking ticket with request: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@2d5c0975
2025-01-07 21:10:41 - Ticket booking successful. Ticket ID: 1d9d8664665d4968bbe7c9f6d2cdd8a9
2025-01-07 21:10:42 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-07 21:10:46 - Securing POST /api/ticket/1d9d8664665d4968bbe7c9f6d2cdd8a9/confirm
2025-01-07 21:10:46 - Secured POST /api/ticket/1d9d8664665d4968bbe7c9f6d2cdd8a9/confirm
2025-01-07 21:10:46 - Confirming ticket with ticketId=1d9d8664665d4968bbe7c9f6d2cdd8a9
2025-01-07 21:10:46 - Ticket booked. Ticket: com.airline.domain.ticket.model.Ticket@19ba344d
2025-01-07 21:10:53 - Ticket with ticketId=1d9d8664665d4968bbe7c9f6d2cdd8a9 update available seats successfully for trainScheduleId=a9158e649e6445a8a56ec13184e47625.
2025-01-07 21:10:56 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-07 21:10:57 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:661)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 21:10:57 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 7 for partition email-topic-0
2025-01-07 21:10:57 - Record in retry and not yet recovered
2025-01-07 21:10:58 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 21:10:58 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 7 for partition email-topic-0
2025-01-07 21:10:58 - Record in retry and not yet recovered
2025-01-07 21:10:58 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 21:10:58 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 7 for partition email-topic-0
2025-01-07 21:10:58 - Record in retry and not yet recovered
2025-01-07 21:10:59 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 21:10:59 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 7 for partition email-topic-0
2025-01-07 21:10:59 - Record in retry and not yet recovered
2025-01-07 21:11:00 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 21:11:00 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 7 for partition email-topic-0
2025-01-07 21:11:00 - Record in retry and not yet recovered
2025-01-07 21:11:01 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 21:11:01 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 7 for partition email-topic-0
2025-01-07 21:11:01 - Record in retry and not yet recovered
2025-01-07 21:11:02 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 21:11:02 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 7 for partition email-topic-0
2025-01-07 21:11:02 - Record in retry and not yet recovered
2025-01-07 21:11:02 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 21:11:02 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 7 for partition email-topic-0
2025-01-07 21:11:02 - Record in retry and not yet recovered
2025-01-07 21:11:03 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 21:11:03 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 7 for partition email-topic-0
2025-01-07 21:11:03 - Record in retry and not yet recovered
2025-01-07 21:11:04 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 21:11:04 - Backoff FixedBackOff{interval=0, currentAttempts=10, maxAttempts=9} exhausted for email-topic-0@7
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(com.airline.infrastructure.dataTransferObject.request.EmailRequest)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2982)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2889)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:489)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
Caused by: org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: "childSeats + adultSeats + seniorSeats" (template: "confirm-ticket" - line 40, col 77)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:292)
	at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166)
	at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109)
	at org.thymeleaf.standard.expression.AdditionExpression.executeAddition(AdditionExpression.java:89)
	at org.thymeleaf.standard.expression.ComplexExpression.executeComplex(ComplexExpression.java:62)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:112)
	at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.infrastructure.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:18)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	... 10 common frames omitted
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1030E: The operator 'ADD' is not supported between objects of type 'null' and 'null'
	at org.springframework.expression.spel.ExpressionState.operate(ExpressionState.java:310)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:152)
	at org.springframework.expression.spel.ast.OpPlus.getValueInternal(OpPlus.java:93)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:116)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:338)
	at org.thymeleaf.spring6.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:265)
	... 41 common frames omitted
2025-01-07 21:11:37 - Securing GET /api/payment/VNPay_ipn?vnp_Amount=143212500&vnp_BankCode=NCB&vnp_BankTranNo=VNP14783876&vnp_CardType=ATM&vnp_OrderInfo=Payment+ticket+id+1d9d8664665d4968bbe7c9f6d2cdd8a9&vnp_PayDate=20250107211109&vnp_ResponseCode=00&vnp_TmnCode=FPBMPL8F&vnp_TransactionNo=14783876&vnp_TransactionStatus=00&vnp_TxnRef=1d9d8664665d4968bbe7c9f6d2cdd8a9&vnp_SecureHash=d75ec72979a6355ff20e34de2fd26ed7fad948b56f2bf8bd78475326164cacc5e341ead611f2a59a2db56b143c6da6e30469b07296d8de78c490bfb1bce9daf1
2025-01-07 21:11:37 - Secured GET /api/payment/VNPay_ipn?vnp_Amount=143212500&vnp_BankCode=NCB&vnp_BankTranNo=VNP14783876&vnp_CardType=ATM&vnp_OrderInfo=Payment+ticket+id+1d9d8664665d4968bbe7c9f6d2cdd8a9&vnp_PayDate=20250107211109&vnp_ResponseCode=00&vnp_TmnCode=FPBMPL8F&vnp_TransactionNo=14783876&vnp_TransactionStatus=00&vnp_TxnRef=1d9d8664665d4968bbe7c9f6d2cdd8a9&vnp_SecureHash=d75ec72979a6355ff20e34de2fd26ed7fad948b56f2bf8bd78475326164cacc5e341ead611f2a59a2db56b143c6da6e30469b07296d8de78c490bfb1bce9daf1
2025-01-07 21:11:37 - Received IPN request with params: {vnp_Amount=143212500, vnp_BankCode=NCB, vnp_BankTranNo=VNP14783876, vnp_CardType=ATM, vnp_OrderInfo=Payment ticket id 1d9d8664665d4968bbe7c9f6d2cdd8a9, vnp_PayDate=20250107211109, vnp_ResponseCode=00, vnp_TmnCode=FPBMPL8F, vnp_TransactionNo=14783876, vnp_TransactionStatus=00, vnp_TxnRef=1d9d8664665d4968bbe7c9f6d2cdd8a9, vnp_SecureHash=d75ec72979a6355ff20e34de2fd26ed7fad948b56f2bf8bd78475326164cacc5e341ead611f2a59a2db56b143c6da6e30469b07296d8de78c490bfb1bce9daf1}
2025-01-07 21:11:37 - IPN signature verification failed for params: {vnp_Amount=143212500, vnp_BankCode=NCB, vnp_BankTranNo=VNP14783876, vnp_CardType=ATM, vnp_OrderInfo=Payment ticket id 1d9d8664665d4968bbe7c9f6d2cdd8a9, vnp_PayDate=20250107211109, vnp_ResponseCode=00, vnp_TmnCode=FPBMPL8F, vnp_TransactionNo=14783876, vnp_TransactionStatus=00, vnp_TxnRef=1d9d8664665d4968bbe7c9f6d2cdd8a9}
2025-01-07 21:11:37 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-07 21:12:04 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Revoke previously assigned partitions email-topic-0
2025-01-07 21:12:04 - email-group: partitions revoked: [email-topic-0]
2025-01-07 21:12:04 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Member consumer-email-group-1-3d7fe61a-d438-45c8-93d3-453afe1e97a2 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-07 21:12:04 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-07 21:12:04 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-07 21:12:04 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-07 21:12:04 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-07 21:12:04 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-07 21:12:19 - Starting airlineServerApplication using Java 23.0.1 with PID 12404 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-07 21:12:19 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-07 21:12:19 - No active profile set, falling back to 1 default profile: "default"
2025-01-07 21:12:19 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-07 21:12:19 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-07 21:12:19 - Finished Spring Data repository scanning in 87 ms. Found 10 JPA repository interfaces.
2025-01-07 21:12:19 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-07 21:12:19 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-07 21:12:19 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 21:12:19 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 21:12:19 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 21:12:19 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 21:12:19 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 21:12:19 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 21:12:19 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 21:12:19 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 21:12:19 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 21:12:19 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 21:12:19 - Finished Spring Data repository scanning in 18 ms. Found 0 Redis repository interfaces.
2025-01-07 21:12:20 - Tomcat initialized with port 8080 (http)
2025-01-07 21:12:20 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-07 21:12:20 - Starting service [Tomcat]
2025-01-07 21:12:20 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-07 21:12:20 - Initializing Spring embedded WebApplicationContext
2025-01-07 21:12:20 - Root WebApplicationContext: initialization completed in 1250 ms
2025-01-07 21:12:20 - HikariPool-1 - Starting...
2025-01-07 21:12:22 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@563843f1
2025-01-07 21:12:22 - HikariPool-1 - Start completed.
2025-01-07 21:12:22 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-07 21:12:22 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-07 21:12:22 - HHH000026: Second-level cache disabled
2025-01-07 21:12:22 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-07 21:12:22 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-07 21:12:22 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-07 21:12:22 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-07 21:12:23 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-07 21:12:23 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-07 21:12:23 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-07 21:12:24 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-07 21:12:24 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-07 21:12:24 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-07 21:12:24 - Filter 'authenticationFilter' configured for use
2025-01-07 21:12:25 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-07 21:12:25 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-07 21:12:25 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-07 21:12:25 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-07 21:12:25 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-07 21:12:25 - Tomcat started on port 8080 (http) with context path '/'
2025-01-07 21:12:25 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-07 21:12:25 - initializing Kafka metrics collector
2025-01-07 21:12:25 - Kafka version: 3.9.0
2025-01-07 21:12:25 - Kafka commitId: 84caaa6e9da06435
2025-01-07 21:12:25 - Kafka startTimeMs: 1736259145675
2025-01-07 21:12:25 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-07 21:12:25 - Started airlineServerApplication in 6.993 seconds (process running for 7.353)
2025-01-07 21:12:25 - airlineServerApplication started
2025-01-07 21:12:26 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-07 21:12:26 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-07 21:12:26 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-07 21:12:27 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-1-c6846c3b-c583-4999-9289-9f47cabe29df
2025-01-07 21:12:27 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-07 21:12:28 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully joined group with generation Generation{generationId=125, memberId='consumer-email-group-1-c6846c3b-c583-4999-9289-9f47cabe29df', protocol='range'}
2025-01-07 21:12:28 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully synced group in generation Generation{generationId=125, memberId='consumer-email-group-1-c6846c3b-c583-4999-9289-9f47cabe29df', protocol='range'}
2025-01-07 21:12:28 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Notifying assignor about the new Assignment(partitions=[])
2025-01-07 21:12:28 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Adding newly assigned partitions: 
2025-01-07 21:12:28 - email-group: partitions assigned: []
2025-01-07 21:12:51 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-07 21:12:51 - Initializing Servlet 'dispatcherServlet'
2025-01-07 21:12:51 - Completed initialization in 1 ms
2025-01-07 21:12:51 - Securing POST /api/ticket
2025-01-07 21:12:51 - Secured POST /api/ticket
2025-01-07 21:12:51 - Start booking ticket with request: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@3f22a8f4
2025-01-07 21:12:53 - Ticket booking successful. Ticket ID: 4e4f032d1a00452482ee30e6d7487ce3
2025-01-07 21:12:54 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-07 21:13:04 - Securing POST /api/ticket/4e4f032d1a00452482ee30e6d7487ce3/confirm
2025-01-07 21:13:04 - Secured POST /api/ticket/4e4f032d1a00452482ee30e6d7487ce3/confirm
2025-01-07 21:13:04 - Confirming ticket with ticketId=4e4f032d1a00452482ee30e6d7487ce3
2025-01-07 21:13:05 - Ticket booked. Ticket: com.airline.domain.ticket.model.Ticket@5028caca
2025-01-07 21:13:12 - Ticket with ticketId=4e4f032d1a00452482ee30e6d7487ce3 update available seats successfully for trainScheduleId=a9158e649e6445a8a56ec13184e47625.
2025-01-07 21:13:16 - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [dqhdev.io.vn:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = airlineServer-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-01-07 21:13:16 - initializing Kafka metrics collector
2025-01-07 21:13:16 - [Producer clientId=airlineServer-producer-1] Instantiated an idempotent producer.
2025-01-07 21:13:16 - Kafka version: 3.9.0
2025-01-07 21:13:16 - Kafka commitId: 84caaa6e9da06435
2025-01-07 21:13:16 - Kafka startTimeMs: 1736259196373
2025-01-07 21:13:16 - [Producer clientId=airlineServer-producer-1] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-07 21:13:16 - [Producer clientId=airlineServer-producer-1] ProducerId set to 6 with epoch 0
2025-01-07 21:13:17 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-07 21:18:55 - Securing POST /api/ticket
2025-01-07 21:18:55 - Secured POST /api/ticket
2025-01-07 21:18:55 - Start booking ticket with request: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@7e774e43
2025-01-07 21:18:56 - Ticket booking successful. Ticket ID: 2031665292794886a080afb3d19b6a69
2025-01-07 21:18:57 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-07 21:19:02 - Securing POST /api/ticket/2031665292794886a080afb3d19b6a69/confirm
2025-01-07 21:19:02 - Secured POST /api/ticket/2031665292794886a080afb3d19b6a69/confirm
2025-01-07 21:19:02 - Confirming ticket with ticketId=2031665292794886a080afb3d19b6a69
2025-01-07 21:19:02 - Ticket booked. Ticket: com.airline.domain.ticket.model.Ticket@2961d341
2025-01-07 21:19:09 - Ticket with ticketId=2031665292794886a080afb3d19b6a69 update available seats successfully for trainScheduleId=a9158e649e6445a8a56ec13184e47625.
2025-01-07 21:19:13 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-07 21:20:04 - Securing GET /api/payment/VNPay_ipn?vnp_Amount=143212500&vnp_BankCode=VNPAY&vnp_CardType=QRCODE&vnp_OrderInfo=Payment+ticket+id+2031665292794886a080afb3d19b6a69&vnp_PayDate=20250107211933&vnp_ResponseCode=24&vnp_TmnCode=FPBMPL8F&vnp_TransactionNo=0&vnp_TransactionStatus=02&vnp_TxnRef=2031665292794886a080afb3d19b6a69&vnp_SecureHash=9d5ba6b276ef59f9693bf65229a7e661a452b0d49f8de71a1554cf138a6143772500a0cb16c33166ff71c8bc759c9bb5563cf0d6deec3033db1ba10a0956cd86
2025-01-07 21:20:04 - Secured GET /api/payment/VNPay_ipn?vnp_Amount=143212500&vnp_BankCode=VNPAY&vnp_CardType=QRCODE&vnp_OrderInfo=Payment+ticket+id+2031665292794886a080afb3d19b6a69&vnp_PayDate=20250107211933&vnp_ResponseCode=24&vnp_TmnCode=FPBMPL8F&vnp_TransactionNo=0&vnp_TransactionStatus=02&vnp_TxnRef=2031665292794886a080afb3d19b6a69&vnp_SecureHash=9d5ba6b276ef59f9693bf65229a7e661a452b0d49f8de71a1554cf138a6143772500a0cb16c33166ff71c8bc759c9bb5563cf0d6deec3033db1ba10a0956cd86
2025-01-07 21:20:04 - Received IPN request with params: {vnp_Amount=143212500, vnp_BankCode=VNPAY, vnp_CardType=QRCODE, vnp_OrderInfo=Payment ticket id 2031665292794886a080afb3d19b6a69, vnp_PayDate=20250107211933, vnp_ResponseCode=24, vnp_TmnCode=FPBMPL8F, vnp_TransactionNo=0, vnp_TransactionStatus=02, vnp_TxnRef=2031665292794886a080afb3d19b6a69, vnp_SecureHash=9d5ba6b276ef59f9693bf65229a7e661a452b0d49f8de71a1554cf138a6143772500a0cb16c33166ff71c8bc759c9bb5563cf0d6deec3033db1ba10a0956cd86}
2025-01-07 21:20:04 - IPN signature verification failed for params: {vnp_Amount=143212500, vnp_BankCode=VNPAY, vnp_CardType=QRCODE, vnp_OrderInfo=Payment ticket id 2031665292794886a080afb3d19b6a69, vnp_PayDate=20250107211933, vnp_ResponseCode=24, vnp_TmnCode=FPBMPL8F, vnp_TransactionNo=0, vnp_TransactionStatus=02, vnp_TxnRef=2031665292794886a080afb3d19b6a69}
2025-01-07 21:20:04 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-07 21:23:06 - Securing POST /api/ticket
2025-01-07 21:23:06 - Secured POST /api/ticket
2025-01-07 21:23:08 - Start booking ticket with request: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@7e53f177
2025-01-07 21:23:16 - Ticket booking successful. Ticket ID: 97029da3013e402da95caf723fbd318b
2025-01-07 21:23:18 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-07 21:23:25 - Securing POST /api/ticket/97029da3013e402da95caf723fbd318b/confirm
2025-01-07 21:23:25 - Secured POST /api/ticket/97029da3013e402da95caf723fbd318b/confirm
2025-01-07 21:23:25 - Confirming ticket with ticketId=97029da3013e402da95caf723fbd318b
2025-01-07 21:23:26 - Ticket booked. Ticket: com.airline.domain.ticket.model.Ticket@693060d4
2025-01-07 21:23:39 - Ticket with ticketId=97029da3013e402da95caf723fbd318b update available seats successfully for trainScheduleId=a9158e649e6445a8a56ec13184e47625.
2025-01-07 21:23:43 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-07 21:23:57 - Error while validating pooled Jedis object.
redis.clients.jedis.exceptions.JedisConnectionException: java.net.SocketTimeoutException: Read timed out
	at redis.clients.jedis.util.RedisInputStream.ensureFill(RedisInputStream.java:208)
	at redis.clients.jedis.util.RedisInputStream.readByte(RedisInputStream.java:46)
	at redis.clients.jedis.Protocol.process(Protocol.java:126)
	at redis.clients.jedis.Protocol.read(Protocol.java:192)
	at redis.clients.jedis.Connection.readProtocolWithCheckingBroken(Connection.java:335)
	at redis.clients.jedis.Connection.getStatusCodeReply(Connection.java:262)
	at redis.clients.jedis.Jedis.ping(Jedis.java:331)
	at redis.clients.jedis.JedisFactory.validateObject(JedisFactory.java:206)
	at org.apache.commons.pool2.impl.GenericObjectPool.evict(GenericObjectPool.java:748)
	at org.apache.commons.pool2.impl.BaseGenericObjectPool$Evictor.run(BaseGenericObjectPool.java:162)
	at org.apache.commons.pool2.impl.EvictionTimer$WeakRunner.run(EvictionTimer.java:115)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:278)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:304)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:346)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:796)
	at java.base/java.net.Socket$SocketInputStream.implRead(Socket.java:1116)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:1103)
	at java.base/java.io.InputStream.read(InputStream.java:220)
	at redis.clients.jedis.util.RedisInputStream.ensureFill(RedisInputStream.java:202)
	... 16 common frames omitted
2025-01-07 21:25:31 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Member consumer-email-group-1-c6846c3b-c583-4999-9289-9f47cabe29df sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-07 21:25:31 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-07 21:25:31 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-07 21:25:31 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-07 21:25:31 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-07 21:25:31 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-07 21:58:10 - Starting airlineServerApplication using Java 23.0.1 with PID 9492 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-07 21:58:10 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-07 21:58:10 - No active profile set, falling back to 1 default profile: "default"
2025-01-07 21:58:11 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanDefinitionStoreException: Failed to parse configuration class [com.airline.AirLineServerApplication]
2025-01-07 21:58:11 - Application run failed
org.springframework.beans.factory.BeanDefinitionStoreException: Failed to parse configuration class [com.airline.AirLineServerApplication]
	at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:185)
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:418)
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:290)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:349)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:118)
	at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:791)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:609)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.airline.AirLineServerApplication.main(airlineServerApplication.java:11)
Caused by: org.springframework.context.annotation.ConflictingBeanDefinitionException: Annotation-specified bean name 'paymentService' for bean class [com.airline.domain.payment.service.impl.PaymentService] conflicts with existing, non-compatible bean definition of same name and class [com.airline.application.payment.service.PaymentService]
	at org.springframework.context.annotation.ClassPathBeanDefinitionScanner.checkCandidate(ClassPathBeanDefinitionScanner.java:361)
	at org.springframework.context.annotation.ClassPathBeanDefinitionScanner.doScan(ClassPathBeanDefinitionScanner.java:288)
	at org.springframework.context.annotation.ComponentScanAnnotationParser.parse(ComponentScanAnnotationParser.java:128)
	at org.springframework.context.annotation.ConfigurationClassParser.doProcessConfigurationClass(ConfigurationClassParser.java:332)
	at org.springframework.context.annotation.ConfigurationClassParser.processConfigurationClass(ConfigurationClassParser.java:267)
	at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:193)
	at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:171)
	... 13 common frames omitted
2025-01-07 22:01:45 - Starting airlineServerApplication using Java 23.0.1 with PID 1756 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-07 22:01:45 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-07 22:01:45 - No active profile set, falling back to 1 default profile: "default"
2025-01-07 22:01:45 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-07 22:01:45 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-07 22:01:45 - Finished Spring Data repository scanning in 67 ms. Found 10 JPA repository interfaces.
2025-01-07 22:01:45 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-07 22:01:45 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-07 22:01:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:01:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:01:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:01:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:01:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:01:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:01:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:01:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:01:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:01:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:01:45 - Finished Spring Data repository scanning in 19 ms. Found 0 Redis repository interfaces.
2025-01-07 22:01:46 - Tomcat initialized with port 8080 (http)
2025-01-07 22:01:46 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-07 22:01:46 - Starting service [Tomcat]
2025-01-07 22:01:46 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-07 22:01:46 - Initializing Spring embedded WebApplicationContext
2025-01-07 22:01:46 - Root WebApplicationContext: initialization completed in 1121 ms
2025-01-07 22:01:46 - HikariPool-1 - Starting...
2025-01-07 22:18:03 - Starting airlineServerApplication using Java 23.0.1 with PID 22444 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-07 22:18:03 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-07 22:18:03 - No active profile set, falling back to 1 default profile: "default"
2025-01-07 22:18:03 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-07 22:18:03 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-07 22:18:04 - Finished Spring Data repository scanning in 79 ms. Found 10 JPA repository interfaces.
2025-01-07 22:18:04 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-07 22:18:04 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-07 22:18:04 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:18:04 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:18:04 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:18:04 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:18:04 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:18:04 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:18:04 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:18:04 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:18:04 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:18:04 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:18:04 - Finished Spring Data repository scanning in 17 ms. Found 0 Redis repository interfaces.
2025-01-07 22:18:04 - Tomcat initialized with port 8080 (http)
2025-01-07 22:18:04 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-07 22:18:04 - Starting service [Tomcat]
2025-01-07 22:18:04 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-07 22:18:04 - Initializing Spring embedded WebApplicationContext
2025-01-07 22:18:04 - Root WebApplicationContext: initialization completed in 1193 ms
2025-01-07 22:18:04 - HikariPool-1 - Starting...
2025-01-07 22:18:06 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@23df7fad
2025-01-07 22:18:06 - HikariPool-1 - Start completed.
2025-01-07 22:18:06 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-07 22:18:06 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-07 22:18:06 - HHH000026: Second-level cache disabled
2025-01-07 22:18:06 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-07 22:18:06 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-07 22:18:06 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-07 22:18:06 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-07 22:18:07 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-07 22:18:07 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-07 22:18:07 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-07 22:18:07 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-07 22:18:07 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-07 22:18:07 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-07 22:18:08 - Filter 'authenticationFilter' configured for use
2025-01-07 22:18:08 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-07 22:18:08 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-07 22:18:08 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-07 22:18:08 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-07 22:18:09 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [JedisPool [maxTotal=10, blockWhenExhausted=true, maxWaitDuration=PT-0.001S, lifo=true, fairness=false, testOnCreate=false, testOnBorrow=false, testOnReturn=false, testWhileIdle=true, durationBetweenEvictionRuns=PT30S, numTestsPerEvictionRun=-1, minEvictableIdleTimeDuration=PT1M, softMinEvictableIdleTimeDuration=PT-0.001S, evictionPolicy=org.apache.commons.pool2.impl.DefaultEvictionPolicy@2de29667, closeLock=java.lang.Object@47cdfd0d, closed=false, evictionLock=java.lang.Object@3695deb0, evictor=org.apache.commons.pool2.impl.BaseGenericObjectPool$Evictor [scheduledFuture=java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@32e9ebbf[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@230ca3c3[Wrapped task = org.apache.commons.pool2.impl.EvictionTimer$WeakRunner@1a64586b]]], evictionIterator=null, factoryClassLoader=java.lang.ref.WeakReference@2a91c30c, oname=org.apache.commons.pool2:type=GenericObjectPool,name=pool2, creationStackTrace=java.lang.Exception
	at org.apache.commons.pool2.impl.BaseGenericObjectPool.<init>(BaseGenericObjectPool.java:420)
	at org.apache.commons.pool2.impl.GenericObjectPool.<init>(GenericObjectPool.java:150)
	at redis.clients.jedis.util.Pool.<init>(Pool.java:16)
	at redis.clients.jedis.util.Pool.<init>(Pool.java:12)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:373)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:233)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:201)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:173)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:145)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:127)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:105)
	at com.airline.infrastructure.config.RedisConfig.jedisPool(RedisConfig.java:42)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$0.CGLIB$jedisPool$0(<generated>)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$FastClass$$1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:258)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:348)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$0.jedisPool(<generated>)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.lambda$instantiate$0(SimpleInstantiationStrategy.java:171)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiateWithFactoryMethod(SimpleInstantiationStrategy.java:88)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:168)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:489)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1351)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1568)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1514)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:913)
	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:240)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1371)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1208)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.instantiateSingleton(DefaultListableBeanFactory.java:1122)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingleton(DefaultListableBeanFactory.java:1093)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:1030)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:987)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.airline.AirLineServerApplication.main(airlineServerApplication.java:11)
, borrowedCount=0, returnedCount=0, createdCount=0, destroyedCount=0, destroyedByEvictorCount=0, destroyedByBorrowValidationCount=0, activeTimes=StatsStore [[]], size=100, index=0], idleTimes=StatsStore [[]], size=100, index=0], waitTimes=StatsStore [[]], size=100, index=0], maxBorrowWaitDuration=PT0S, swallowedExceptionListener=null, factoryType=null, maxIdle=5, minIdle=0, factory=redis.clients.jedis.JedisFactory@6cc57f26, allObjects={}, createCount=0, idleObjects=[], abandonedConfig=null]] with key 'jedisPool'
2025-01-07 22:18:09 - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-01-07 22:18:09 - HikariPool-1 - Shutdown initiated...
2025-01-07 22:18:10 - HikariPool-1 - Shutdown completed.
2025-01-07 22:18:10 - Stopping service [Tomcat]
2025-01-07 22:18:10 - 

Error starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled.
2025-01-07 22:18:10 - Application run failed
org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [JedisPool [maxTotal=10, blockWhenExhausted=true, maxWaitDuration=PT-0.001S, lifo=true, fairness=false, testOnCreate=false, testOnBorrow=false, testOnReturn=false, testWhileIdle=true, durationBetweenEvictionRuns=PT30S, numTestsPerEvictionRun=-1, minEvictableIdleTimeDuration=PT1M, softMinEvictableIdleTimeDuration=PT-0.001S, evictionPolicy=org.apache.commons.pool2.impl.DefaultEvictionPolicy@2de29667, closeLock=java.lang.Object@47cdfd0d, closed=false, evictionLock=java.lang.Object@3695deb0, evictor=org.apache.commons.pool2.impl.BaseGenericObjectPool$Evictor [scheduledFuture=java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@32e9ebbf[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@230ca3c3[Wrapped task = org.apache.commons.pool2.impl.EvictionTimer$WeakRunner@1a64586b]]], evictionIterator=null, factoryClassLoader=java.lang.ref.WeakReference@2a91c30c, oname=org.apache.commons.pool2:type=GenericObjectPool,name=pool2, creationStackTrace=java.lang.Exception
	at org.apache.commons.pool2.impl.BaseGenericObjectPool.<init>(BaseGenericObjectPool.java:420)
	at org.apache.commons.pool2.impl.GenericObjectPool.<init>(GenericObjectPool.java:150)
	at redis.clients.jedis.util.Pool.<init>(Pool.java:16)
	at redis.clients.jedis.util.Pool.<init>(Pool.java:12)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:373)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:233)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:201)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:173)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:145)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:127)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:105)
	at com.airline.infrastructure.config.RedisConfig.jedisPool(RedisConfig.java:42)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$0.CGLIB$jedisPool$0(<generated>)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$FastClass$$1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:258)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:348)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$0.jedisPool(<generated>)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.lambda$instantiate$0(SimpleInstantiationStrategy.java:171)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiateWithFactoryMethod(SimpleInstantiationStrategy.java:88)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:168)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:489)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1351)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1568)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1514)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:913)
	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:240)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1371)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1208)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.instantiateSingleton(DefaultListableBeanFactory.java:1122)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingleton(DefaultListableBeanFactory.java:1093)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:1030)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:987)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.airline.AirLineServerApplication.main(airlineServerApplication.java:11)
, borrowedCount=0, returnedCount=0, createdCount=0, destroyedCount=0, destroyedByEvictorCount=0, destroyedByBorrowValidationCount=0, activeTimes=StatsStore [[]], size=100, index=0], idleTimes=StatsStore [[]], size=100, index=0], waitTimes=StatsStore [[]], size=100, index=0], maxBorrowWaitDuration=PT0S, swallowedExceptionListener=null, factoryType=null, maxIdle=5, minIdle=0, factory=redis.clients.jedis.JedisFactory@6cc57f26, allObjects={}, createCount=0, idleObjects=[], abandonedConfig=null]] with key 'jedisPool'
	at org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:640)
	at org.springframework.jmx.export.MBeanExporter.lambda$registerBeans$2(MBeanExporter.java:567)
	at java.base/java.util.HashMap.forEach(HashMap.java:1430)
	at org.springframework.jmx.export.MBeanExporter.registerBeans(MBeanExporter.java:567)
	at org.springframework.jmx.export.MBeanExporter.afterSingletonsInstantiated(MBeanExporter.java:450)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:1057)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:987)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.airline.AirLineServerApplication.main(airlineServerApplication.java:11)
Caused by: javax.management.InstanceAlreadyExistsException: MXBean already registered with name org.apache.commons.pool2:type=GenericObjectPool,name=pool2
	at java.management/com.sun.jmx.mbeanserver.MXBeanLookup.addReference(MXBeanLookup.java:152)
	at java.management/com.sun.jmx.mbeanserver.MXBeanSupport.register(MXBeanSupport.java:160)
	at java.management/com.sun.jmx.mbeanserver.MBeanSupport.preRegister2(MBeanSupport.java:173)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:909)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:880)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:315)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.springframework.jmx.support.MBeanRegistrationSupport.doRegister(MBeanRegistrationSupport.java:138)
	at org.springframework.jmx.export.MBeanExporter.registerBeanInstance(MBeanExporter.java:686)
	at org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:630)
	... 14 common frames omitted
2025-01-07 22:19:27 - Starting airlineServerApplication using Java 23.0.1 with PID 23304 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-07 22:19:27 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-07 22:19:27 - No active profile set, falling back to 1 default profile: "default"
2025-01-07 22:19:27 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-07 22:19:27 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-07 22:19:27 - Finished Spring Data repository scanning in 75 ms. Found 10 JPA repository interfaces.
2025-01-07 22:19:27 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-07 22:19:27 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-07 22:19:27 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:19:27 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:19:27 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:19:27 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:19:27 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:19:27 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:19:27 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:19:27 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:19:27 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:19:27 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:19:27 - Finished Spring Data repository scanning in 17 ms. Found 0 Redis repository interfaces.
2025-01-07 22:19:28 - Tomcat initialized with port 8080 (http)
2025-01-07 22:19:28 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-07 22:19:28 - Starting service [Tomcat]
2025-01-07 22:19:28 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-07 22:19:28 - Initializing Spring embedded WebApplicationContext
2025-01-07 22:19:28 - Root WebApplicationContext: initialization completed in 1118 ms
2025-01-07 22:19:28 - HikariPool-1 - Starting...
2025-01-07 22:19:29 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@391d28ea
2025-01-07 22:19:29 - HikariPool-1 - Start completed.
2025-01-07 22:19:29 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-07 22:19:30 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-07 22:19:30 - HHH000026: Second-level cache disabled
2025-01-07 22:19:30 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-07 22:19:30 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-07 22:19:30 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-07 22:19:30 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-07 22:19:31 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-07 22:19:31 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-07 22:19:31 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-07 22:19:31 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-07 22:19:31 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-07 22:19:31 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-07 22:19:31 - Filter 'authenticationFilter' configured for use
2025-01-07 22:19:32 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-07 22:19:32 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-07 22:19:32 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-07 22:19:32 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-07 22:19:32 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [JedisPool [maxTotal=10, blockWhenExhausted=true, maxWaitDuration=PT-0.001S, lifo=true, fairness=false, testOnCreate=false, testOnBorrow=false, testOnReturn=false, testWhileIdle=true, durationBetweenEvictionRuns=PT30S, numTestsPerEvictionRun=-1, minEvictableIdleTimeDuration=PT1M, softMinEvictableIdleTimeDuration=PT-0.001S, evictionPolicy=org.apache.commons.pool2.impl.DefaultEvictionPolicy@11f5ab76, closeLock=java.lang.Object@62b899bf, closed=false, evictionLock=java.lang.Object@68aa14fa, evictor=org.apache.commons.pool2.impl.BaseGenericObjectPool$Evictor [scheduledFuture=java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@28faece4[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@323b4ac5[Wrapped task = org.apache.commons.pool2.impl.EvictionTimer$WeakRunner@ea9f9ef]]], evictionIterator=null, factoryClassLoader=java.lang.ref.WeakReference@104f20c5, oname=org.apache.commons.pool2:type=GenericObjectPool,name=pool2, creationStackTrace=java.lang.Exception
	at org.apache.commons.pool2.impl.BaseGenericObjectPool.<init>(BaseGenericObjectPool.java:420)
	at org.apache.commons.pool2.impl.GenericObjectPool.<init>(GenericObjectPool.java:150)
	at redis.clients.jedis.util.Pool.<init>(Pool.java:16)
	at redis.clients.jedis.util.Pool.<init>(Pool.java:12)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:373)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:233)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:201)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:173)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:145)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:127)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:105)
	at com.airline.infrastructure.config.RedisConfig.jedisPool(RedisConfig.java:42)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$0.CGLIB$jedisPool$1(<generated>)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$FastClass$$1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:258)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:348)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$0.jedisPool(<generated>)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.lambda$instantiate$0(SimpleInstantiationStrategy.java:171)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiateWithFactoryMethod(SimpleInstantiationStrategy.java:88)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:168)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:489)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1351)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1568)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1514)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:913)
	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:240)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1371)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1208)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.instantiateSingleton(DefaultListableBeanFactory.java:1122)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingleton(DefaultListableBeanFactory.java:1093)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:1030)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:987)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.airline.AirLineServerApplication.main(airlineServerApplication.java:11)
, borrowedCount=0, returnedCount=0, createdCount=0, destroyedCount=0, destroyedByEvictorCount=0, destroyedByBorrowValidationCount=0, activeTimes=StatsStore [[]], size=100, index=0], idleTimes=StatsStore [[]], size=100, index=0], waitTimes=StatsStore [[]], size=100, index=0], maxBorrowWaitDuration=PT0S, swallowedExceptionListener=null, factoryType=null, maxIdle=5, minIdle=0, factory=redis.clients.jedis.JedisFactory@78ca3d6b, allObjects={}, createCount=0, idleObjects=[], abandonedConfig=null]] with key 'jedisPool'
2025-01-07 22:19:32 - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-01-07 22:19:32 - HikariPool-1 - Shutdown initiated...
2025-01-07 22:19:33 - HikariPool-1 - Shutdown completed.
2025-01-07 22:19:33 - Stopping service [Tomcat]
2025-01-07 22:19:33 - 

Error starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled.
2025-01-07 22:19:33 - Application run failed
org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [JedisPool [maxTotal=10, blockWhenExhausted=true, maxWaitDuration=PT-0.001S, lifo=true, fairness=false, testOnCreate=false, testOnBorrow=false, testOnReturn=false, testWhileIdle=true, durationBetweenEvictionRuns=PT30S, numTestsPerEvictionRun=-1, minEvictableIdleTimeDuration=PT1M, softMinEvictableIdleTimeDuration=PT-0.001S, evictionPolicy=org.apache.commons.pool2.impl.DefaultEvictionPolicy@11f5ab76, closeLock=java.lang.Object@62b899bf, closed=false, evictionLock=java.lang.Object@68aa14fa, evictor=org.apache.commons.pool2.impl.BaseGenericObjectPool$Evictor [scheduledFuture=java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@28faece4[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@323b4ac5[Wrapped task = org.apache.commons.pool2.impl.EvictionTimer$WeakRunner@ea9f9ef]]], evictionIterator=null, factoryClassLoader=java.lang.ref.WeakReference@104f20c5, oname=org.apache.commons.pool2:type=GenericObjectPool,name=pool2, creationStackTrace=java.lang.Exception
	at org.apache.commons.pool2.impl.BaseGenericObjectPool.<init>(BaseGenericObjectPool.java:420)
	at org.apache.commons.pool2.impl.GenericObjectPool.<init>(GenericObjectPool.java:150)
	at redis.clients.jedis.util.Pool.<init>(Pool.java:16)
	at redis.clients.jedis.util.Pool.<init>(Pool.java:12)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:373)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:233)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:201)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:173)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:145)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:127)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:105)
	at com.airline.infrastructure.config.RedisConfig.jedisPool(RedisConfig.java:42)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$0.CGLIB$jedisPool$1(<generated>)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$FastClass$$1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:258)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:348)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$0.jedisPool(<generated>)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.lambda$instantiate$0(SimpleInstantiationStrategy.java:171)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiateWithFactoryMethod(SimpleInstantiationStrategy.java:88)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:168)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:489)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1351)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1568)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1514)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:913)
	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:240)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1371)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1208)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.instantiateSingleton(DefaultListableBeanFactory.java:1122)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingleton(DefaultListableBeanFactory.java:1093)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:1030)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:987)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.airline.AirLineServerApplication.main(airlineServerApplication.java:11)
, borrowedCount=0, returnedCount=0, createdCount=0, destroyedCount=0, destroyedByEvictorCount=0, destroyedByBorrowValidationCount=0, activeTimes=StatsStore [[]], size=100, index=0], idleTimes=StatsStore [[]], size=100, index=0], waitTimes=StatsStore [[]], size=100, index=0], maxBorrowWaitDuration=PT0S, swallowedExceptionListener=null, factoryType=null, maxIdle=5, minIdle=0, factory=redis.clients.jedis.JedisFactory@78ca3d6b, allObjects={}, createCount=0, idleObjects=[], abandonedConfig=null]] with key 'jedisPool'
	at org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:640)
	at org.springframework.jmx.export.MBeanExporter.lambda$registerBeans$2(MBeanExporter.java:567)
	at java.base/java.util.HashMap.forEach(HashMap.java:1430)
	at org.springframework.jmx.export.MBeanExporter.registerBeans(MBeanExporter.java:567)
	at org.springframework.jmx.export.MBeanExporter.afterSingletonsInstantiated(MBeanExporter.java:450)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:1057)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:987)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.airline.AirLineServerApplication.main(airlineServerApplication.java:11)
Caused by: javax.management.InstanceAlreadyExistsException: MXBean already registered with name org.apache.commons.pool2:type=GenericObjectPool,name=pool2
	at java.management/com.sun.jmx.mbeanserver.MXBeanLookup.addReference(MXBeanLookup.java:152)
	at java.management/com.sun.jmx.mbeanserver.MXBeanSupport.register(MXBeanSupport.java:160)
	at java.management/com.sun.jmx.mbeanserver.MBeanSupport.preRegister2(MBeanSupport.java:173)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:909)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:880)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:315)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.springframework.jmx.support.MBeanRegistrationSupport.doRegister(MBeanRegistrationSupport.java:138)
	at org.springframework.jmx.export.MBeanExporter.registerBeanInstance(MBeanExporter.java:686)
	at org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:630)
	... 14 common frames omitted
2025-01-07 22:20:48 - Starting airlineServerApplication using Java 23.0.1 with PID 24648 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-07 22:20:48 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-07 22:20:48 - No active profile set, falling back to 1 default profile: "default"
2025-01-07 22:20:49 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-07 22:20:49 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-07 22:20:49 - Finished Spring Data repository scanning in 89 ms. Found 10 JPA repository interfaces.
2025-01-07 22:20:49 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-07 22:20:49 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-07 22:20:49 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:20:49 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:20:49 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:20:49 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:20:49 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:20:49 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:20:49 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:20:49 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:20:49 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:20:49 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:20:49 - Finished Spring Data repository scanning in 19 ms. Found 0 Redis repository interfaces.
2025-01-07 22:20:49 - Tomcat initialized with port 8080 (http)
2025-01-07 22:20:49 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-07 22:20:49 - Starting service [Tomcat]
2025-01-07 22:20:49 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-07 22:20:50 - Initializing Spring embedded WebApplicationContext
2025-01-07 22:20:50 - Root WebApplicationContext: initialization completed in 1241 ms
2025-01-07 22:20:50 - HikariPool-1 - Starting...
2025-01-07 22:20:51 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@f49e81a
2025-01-07 22:20:51 - HikariPool-1 - Start completed.
2025-01-07 22:20:51 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-07 22:20:51 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-07 22:20:51 - HHH000026: Second-level cache disabled
2025-01-07 22:20:52 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-07 22:20:52 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-07 22:20:52 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-07 22:20:52 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-07 22:20:53 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-07 22:20:53 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-07 22:20:53 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-07 22:20:53 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-07 22:20:53 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-07 22:20:53 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-07 22:20:53 - Filter 'authenticationFilter' configured for use
2025-01-07 22:20:54 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-07 22:20:54 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-07 22:20:54 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-07 22:20:54 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-07 22:20:54 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [JedisPool [maxTotal=10, blockWhenExhausted=true, maxWaitDuration=PT-0.001S, lifo=true, fairness=false, testOnCreate=false, testOnBorrow=false, testOnReturn=false, testWhileIdle=true, durationBetweenEvictionRuns=PT30S, numTestsPerEvictionRun=-1, minEvictableIdleTimeDuration=PT1M, softMinEvictableIdleTimeDuration=PT-0.001S, evictionPolicy=org.apache.commons.pool2.impl.DefaultEvictionPolicy@1d90f169, closeLock=java.lang.Object@5c72d1b5, closed=false, evictionLock=java.lang.Object@90d0815, evictor=org.apache.commons.pool2.impl.BaseGenericObjectPool$Evictor [scheduledFuture=java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@7776dee7[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@27c2e9ab[Wrapped task = org.apache.commons.pool2.impl.EvictionTimer$WeakRunner@3d435f83]]], evictionIterator=null, factoryClassLoader=java.lang.ref.WeakReference@165a2dbc, oname=org.apache.commons.pool2:type=GenericObjectPool,name=pool2, creationStackTrace=java.lang.Exception
	at org.apache.commons.pool2.impl.BaseGenericObjectPool.<init>(BaseGenericObjectPool.java:420)
	at org.apache.commons.pool2.impl.GenericObjectPool.<init>(GenericObjectPool.java:150)
	at redis.clients.jedis.util.Pool.<init>(Pool.java:16)
	at redis.clients.jedis.util.Pool.<init>(Pool.java:12)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:373)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:233)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:201)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:173)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:145)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:127)
	at com.airline.infrastructure.config.RedisConfig.jedisPool(RedisConfig.java:42)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$0.CGLIB$jedisPool$1(<generated>)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$FastClass$$1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:258)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:348)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$0.jedisPool(<generated>)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.lambda$instantiate$0(SimpleInstantiationStrategy.java:171)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiateWithFactoryMethod(SimpleInstantiationStrategy.java:88)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:168)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:489)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1351)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1568)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1514)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:913)
	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:240)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1371)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1208)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.instantiateSingleton(DefaultListableBeanFactory.java:1122)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingleton(DefaultListableBeanFactory.java:1093)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:1030)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:987)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.airline.AirLineServerApplication.main(airlineServerApplication.java:11)
, borrowedCount=0, returnedCount=0, createdCount=0, destroyedCount=0, destroyedByEvictorCount=0, destroyedByBorrowValidationCount=0, activeTimes=StatsStore [[]], size=100, index=0], idleTimes=StatsStore [[]], size=100, index=0], waitTimes=StatsStore [[]], size=100, index=0], maxBorrowWaitDuration=PT0S, swallowedExceptionListener=null, factoryType=null, maxIdle=5, minIdle=0, factory=redis.clients.jedis.JedisFactory@2665016d, allObjects={}, createCount=0, idleObjects=[], abandonedConfig=null]] with key 'jedisPool'
2025-01-07 22:20:54 - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-01-07 22:20:54 - HikariPool-1 - Shutdown initiated...
2025-01-07 22:20:55 - HikariPool-1 - Shutdown completed.
2025-01-07 22:20:55 - Stopping service [Tomcat]
2025-01-07 22:20:55 - 

Error starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled.
2025-01-07 22:20:55 - Application run failed
org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [JedisPool [maxTotal=10, blockWhenExhausted=true, maxWaitDuration=PT-0.001S, lifo=true, fairness=false, testOnCreate=false, testOnBorrow=false, testOnReturn=false, testWhileIdle=true, durationBetweenEvictionRuns=PT30S, numTestsPerEvictionRun=-1, minEvictableIdleTimeDuration=PT1M, softMinEvictableIdleTimeDuration=PT-0.001S, evictionPolicy=org.apache.commons.pool2.impl.DefaultEvictionPolicy@1d90f169, closeLock=java.lang.Object@5c72d1b5, closed=false, evictionLock=java.lang.Object@90d0815, evictor=org.apache.commons.pool2.impl.BaseGenericObjectPool$Evictor [scheduledFuture=java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@7776dee7[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@27c2e9ab[Wrapped task = org.apache.commons.pool2.impl.EvictionTimer$WeakRunner@3d435f83]]], evictionIterator=null, factoryClassLoader=java.lang.ref.WeakReference@165a2dbc, oname=org.apache.commons.pool2:type=GenericObjectPool,name=pool2, creationStackTrace=java.lang.Exception
	at org.apache.commons.pool2.impl.BaseGenericObjectPool.<init>(BaseGenericObjectPool.java:420)
	at org.apache.commons.pool2.impl.GenericObjectPool.<init>(GenericObjectPool.java:150)
	at redis.clients.jedis.util.Pool.<init>(Pool.java:16)
	at redis.clients.jedis.util.Pool.<init>(Pool.java:12)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:373)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:233)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:201)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:173)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:145)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:127)
	at com.airline.infrastructure.config.RedisConfig.jedisPool(RedisConfig.java:42)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$0.CGLIB$jedisPool$1(<generated>)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$FastClass$$1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:258)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:348)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$0.jedisPool(<generated>)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.lambda$instantiate$0(SimpleInstantiationStrategy.java:171)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiateWithFactoryMethod(SimpleInstantiationStrategy.java:88)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:168)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:489)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1351)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1568)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1514)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:913)
	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:240)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1371)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1208)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.instantiateSingleton(DefaultListableBeanFactory.java:1122)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingleton(DefaultListableBeanFactory.java:1093)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:1030)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:987)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.airline.AirLineServerApplication.main(airlineServerApplication.java:11)
, borrowedCount=0, returnedCount=0, createdCount=0, destroyedCount=0, destroyedByEvictorCount=0, destroyedByBorrowValidationCount=0, activeTimes=StatsStore [[]], size=100, index=0], idleTimes=StatsStore [[]], size=100, index=0], waitTimes=StatsStore [[]], size=100, index=0], maxBorrowWaitDuration=PT0S, swallowedExceptionListener=null, factoryType=null, maxIdle=5, minIdle=0, factory=redis.clients.jedis.JedisFactory@2665016d, allObjects={}, createCount=0, idleObjects=[], abandonedConfig=null]] with key 'jedisPool'
	at org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:640)
	at org.springframework.jmx.export.MBeanExporter.lambda$registerBeans$2(MBeanExporter.java:567)
	at java.base/java.util.HashMap.forEach(HashMap.java:1430)
	at org.springframework.jmx.export.MBeanExporter.registerBeans(MBeanExporter.java:567)
	at org.springframework.jmx.export.MBeanExporter.afterSingletonsInstantiated(MBeanExporter.java:450)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:1057)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:987)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.airline.AirLineServerApplication.main(airlineServerApplication.java:11)
Caused by: javax.management.InstanceAlreadyExistsException: MXBean already registered with name org.apache.commons.pool2:type=GenericObjectPool,name=pool2
	at java.management/com.sun.jmx.mbeanserver.MXBeanLookup.addReference(MXBeanLookup.java:152)
	at java.management/com.sun.jmx.mbeanserver.MXBeanSupport.register(MXBeanSupport.java:160)
	at java.management/com.sun.jmx.mbeanserver.MBeanSupport.preRegister2(MBeanSupport.java:173)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:909)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:880)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:315)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.springframework.jmx.support.MBeanRegistrationSupport.doRegister(MBeanRegistrationSupport.java:138)
	at org.springframework.jmx.export.MBeanExporter.registerBeanInstance(MBeanExporter.java:686)
	at org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:630)
	... 14 common frames omitted
2025-01-07 22:34:05 - Starting airlineServerApplication using Java 23.0.1 with PID 4320 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-07 22:34:05 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-07 22:34:05 - No active profile set, falling back to 1 default profile: "default"
2025-01-07 22:34:06 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-07 22:34:06 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-07 22:34:06 - Finished Spring Data repository scanning in 76 ms. Found 10 JPA repository interfaces.
2025-01-07 22:34:06 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-07 22:34:06 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-07 22:34:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:34:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:34:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:34:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:34:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:34:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:34:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:34:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:34:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:34:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-07 22:34:06 - Finished Spring Data repository scanning in 19 ms. Found 0 Redis repository interfaces.
2025-01-07 22:34:06 - Tomcat initialized with port 8080 (http)
2025-01-07 22:34:06 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-07 22:34:06 - Starting service [Tomcat]
2025-01-07 22:34:06 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-07 22:34:06 - Initializing Spring embedded WebApplicationContext
2025-01-07 22:34:06 - Root WebApplicationContext: initialization completed in 1168 ms
2025-01-07 22:34:06 - HikariPool-1 - Starting...
2025-01-07 22:34:08 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@2acca224
2025-01-07 22:34:08 - HikariPool-1 - Start completed.
2025-01-07 22:34:08 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-07 22:34:08 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-07 22:34:08 - HHH000026: Second-level cache disabled
2025-01-07 22:34:08 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-07 22:34:08 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-07 22:34:08 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-07 22:34:08 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-07 22:34:09 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-07 22:34:09 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-07 22:34:09 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-07 22:34:10 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-07 22:34:10 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-07 22:34:10 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-07 22:34:10 - Filter 'authenticationFilter' configured for use
2025-01-07 22:34:10 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-07 22:34:10 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-07 22:34:11 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-07 22:34:11 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-07 22:34:11 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [JedisPool [maxTotal=10, blockWhenExhausted=true, maxWaitDuration=PT-0.001S, lifo=true, fairness=false, testOnCreate=false, testOnBorrow=false, testOnReturn=false, testWhileIdle=true, durationBetweenEvictionRuns=PT30S, numTestsPerEvictionRun=-1, minEvictableIdleTimeDuration=PT1M, softMinEvictableIdleTimeDuration=PT-0.001S, evictionPolicy=org.apache.commons.pool2.impl.DefaultEvictionPolicy@398956e9, closeLock=java.lang.Object@2894519b, closed=false, evictionLock=java.lang.Object@a8a1822, evictor=org.apache.commons.pool2.impl.BaseGenericObjectPool$Evictor [scheduledFuture=java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@68aa14fa[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@11f5ab76[Wrapped task = org.apache.commons.pool2.impl.EvictionTimer$WeakRunner@62b899bf]]], evictionIterator=null, factoryClassLoader=java.lang.ref.WeakReference@323b4ac5, oname=org.apache.commons.pool2:type=GenericObjectPool,name=pool2, creationStackTrace=java.lang.Exception
	at org.apache.commons.pool2.impl.BaseGenericObjectPool.<init>(BaseGenericObjectPool.java:420)
	at org.apache.commons.pool2.impl.GenericObjectPool.<init>(GenericObjectPool.java:150)
	at redis.clients.jedis.util.Pool.<init>(Pool.java:16)
	at redis.clients.jedis.util.Pool.<init>(Pool.java:12)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:373)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:233)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:201)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:173)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:145)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:127)
	at com.airline.infrastructure.config.RedisConfig.jedisPool(RedisConfig.java:42)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$0.CGLIB$jedisPool$1(<generated>)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$FastClass$$1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:258)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:348)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$0.jedisPool(<generated>)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.lambda$instantiate$0(SimpleInstantiationStrategy.java:171)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiateWithFactoryMethod(SimpleInstantiationStrategy.java:88)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:168)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:489)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1351)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1568)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1514)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:913)
	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:240)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1371)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1208)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.instantiateSingleton(DefaultListableBeanFactory.java:1122)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingleton(DefaultListableBeanFactory.java:1093)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:1030)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:987)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.airline.AirLineServerApplication.main(airlineServerApplication.java:11)
, borrowedCount=0, returnedCount=0, createdCount=0, destroyedCount=0, destroyedByEvictorCount=0, destroyedByBorrowValidationCount=0, activeTimes=StatsStore [[]], size=100, index=0], idleTimes=StatsStore [[]], size=100, index=0], waitTimes=StatsStore [[]], size=100, index=0], maxBorrowWaitDuration=PT0S, swallowedExceptionListener=null, factoryType=null, maxIdle=5, minIdle=0, factory=redis.clients.jedis.JedisFactory@ea9f9ef, allObjects={}, createCount=0, idleObjects=[], abandonedConfig=null]] with key 'jedisPool'
2025-01-07 22:34:11 - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-01-07 22:34:11 - HikariPool-1 - Shutdown initiated...
2025-01-07 22:34:12 - HikariPool-1 - Shutdown completed.
2025-01-07 22:34:12 - Stopping service [Tomcat]
2025-01-07 22:34:12 - 

Error starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled.
2025-01-07 22:34:12 - Application run failed
org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [JedisPool [maxTotal=10, blockWhenExhausted=true, maxWaitDuration=PT-0.001S, lifo=true, fairness=false, testOnCreate=false, testOnBorrow=false, testOnReturn=false, testWhileIdle=true, durationBetweenEvictionRuns=PT30S, numTestsPerEvictionRun=-1, minEvictableIdleTimeDuration=PT1M, softMinEvictableIdleTimeDuration=PT-0.001S, evictionPolicy=org.apache.commons.pool2.impl.DefaultEvictionPolicy@398956e9, closeLock=java.lang.Object@2894519b, closed=false, evictionLock=java.lang.Object@a8a1822, evictor=org.apache.commons.pool2.impl.BaseGenericObjectPool$Evictor [scheduledFuture=java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@68aa14fa[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@11f5ab76[Wrapped task = org.apache.commons.pool2.impl.EvictionTimer$WeakRunner@62b899bf]]], evictionIterator=null, factoryClassLoader=java.lang.ref.WeakReference@323b4ac5, oname=org.apache.commons.pool2:type=GenericObjectPool,name=pool2, creationStackTrace=java.lang.Exception
	at org.apache.commons.pool2.impl.BaseGenericObjectPool.<init>(BaseGenericObjectPool.java:420)
	at org.apache.commons.pool2.impl.GenericObjectPool.<init>(GenericObjectPool.java:150)
	at redis.clients.jedis.util.Pool.<init>(Pool.java:16)
	at redis.clients.jedis.util.Pool.<init>(Pool.java:12)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:373)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:233)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:201)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:173)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:145)
	at redis.clients.jedis.JedisPool.<init>(JedisPool.java:127)
	at com.airline.infrastructure.config.RedisConfig.jedisPool(RedisConfig.java:42)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$0.CGLIB$jedisPool$1(<generated>)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$FastClass$$1.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:258)
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:348)
	at com.airline.infrastructure.config.RedisConfig$$SpringCGLIB$$0.jedisPool(<generated>)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.lambda$instantiate$0(SimpleInstantiationStrategy.java:171)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiateWithFactoryMethod(SimpleInstantiationStrategy.java:88)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:168)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:489)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1351)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1568)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1514)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:913)
	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:240)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1371)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1208)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.instantiateSingleton(DefaultListableBeanFactory.java:1122)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingleton(DefaultListableBeanFactory.java:1093)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:1030)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:987)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.airline.AirLineServerApplication.main(airlineServerApplication.java:11)
, borrowedCount=0, returnedCount=0, createdCount=0, destroyedCount=0, destroyedByEvictorCount=0, destroyedByBorrowValidationCount=0, activeTimes=StatsStore [[]], size=100, index=0], idleTimes=StatsStore [[]], size=100, index=0], waitTimes=StatsStore [[]], size=100, index=0], maxBorrowWaitDuration=PT0S, swallowedExceptionListener=null, factoryType=null, maxIdle=5, minIdle=0, factory=redis.clients.jedis.JedisFactory@ea9f9ef, allObjects={}, createCount=0, idleObjects=[], abandonedConfig=null]] with key 'jedisPool'
	at org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:640)
	at org.springframework.jmx.export.MBeanExporter.lambda$registerBeans$2(MBeanExporter.java:567)
	at java.base/java.util.HashMap.forEach(HashMap.java:1430)
	at org.springframework.jmx.export.MBeanExporter.registerBeans(MBeanExporter.java:567)
	at org.springframework.jmx.export.MBeanExporter.afterSingletonsInstantiated(MBeanExporter.java:450)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:1057)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:987)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.airline.AirLineServerApplication.main(airlineServerApplication.java:11)
Caused by: javax.management.InstanceAlreadyExistsException: MXBean already registered with name org.apache.commons.pool2:type=GenericObjectPool,name=pool2
	at java.management/com.sun.jmx.mbeanserver.MXBeanLookup.addReference(MXBeanLookup.java:152)
	at java.management/com.sun.jmx.mbeanserver.MXBeanSupport.register(MXBeanSupport.java:160)
	at java.management/com.sun.jmx.mbeanserver.MBeanSupport.preRegister2(MBeanSupport.java:173)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:909)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:880)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:315)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.springframework.jmx.support.MBeanRegistrationSupport.doRegister(MBeanRegistrationSupport.java:138)
	at org.springframework.jmx.export.MBeanExporter.registerBeanInstance(MBeanExporter.java:686)
	at org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:630)
	... 14 common frames omitted
2025-01-08 10:21:45 - Starting airlineServerApplication using Java 23.0.1 with PID 27608 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 10:21:45 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 10:21:45 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 10:21:46 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 10:21:46 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 10:21:46 - Finished Spring Data repository scanning in 75 ms. Found 10 JPA repository interfaces.
2025-01-08 10:21:46 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 10:21:46 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 10:21:46 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:21:46 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:21:46 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:21:46 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:21:46 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:21:46 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:21:46 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:21:46 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:21:46 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:21:46 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:21:46 - Finished Spring Data repository scanning in 21 ms. Found 0 Redis repository interfaces.
2025-01-08 10:21:47 - Tomcat initialized with port 8080 (http)
2025-01-08 10:21:47 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 10:21:47 - Starting service [Tomcat]
2025-01-08 10:21:47 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 10:21:47 - Initializing Spring embedded WebApplicationContext
2025-01-08 10:21:47 - Root WebApplicationContext: initialization completed in 1427 ms
2025-01-08 10:21:47 - HikariPool-1 - Starting...
2025-01-08 10:21:49 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@5d5574c7
2025-01-08 10:21:49 - HikariPool-1 - Start completed.
2025-01-08 10:21:49 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 10:21:49 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 10:21:49 - HHH000026: Second-level cache disabled
2025-01-08 10:21:49 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 10:21:49 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 10:21:49 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 10:21:50 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 10:21:50 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 10:21:50 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 10:21:50 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 10:21:51 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 10:21:51 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 10:21:51 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 10:21:51 - Filter 'authenticationFilter' configured for use
2025-01-08 10:21:52 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'kafkaConsumer' defined in file [F:\project personal\TrainApp\airlineServer\build\classes\java\main\com\airline\application\component\KafkaConsumer.class]: Unsatisfied dependency expressed through constructor parameter 1: Error creating bean with name 'ticketUseCaseImpl': Injection of autowired dependencies failed
2025-01-08 10:21:52 - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 10:21:52 - HikariPool-1 - Shutdown initiated...
2025-01-08 10:21:52 - HikariPool-1 - Shutdown completed.
2025-01-08 10:21:52 - Stopping service [Tomcat]
2025-01-08 10:21:52 - 

Error starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled.
2025-01-08 10:21:52 - Application run failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'kafkaConsumer' defined in file [F:\project personal\TrainApp\airlineServer\build\classes\java\main\com\airline\application\component\KafkaConsumer.class]: Unsatisfied dependency expressed through constructor parameter 1: Error creating bean with name 'ticketUseCaseImpl': Injection of autowired dependencies failed
	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:804)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:240)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1371)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1208)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.instantiateSingleton(DefaultListableBeanFactory.java:1122)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingleton(DefaultListableBeanFactory.java:1093)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:1030)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:987)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.airline.AirLineServerApplication.main(airlineServerApplication.java:11)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'ticketUseCaseImpl': Injection of autowired dependencies failed
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:515)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1435)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:600)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:254)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1626)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1514)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:913)
	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791)
	... 21 common frames omitted
Caused by: org.springframework.util.PlaceholderResolutionException: Could not resolve placeholder 'spring.data.redis.key.ticket.ticket-payment.timeout' in value "${spring.data.redis.key.ticket.ticket-payment.timeout}"
	at org.springframework.util.PlaceholderResolutionException.withValue(PlaceholderResolutionException.java:81)
	at org.springframework.util.PlaceholderParser$ParsedValue.resolve(PlaceholderParser.java:416)
	at org.springframework.util.PlaceholderParser.replacePlaceholders(PlaceholderParser.java:128)
	at org.springframework.util.PropertyPlaceholderHelper.parseStringValue(PropertyPlaceholderHelper.java:118)
	at org.springframework.util.PropertyPlaceholderHelper.replacePlaceholders(PropertyPlaceholderHelper.java:114)
	at org.springframework.core.env.AbstractPropertyResolver.doResolvePlaceholders(AbstractPropertyResolver.java:255)
	at org.springframework.core.env.AbstractPropertyResolver.resolveRequiredPlaceholders(AbstractPropertyResolver.java:226)
	at org.springframework.context.support.PropertySourcesPlaceholderConfigurer.lambda$processProperties$0(PropertySourcesPlaceholderConfigurer.java:201)
	at org.springframework.beans.factory.support.AbstractBeanFactory.resolveEmbeddedValue(AbstractBeanFactory.java:963)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1536)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1514)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:785)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:768)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:146)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:509)
	... 33 common frames omitted
2025-01-08 10:22:28 - Starting airlineServerApplication using Java 23.0.1 with PID 22172 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 10:22:28 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 10:22:28 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 10:22:28 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 10:22:28 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 10:22:28 - Finished Spring Data repository scanning in 75 ms. Found 10 JPA repository interfaces.
2025-01-08 10:22:28 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 10:22:28 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 10:22:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:22:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:22:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:22:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:22:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:22:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:22:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:22:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:22:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:22:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:22:29 - Finished Spring Data repository scanning in 17 ms. Found 0 Redis repository interfaces.
2025-01-08 10:22:29 - Tomcat initialized with port 8080 (http)
2025-01-08 10:22:29 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 10:22:29 - Starting service [Tomcat]
2025-01-08 10:22:29 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 10:22:29 - Initializing Spring embedded WebApplicationContext
2025-01-08 10:22:29 - Root WebApplicationContext: initialization completed in 1100 ms
2025-01-08 10:22:29 - HikariPool-1 - Starting...
2025-01-08 10:22:32 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@56872fcb
2025-01-08 10:22:32 - HikariPool-1 - Start completed.
2025-01-08 10:22:32 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 10:22:32 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 10:22:32 - HHH000026: Second-level cache disabled
2025-01-08 10:22:32 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 10:22:32 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 10:22:32 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 10:22:32 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 10:22:33 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 10:22:33 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 10:22:33 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 10:22:34 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 10:22:34 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 10:22:34 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 10:22:34 - Filter 'authenticationFilter' configured for use
2025-01-08 10:22:34 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'transactionMonitorService' defined in file [F:\project personal\TrainApp\airlineServer\build\classes\java\main\com\airline\application\payment\service\TransactionMonitorService.class]: Unsatisfied dependency expressed through constructor parameter 3: No qualifying bean of type 'redis.clients.jedis.JedisPool' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {}
2025-01-08 10:22:34 - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 10:22:34 - HikariPool-1 - Shutdown initiated...
2025-01-08 10:22:35 - HikariPool-1 - Shutdown completed.
2025-01-08 10:22:35 - Stopping service [Tomcat]
2025-01-08 10:22:35 - 

Error starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled.
2025-01-08 10:22:35 - 

***************************
APPLICATION FAILED TO START
***************************

Description:

Parameter 3 of constructor in com.airline.application.payment.service.TransactionMonitorService required a bean of type 'redis.clients.jedis.JedisPool' that could not be found.


Action:

Consider defining a bean of type 'redis.clients.jedis.JedisPool' in your configuration.

2025-01-08 10:23:01 - Starting airlineServerApplication using Java 23.0.1 with PID 14696 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 10:23:01 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 10:23:01 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 10:23:01 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 10:23:01 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 10:23:01 - Finished Spring Data repository scanning in 75 ms. Found 10 JPA repository interfaces.
2025-01-08 10:23:01 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 10:23:01 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 10:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:23:01 - Finished Spring Data repository scanning in 17 ms. Found 0 Redis repository interfaces.
2025-01-08 10:23:02 - Tomcat initialized with port 8080 (http)
2025-01-08 10:23:02 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 10:23:02 - Starting service [Tomcat]
2025-01-08 10:23:02 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 10:23:02 - Initializing Spring embedded WebApplicationContext
2025-01-08 10:23:02 - Root WebApplicationContext: initialization completed in 1163 ms
2025-01-08 10:23:02 - HikariPool-1 - Starting...
2025-01-08 10:23:04 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@34e25492
2025-01-08 10:23:04 - HikariPool-1 - Start completed.
2025-01-08 10:23:04 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 10:23:04 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 10:23:04 - HHH000026: Second-level cache disabled
2025-01-08 10:23:04 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 10:23:04 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 10:23:04 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 10:23:04 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 10:23:05 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 10:23:05 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 10:23:05 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 10:23:05 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 10:23:05 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 10:23:05 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 10:23:06 - Filter 'authenticationFilter' configured for use
2025-01-08 10:23:06 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 10:23:06 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 10:23:06 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-08 10:23:06 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 10:23:07 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-08 10:23:07 - Tomcat started on port 8080 (http) with context path '/'
2025-01-08 10:23:07 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ticket-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ticket
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 10:23:07 - initializing Kafka metrics collector
2025-01-08 10:23:07 - Kafka version: 3.9.0
2025-01-08 10:23:07 - Kafka commitId: 84caaa6e9da06435
2025-01-08 10:23:07 - Kafka startTimeMs: 1736306587296
2025-01-08 10:23:07 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Subscribed to topic(s): ticket-cancel
2025-01-08 10:23:07 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 10:23:07 - initializing Kafka metrics collector
2025-01-08 10:23:07 - Kafka version: 3.9.0
2025-01-08 10:23:07 - Kafka commitId: 84caaa6e9da06435
2025-01-08 10:23:07 - Kafka startTimeMs: 1736306587313
2025-01-08 10:23:07 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-08 10:23:07 - Started airlineServerApplication in 6.545 seconds (process running for 6.9)
2025-01-08 10:23:07 - airlineServerApplication started
2025-01-08 10:23:08 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 10:23:08 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 10:23:08 - [Consumer clientId=consumer-email-group-2, groupId=email-group] (Re-)joining group
2025-01-08 10:23:08 - [Consumer clientId=consumer-ticket-1, groupId=ticket] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {ticket-cancel=LEADER_NOT_AVAILABLE}
2025-01-08 10:23:08 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 10:23:08 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 10:23:08 - [Consumer clientId=consumer-ticket-1, groupId=ticket] (Re-)joining group
2025-01-08 10:23:08 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-2-dac7d13b-a0da-421b-8e11-1cf07c66b164
2025-01-08 10:23:08 - [Consumer clientId=consumer-email-group-2, groupId=email-group] (Re-)joining group
2025-01-08 10:23:09 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Request joining group due to: need to re-join with the given member-id: consumer-ticket-1-34b28e36-3cb3-42c0-b404-c9c5d3287fed
2025-01-08 10:23:09 - [Consumer clientId=consumer-ticket-1, groupId=ticket] (Re-)joining group
2025-01-08 10:23:09 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Successfully joined group with generation Generation{generationId=127, memberId='consumer-email-group-2-dac7d13b-a0da-421b-8e11-1cf07c66b164', protocol='range'}
2025-01-08 10:23:09 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Successfully synced group in generation Generation{generationId=127, memberId='consumer-email-group-2-dac7d13b-a0da-421b-8e11-1cf07c66b164', protocol='range'}
2025-01-08 10:23:09 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Notifying assignor about the new Assignment(partitions=[])
2025-01-08 10:23:09 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Adding newly assigned partitions: 
2025-01-08 10:23:09 - email-group: partitions assigned: []
2025-01-08 10:23:12 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Successfully joined group with generation Generation{generationId=1, memberId='consumer-ticket-1-34b28e36-3cb3-42c0-b404-c9c5d3287fed', protocol='range'}
2025-01-08 10:23:12 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Finished assignment for group at generation 1: {consumer-ticket-1-34b28e36-3cb3-42c0-b404-c9c5d3287fed=Assignment(partitions=[ticket-cancel-0])}
2025-01-08 10:23:12 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Successfully synced group in generation Generation{generationId=1, memberId='consumer-ticket-1-34b28e36-3cb3-42c0-b404-c9c5d3287fed', protocol='range'}
2025-01-08 10:23:12 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Notifying assignor about the new Assignment(partitions=[ticket-cancel-0])
2025-01-08 10:23:12 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Adding newly assigned partitions: ticket-cancel-0
2025-01-08 10:23:12 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Found no committed offset for partition ticket-cancel-0
2025-01-08 10:23:12 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Found no committed offset for partition ticket-cancel-0
2025-01-08 10:23:13 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Resetting offset for partition ticket-cancel-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}.
2025-01-08 10:23:13 - ticket: partitions assigned: [ticket-cancel-0]
2025-01-08 10:23:18 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-08 10:23:18 - Initializing Servlet 'dispatcherServlet'
2025-01-08 10:23:18 - Completed initialization in 2 ms
2025-01-08 10:23:18 - Securing POST /ticket
2025-01-08 10:23:18 - Secured POST /ticket
2025-01-08 10:23:18 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 10:23:18 - Securing POST /error
2025-01-08 10:23:18 - Secured POST /error
2025-01-08 10:23:18 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 10:23:33 - Securing POST /api/ticket
2025-01-08 10:23:33 - Secured POST /api/ticket
2025-01-08 10:23:33 - Start booking ticket with request: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@2f938ab8
2025-01-08 10:23:34 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 10:24:28 - Securing POST /api/ticket
2025-01-08 10:24:28 - Secured POST /api/ticket
2025-01-08 10:24:28 - Start booking ticket with request: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@3222781c
2025-01-08 10:24:30 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 10:24:30 - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed: org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection] with root cause
redis.clients.jedis.exceptions.JedisDataException: ERR AUTH <password> called without any password configured for the default user. Are you sure your configuration is correct?
	at redis.clients.jedis.Protocol.processError(Protocol.java:96)
	at redis.clients.jedis.Protocol.process(Protocol.java:137)
	at redis.clients.jedis.Protocol.read(Protocol.java:192)
	at redis.clients.jedis.Connection.readProtocolWithCheckingBroken(Connection.java:335)
	at redis.clients.jedis.Connection.getStatusCodeReply(Connection.java:262)
	at redis.clients.jedis.Connection.auth(Connection.java:446)
	at redis.clients.jedis.Connection.initializeFromClientConfig(Connection.java:380)
	at redis.clients.jedis.Connection.<init>(Connection.java:61)
	at redis.clients.jedis.Jedis.<init>(Jedis.java:214)
	at redis.clients.jedis.JedisFactory.makeObject(JedisFactory.java:178)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:566)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:306)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:233)
	at redis.clients.jedis.util.Pool.getResource(Pool.java:38)
	at redis.clients.jedis.JedisPool.getResource(JedisPool.java:378)
	at redis.clients.jedis.JedisPool.getResource(JedisPool.java:17)
	at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:916)
	at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:888)
	at org.springframework.data.redis.core.RedisConnectionUtils.fetchConnection(RedisConnectionUtils.java:195)
	at org.springframework.data.redis.core.RedisConnectionUtils.doGetConnection(RedisConnectionUtils.java:144)
	at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:105)
	at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:398)
	at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:378)
	at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:117)
	at org.springframework.data.redis.core.DefaultValueOperations.set(DefaultValueOperations.java:208)
	at com.airline.infrastructure.service.cache.impl.RedisCacheServiceImpl.put(RedisCacheServiceImpl.java:39)
	at com.airline.application.ticket.service.impl.TicketUseCaseImpl.book(TicketUseCaseImpl.java:132)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:380)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:727)
	at com.airline.application.ticket.service.impl.TicketUseCaseImpl$$SpringCGLIB$$0.book(<generated>)
	at com.airline.presentation.ticket.TicketController.handleBookingTicket(TicketController.java:28)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:255)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:188)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:118)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:986)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:891)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1088)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:978)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:914)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:885)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:658)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:195)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:51)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:110)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.servlet.resource.ResourceUrlEncodingFilter.doFilter(ResourceUrlEncodingFilter.java:66)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.CompositeFilter$VirtualFilterChain.doFilter(CompositeFilter.java:108)
	at org.springframework.security.web.FilterChainProxy.lambda$doFilterInternal$3(FilterChainProxy.java:231)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:365)
	at org.springframework.security.web.access.intercept.AuthorizationFilter.doFilter(AuthorizationFilter.java:101)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:126)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:120)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:100)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:179)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374)
	at com.airline.application.utils.AuthenticationFilter.doFilterInternal(AuthenticationFilter.java:60)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:723)
	at com.airline.application.utils.AuthenticationFilter$$SpringCGLIB$$0.doFilterInternal(<generated>)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:107)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:93)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374)
	at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374)
	at org.springframework.security.web.context.SecurityContextHolderFilter.doFilter(SecurityContextHolderFilter.java:82)
	at org.springframework.security.web.context.SecurityContextHolderFilter.doFilter(SecurityContextHolderFilter.java:69)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:62)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374)
	at org.springframework.security.web.session.DisableEncodeUrlFilter.doFilterInternal(DisableEncodeUrlFilter.java:42)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:374)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:233)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:191)
	at org.springframework.web.filter.CompositeFilter$VirtualFilterChain.doFilter(CompositeFilter.java:113)
	at org.springframework.web.servlet.handler.HandlerMappingIntrospector.lambda$createCacheFilter$3(HandlerMappingIntrospector.java:243)
	at org.springframework.web.filter.CompositeFilter$VirtualFilterChain.doFilter(CompositeFilter.java:113)
	at org.springframework.web.filter.CompositeFilter.doFilter(CompositeFilter.java:74)
	at org.springframework.security.config.annotation.web.configuration.WebMvcSecurityConfiguration$CompositeFilterChainProxy.doFilter(WebMvcSecurityConfiguration.java:238)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:362)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:278)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:167)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:90)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:483)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:115)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:93)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:344)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:397)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:905)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1741)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1190)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:63)
	at java.base/java.lang.Thread.run(Thread.java:1575)
2025-01-08 10:24:30 - Securing POST /error
2025-01-08 10:24:30 - Secured POST /error
2025-01-08 10:24:30 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 10:25:13 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Revoke previously assigned partitions ticket-cancel-0
2025-01-08 10:25:13 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Member consumer-email-group-2-dac7d13b-a0da-421b-8e11-1cf07c66b164 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 10:25:13 - ticket: partitions revoked: [ticket-cancel-0]
2025-01-08 10:25:13 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Member consumer-ticket-1-34b28e36-3cb3-42c0-b404-c9c5d3287fed sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 10:25:13 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 10:25:13 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 10:25:13 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 10:25:13 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 10:25:13 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 10:25:13 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 10:25:13 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 10:25:13 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 10:25:13 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 10:25:13 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 10:25:15 - Starting airlineServerApplication using Java 23.0.1 with PID 21132 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 10:25:15 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 10:25:15 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 10:25:16 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 10:25:16 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 10:25:16 - Finished Spring Data repository scanning in 77 ms. Found 10 JPA repository interfaces.
2025-01-08 10:25:16 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 10:25:16 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 10:25:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:25:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:25:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:25:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:25:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:25:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:25:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:25:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:25:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:25:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:25:16 - Finished Spring Data repository scanning in 17 ms. Found 0 Redis repository interfaces.
2025-01-08 10:25:17 - Tomcat initialized with port 8080 (http)
2025-01-08 10:25:17 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 10:25:17 - Starting service [Tomcat]
2025-01-08 10:25:17 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 10:25:17 - Initializing Spring embedded WebApplicationContext
2025-01-08 10:25:17 - Root WebApplicationContext: initialization completed in 1147 ms
2025-01-08 10:25:17 - HikariPool-1 - Starting...
2025-01-08 10:25:18 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@716ae973
2025-01-08 10:25:18 - HikariPool-1 - Start completed.
2025-01-08 10:25:18 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 10:25:18 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 10:25:18 - HHH000026: Second-level cache disabled
2025-01-08 10:25:19 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 10:25:19 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 10:25:19 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 10:25:19 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 10:25:19 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 10:25:19 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 10:25:20 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 10:25:20 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 10:25:20 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 10:25:20 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 10:25:20 - Filter 'authenticationFilter' configured for use
2025-01-08 10:25:21 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 10:25:21 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 10:25:21 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-08 10:25:21 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 10:25:21 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-08 10:25:21 - Tomcat started on port 8080 (http) with context path '/'
2025-01-08 10:25:21 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 10:25:21 - initializing Kafka metrics collector
2025-01-08 10:25:21 - Kafka version: 3.9.0
2025-01-08 10:25:21 - Kafka commitId: 84caaa6e9da06435
2025-01-08 10:25:21 - Kafka startTimeMs: 1736306721842
2025-01-08 10:25:21 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-08 10:25:21 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ticket-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ticket
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 10:25:21 - initializing Kafka metrics collector
2025-01-08 10:25:21 - Kafka version: 3.9.0
2025-01-08 10:25:21 - Kafka commitId: 84caaa6e9da06435
2025-01-08 10:25:21 - Kafka startTimeMs: 1736306721859
2025-01-08 10:25:21 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Subscribed to topic(s): ticket-cancel
2025-01-08 10:25:21 - Started airlineServerApplication in 6.181 seconds (process running for 6.536)
2025-01-08 10:25:21 - airlineServerApplication started
2025-01-08 10:25:22 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 10:25:22 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 10:25:22 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 10:25:22 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 10:25:22 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 10:25:22 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 10:25:23 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-1-24359992-e0b4-45e5-b072-2449fc551e40
2025-01-08 10:25:23 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 10:25:23 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: need to re-join with the given member-id: consumer-ticket-2-edcc5dce-3c07-47f3-882a-09ae4f6993ba
2025-01-08 10:25:23 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 10:25:24 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully joined group with generation Generation{generationId=129, memberId='consumer-email-group-1-24359992-e0b4-45e5-b072-2449fc551e40', protocol='range'}
2025-01-08 10:25:24 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully synced group in generation Generation{generationId=129, memberId='consumer-email-group-1-24359992-e0b4-45e5-b072-2449fc551e40', protocol='range'}
2025-01-08 10:25:24 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Notifying assignor about the new Assignment(partitions=[email-topic-0])
2025-01-08 10:25:24 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Adding newly assigned partitions: email-topic-0
2025-01-08 10:25:25 - Setting offset for partition email-topic-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 10:25:25 - email-group: partitions assigned: [email-topic-0]
2025-01-08 10:25:26 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully joined group with generation Generation{generationId=3, memberId='consumer-ticket-2-edcc5dce-3c07-47f3-882a-09ae4f6993ba', protocol='range'}
2025-01-08 10:25:26 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Finished assignment for group at generation 3: {consumer-ticket-2-edcc5dce-3c07-47f3-882a-09ae4f6993ba=Assignment(partitions=[ticket-cancel-0])}
2025-01-08 10:25:26 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully synced group in generation Generation{generationId=3, memberId='consumer-ticket-2-edcc5dce-3c07-47f3-882a-09ae4f6993ba', protocol='range'}
2025-01-08 10:25:26 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Notifying assignor about the new Assignment(partitions=[ticket-cancel-0])
2025-01-08 10:25:26 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Adding newly assigned partitions: ticket-cancel-0
2025-01-08 10:25:26 - Setting offset for partition ticket-cancel-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 10:25:26 - ticket: partitions assigned: [ticket-cancel-0]
2025-01-08 10:25:37 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-08 10:25:37 - Initializing Servlet 'dispatcherServlet'
2025-01-08 10:25:37 - Completed initialization in 1 ms
2025-01-08 10:25:37 - Securing POST /api/ticket
2025-01-08 10:25:37 - Secured POST /api/ticket
2025-01-08 10:25:38 - Start booking ticket with request: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@234c912c
2025-01-08 10:25:39 - Ticket booking successful. Ticket ID: 2abfc6bee81c48dcbaddf3066f116962
2025-01-08 10:25:39 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 10:25:47 - Securing POST /api/ticket/2abfc6bee81c48dcbaddf3066f116962/confirm
2025-01-08 10:25:47 - Secured POST /api/ticket/2abfc6bee81c48dcbaddf3066f116962/confirm
2025-01-08 10:25:47 - Confirming ticket with ticketId=2abfc6bee81c48dcbaddf3066f116962
2025-01-08 10:25:47 - Ticket booked. Ticket: com.airline.domain.ticket.model.Ticket@71d5f5e7
2025-01-08 10:25:48 - Ticket with ticketId=2abfc6bee81c48dcbaddf3066f116962 update available seats successfully for trainScheduleId=504b1c7c7b7b4a7cb2874cb8a57efdbb.
2025-01-08 10:25:52 - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [dqhdev.io.vn:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = airlineServer-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-01-08 10:25:52 - initializing Kafka metrics collector
2025-01-08 10:25:52 - [Producer clientId=airlineServer-producer-1] Instantiated an idempotent producer.
2025-01-08 10:25:52 - Kafka version: 3.9.0
2025-01-08 10:25:52 - Kafka commitId: 84caaa6e9da06435
2025-01-08 10:25:52 - Kafka startTimeMs: 1736306752510
2025-01-08 10:25:53 - [Producer clientId=airlineServer-producer-1] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 10:25:53 - [Producer clientId=airlineServer-producer-1] ProducerId set to 7 with epoch 0
2025-01-08 10:25:53 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 10:25:53 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
org.thymeleaf.exceptions.TemplateProcessingException: Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:131)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:62)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:44)
	at org.thymeleaf.engine.EngineEventUtils.parseAttributeExpression(EngineEventUtils.java:220)
	at org.thymeleaf.engine.EngineEventUtils.computeAttributeExpression(EngineEventUtils.java:207)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:125)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:661)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.application.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:22)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
2025-01-08 10:25:53 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 11 for partition email-topic-0
2025-01-08 10:25:53 - Record in retry and not yet recovered
2025-01-08 10:25:54 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
org.thymeleaf.exceptions.TemplateProcessingException: Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:131)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:62)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:44)
	at org.thymeleaf.engine.EngineEventUtils.parseAttributeExpression(EngineEventUtils.java:220)
	at org.thymeleaf.engine.EngineEventUtils.computeAttributeExpression(EngineEventUtils.java:207)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:125)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.application.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:22)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
2025-01-08 10:25:54 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 11 for partition email-topic-0
2025-01-08 10:25:54 - Record in retry and not yet recovered
2025-01-08 10:25:55 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
org.thymeleaf.exceptions.TemplateProcessingException: Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:131)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:62)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:44)
	at org.thymeleaf.engine.EngineEventUtils.parseAttributeExpression(EngineEventUtils.java:220)
	at org.thymeleaf.engine.EngineEventUtils.computeAttributeExpression(EngineEventUtils.java:207)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:125)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.application.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:22)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
2025-01-08 10:25:55 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 11 for partition email-topic-0
2025-01-08 10:25:55 - Record in retry and not yet recovered
2025-01-08 10:25:56 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
org.thymeleaf.exceptions.TemplateProcessingException: Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:131)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:62)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:44)
	at org.thymeleaf.engine.EngineEventUtils.parseAttributeExpression(EngineEventUtils.java:220)
	at org.thymeleaf.engine.EngineEventUtils.computeAttributeExpression(EngineEventUtils.java:207)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:125)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.application.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:22)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
2025-01-08 10:25:56 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 11 for partition email-topic-0
2025-01-08 10:25:56 - Record in retry and not yet recovered
2025-01-08 10:25:57 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
org.thymeleaf.exceptions.TemplateProcessingException: Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:131)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:62)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:44)
	at org.thymeleaf.engine.EngineEventUtils.parseAttributeExpression(EngineEventUtils.java:220)
	at org.thymeleaf.engine.EngineEventUtils.computeAttributeExpression(EngineEventUtils.java:207)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:125)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.application.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:22)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
2025-01-08 10:25:57 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 11 for partition email-topic-0
2025-01-08 10:25:57 - Record in retry and not yet recovered
2025-01-08 10:25:58 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
org.thymeleaf.exceptions.TemplateProcessingException: Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:131)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:62)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:44)
	at org.thymeleaf.engine.EngineEventUtils.parseAttributeExpression(EngineEventUtils.java:220)
	at org.thymeleaf.engine.EngineEventUtils.computeAttributeExpression(EngineEventUtils.java:207)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:125)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.application.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:22)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
2025-01-08 10:25:58 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 11 for partition email-topic-0
2025-01-08 10:25:58 - Record in retry and not yet recovered
2025-01-08 10:25:59 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
org.thymeleaf.exceptions.TemplateProcessingException: Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:131)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:62)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:44)
	at org.thymeleaf.engine.EngineEventUtils.parseAttributeExpression(EngineEventUtils.java:220)
	at org.thymeleaf.engine.EngineEventUtils.computeAttributeExpression(EngineEventUtils.java:207)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:125)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.application.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:22)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
2025-01-08 10:25:59 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 11 for partition email-topic-0
2025-01-08 10:25:59 - Record in retry and not yet recovered
2025-01-08 10:26:00 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
org.thymeleaf.exceptions.TemplateProcessingException: Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:131)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:62)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:44)
	at org.thymeleaf.engine.EngineEventUtils.parseAttributeExpression(EngineEventUtils.java:220)
	at org.thymeleaf.engine.EngineEventUtils.computeAttributeExpression(EngineEventUtils.java:207)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:125)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.application.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:22)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
2025-01-08 10:26:00 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 11 for partition email-topic-0
2025-01-08 10:26:00 - Record in retry and not yet recovered
2025-01-08 10:26:01 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
org.thymeleaf.exceptions.TemplateProcessingException: Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:131)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:62)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:44)
	at org.thymeleaf.engine.EngineEventUtils.parseAttributeExpression(EngineEventUtils.java:220)
	at org.thymeleaf.engine.EngineEventUtils.computeAttributeExpression(EngineEventUtils.java:207)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:125)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.application.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:22)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
2025-01-08 10:26:01 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Seeking to offset 11 for partition email-topic-0
2025-01-08 10:26:01 - Record in retry and not yet recovered
2025-01-08 10:26:01 - [THYMELEAF][org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Exception processing template "confirm-ticket": Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
org.thymeleaf.exceptions.TemplateProcessingException: Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:131)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:62)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:44)
	at org.thymeleaf.engine.EngineEventUtils.parseAttributeExpression(EngineEventUtils.java:220)
	at org.thymeleaf.engine.EngineEventUtils.computeAttributeExpression(EngineEventUtils.java:207)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:125)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.application.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:22)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
2025-01-08 10:26:01 - Backoff FixedBackOff{interval=0, currentAttempts=10, maxAttempts=9} exhausted for email-topic-0@11
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.airline.application.component.KafkaConsumer.listenOtpMailRequest(com.airline.infrastructure.dataTransferObject.request.EmailRequest)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2982)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2889)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2853)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2766)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2493)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2144)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1520)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1458)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1327)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1848)
	at java.base/java.lang.Thread.run(Thread.java:1575)
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:489)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
Caused by: org.thymeleaf.exceptions.TemplateProcessingException: Could not parse as expression: "'Total Seats:' ${totalSeats} ${(childSeats > 0 ? '(Child: ' + childSeats + ')' : '')
               + (childSeats > 0 && (adultSeats > 0 || seniorSeats > 0) ? ', ' : '')
               + (adultSeats > 0 ? '(Adult: ' + adultSeats + ')' : '')
               + ((adultSeats > 0 && seniorSeats > 0) ? ', ' : '')
               + (seniorSeats > 0 ? '(Senior: ' + seniorSeats + ')' : '')}" (template: "confirm-ticket" - line 41, col 21)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:131)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:62)
	at org.thymeleaf.standard.expression.StandardExpressionParser.parseExpression(StandardExpressionParser.java:44)
	at org.thymeleaf.engine.EngineEventUtils.parseAttributeExpression(EngineEventUtils.java:220)
	at org.thymeleaf.engine.EngineEventUtils.computeAttributeExpression(EngineEventUtils.java:207)
	at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:125)
	at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74)
	at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95)
	at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633)
	at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314)
	at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205)
	at org.thymeleaf.engine.TemplateModel.process(TemplateModel.java:136)
	at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:592)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1103)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1064)
	at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1053)
	at com.airline.infrastructure.service.messaging.EmailService.send(EmailService.java:41)
	at com.airline.application.component.KafkaConsumer.listenOtpMailRequest(KafkaConsumer.java:22)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:71)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:474)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	... 10 common frames omitted
2025-01-08 10:26:10 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Revoke previously assigned partitions email-topic-0
2025-01-08 10:26:10 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Revoke previously assigned partitions ticket-cancel-0
2025-01-08 10:26:10 - email-group: partitions revoked: [email-topic-0]
2025-01-08 10:26:10 - ticket: partitions revoked: [ticket-cancel-0]
2025-01-08 10:26:10 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Member consumer-email-group-1-24359992-e0b4-45e5-b072-2449fc551e40 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 10:26:10 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Member consumer-ticket-2-edcc5dce-3c07-47f3-882a-09ae4f6993ba sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 10:26:10 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 10:26:10 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 10:26:10 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 10:26:10 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 10:26:10 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 10:26:10 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 10:26:10 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 10:26:10 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 10:26:10 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 10:26:10 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 10:42:17 - Starting airlineServerApplication using Java 23.0.1 with PID 14712 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 10:42:17 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 10:42:17 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 10:42:18 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 10:42:18 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 10:42:18 - Finished Spring Data repository scanning in 85 ms. Found 10 JPA repository interfaces.
2025-01-08 10:42:18 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 10:42:18 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 10:42:18 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:42:18 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:42:18 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:42:18 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:42:18 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:42:18 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:42:18 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:42:18 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:42:18 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:42:18 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 10:42:18 - Finished Spring Data repository scanning in 18 ms. Found 0 Redis repository interfaces.
2025-01-08 10:42:18 - Tomcat initialized with port 8080 (http)
2025-01-08 10:42:18 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 10:42:18 - Starting service [Tomcat]
2025-01-08 10:42:18 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 10:42:18 - Initializing Spring embedded WebApplicationContext
2025-01-08 10:42:18 - Root WebApplicationContext: initialization completed in 1218 ms
2025-01-08 10:42:18 - HikariPool-1 - Starting...
2025-01-08 10:42:20 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@56872fcb
2025-01-08 10:42:20 - HikariPool-1 - Start completed.
2025-01-08 10:42:20 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 10:42:20 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 10:42:20 - HHH000026: Second-level cache disabled
2025-01-08 10:42:20 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 10:42:21 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 10:42:21 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 10:42:21 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 10:42:21 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 10:42:21 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 10:42:22 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 10:42:22 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 10:42:22 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 10:42:22 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 10:42:22 - Filter 'authenticationFilter' configured for use
2025-01-08 10:42:23 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 10:42:23 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 10:42:23 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-08 10:42:23 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 10:42:23 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-08 10:42:23 - Tomcat started on port 8080 (http) with context path '/'
2025-01-08 10:42:23 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 10:42:23 - initializing Kafka metrics collector
2025-01-08 10:42:23 - Kafka version: 3.9.0
2025-01-08 10:42:23 - Kafka commitId: 84caaa6e9da06435
2025-01-08 10:42:23 - Kafka startTimeMs: 1736307743962
2025-01-08 10:42:23 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-08 10:42:23 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ticket-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ticket
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 10:42:23 - initializing Kafka metrics collector
2025-01-08 10:42:23 - Kafka version: 3.9.0
2025-01-08 10:42:23 - Kafka commitId: 84caaa6e9da06435
2025-01-08 10:42:23 - Kafka startTimeMs: 1736307743976
2025-01-08 10:42:23 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Subscribed to topic(s): ticket-cancel
2025-01-08 10:42:23 - Started airlineServerApplication in 6.647 seconds (process running for 7.006)
2025-01-08 10:42:23 - airlineServerApplication started
2025-01-08 10:42:24 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 10:42:24 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 10:42:24 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 10:42:24 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 10:42:24 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 10:42:24 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 10:42:25 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-1-2f1ffeee-47c1-4eab-803c-fbc21d031012
2025-01-08 10:42:25 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 10:42:25 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: need to re-join with the given member-id: consumer-ticket-2-9a2e1ca7-d978-4c48-a009-4b6b8cc20be7
2025-01-08 10:42:25 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 10:42:27 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully joined group with generation Generation{generationId=131, memberId='consumer-email-group-1-2f1ffeee-47c1-4eab-803c-fbc21d031012', protocol='range'}
2025-01-08 10:42:27 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully synced group in generation Generation{generationId=131, memberId='consumer-email-group-1-2f1ffeee-47c1-4eab-803c-fbc21d031012', protocol='range'}
2025-01-08 10:42:27 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Notifying assignor about the new Assignment(partitions=[email-topic-0])
2025-01-08 10:42:27 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Adding newly assigned partitions: email-topic-0
2025-01-08 10:42:28 - Setting offset for partition email-topic-0 to the committed offset FetchPosition{offset=12, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 10:42:28 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-08 10:42:28 - Initializing Servlet 'dispatcherServlet'
2025-01-08 10:42:28 - Completed initialization in 1 ms
2025-01-08 10:42:28 - Securing POST /api/ticket
2025-01-08 10:42:28 - Secured POST /api/ticket
2025-01-08 10:42:28 - email-group: partitions assigned: [email-topic-0]
2025-01-08 10:42:28 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully joined group with generation Generation{generationId=5, memberId='consumer-ticket-2-9a2e1ca7-d978-4c48-a009-4b6b8cc20be7', protocol='range'}
2025-01-08 10:42:28 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Finished assignment for group at generation 5: {consumer-ticket-2-9a2e1ca7-d978-4c48-a009-4b6b8cc20be7=Assignment(partitions=[ticket-cancel-0])}
2025-01-08 10:42:28 - Start booking ticket with request: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@2447eb12
2025-01-08 10:42:28 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully synced group in generation Generation{generationId=5, memberId='consumer-ticket-2-9a2e1ca7-d978-4c48-a009-4b6b8cc20be7', protocol='range'}
2025-01-08 10:42:28 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Notifying assignor about the new Assignment(partitions=[ticket-cancel-0])
2025-01-08 10:42:28 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Adding newly assigned partitions: ticket-cancel-0
2025-01-08 10:42:28 - Setting offset for partition ticket-cancel-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 10:42:29 - ticket: partitions assigned: [ticket-cancel-0]
2025-01-08 10:42:29 - Ticket booking successful. Ticket ID: e3438d10c8c745b7b434a37af5006578
2025-01-08 10:42:30 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 10:42:34 - Securing POST /api/ticket/e3438d10c8c745b7b434a37af5006578/confirm
2025-01-08 10:42:34 - Secured POST /api/ticket/e3438d10c8c745b7b434a37af5006578/confirm
2025-01-08 10:42:34 - Confirming ticket with ticketId=e3438d10c8c745b7b434a37af5006578
2025-01-08 10:42:35 - Ticket booked. Ticket: com.airline.domain.ticket.model.Ticket@3aa78947
2025-01-08 10:42:36 - Ticket with ticketId=e3438d10c8c745b7b434a37af5006578 update available seats successfully for trainScheduleId=504b1c7c7b7b4a7cb2874cb8a57efdbb.
2025-01-08 10:42:41 - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [dqhdev.io.vn:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = airlineServer-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-01-08 10:42:41 - initializing Kafka metrics collector
2025-01-08 10:42:41 - [Producer clientId=airlineServer-producer-1] Instantiated an idempotent producer.
2025-01-08 10:42:41 - Kafka version: 3.9.0
2025-01-08 10:42:41 - Kafka commitId: 84caaa6e9da06435
2025-01-08 10:42:41 - Kafka startTimeMs: 1736307761075
2025-01-08 10:42:41 - [Producer clientId=airlineServer-producer-1] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 10:42:41 - [Producer clientId=airlineServer-producer-1] ProducerId set to 8 with epoch 0
2025-01-08 10:42:42 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 10:44:30 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Revoke previously assigned partitions email-topic-0
2025-01-08 10:44:30 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Revoke previously assigned partitions ticket-cancel-0
2025-01-08 10:44:30 - email-group: partitions revoked: [email-topic-0]
2025-01-08 10:44:30 - ticket: partitions revoked: [ticket-cancel-0]
2025-01-08 10:44:30 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Member consumer-email-group-1-2f1ffeee-47c1-4eab-803c-fbc21d031012 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 10:44:30 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Member consumer-ticket-2-9a2e1ca7-d978-4c48-a009-4b6b8cc20be7 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 10:44:30 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 10:44:30 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 10:44:30 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 10:44:30 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 10:44:30 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 10:44:30 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 10:44:30 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 10:44:30 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 10:44:30 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 10:44:30 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 10:44:31 - Metrics scheduler closed
2025-01-08 10:44:31 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-08 10:44:31 - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-01-08 10:44:31 - Metrics reporters closed
2025-01-08 10:44:31 - App info kafka.consumer for consumer-email-group-1 unregistered
2025-01-08 10:44:31 - email-group: Consumer stopped
2025-01-08 10:44:31 - Metrics scheduler closed
2025-01-08 10:44:31 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-08 10:44:31 - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-01-08 10:44:31 - Metrics reporters closed
2025-01-08 10:44:31 - App info kafka.consumer for consumer-ticket-2 unregistered
2025-01-08 10:44:31 - ticket: Consumer stopped
2025-01-08 10:44:31 - Commencing graceful shutdown. Waiting for active requests to complete
2025-01-08 10:44:31 - Graceful shutdown complete
2025-01-08 10:44:31 - [Producer clientId=airlineServer-producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-01-08 10:44:31 - Metrics scheduler closed
2025-01-08 10:44:31 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-08 10:44:31 - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-01-08 10:44:31 - Metrics reporters closed
2025-01-08 10:44:31 - App info kafka.producer for airlineServer-producer-1 unregistered
2025-01-08 10:44:31 - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 10:44:31 - HikariPool-1 - Shutdown initiated...
2025-01-08 11:05:39 - Starting airlineServerApplication using Java 23.0.1 with PID 1684 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 11:05:39 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 11:05:39 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 11:05:40 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 11:05:40 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 11:05:40 - Finished Spring Data repository scanning in 101 ms. Found 10 JPA repository interfaces.
2025-01-08 11:05:40 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 11:05:40 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 11:05:40 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:05:40 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:05:40 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:05:40 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:05:40 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:05:40 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:05:40 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:05:40 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:05:40 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:05:40 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:05:40 - Finished Spring Data repository scanning in 18 ms. Found 0 Redis repository interfaces.
2025-01-08 11:05:40 - Tomcat initialized with port 8080 (http)
2025-01-08 11:05:40 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 11:05:40 - Starting service [Tomcat]
2025-01-08 11:05:40 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 11:05:40 - Initializing Spring embedded WebApplicationContext
2025-01-08 11:05:40 - Root WebApplicationContext: initialization completed in 1268 ms
2025-01-08 11:05:40 - HikariPool-1 - Starting...
2025-01-08 11:05:43 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@4fea5ee0
2025-01-08 11:05:43 - HikariPool-1 - Start completed.
2025-01-08 11:05:43 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 11:05:43 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 11:05:43 - HHH000026: Second-level cache disabled
2025-01-08 11:05:43 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 11:05:44 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 11:05:44 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 11:05:44 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 11:05:44 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 11:05:44 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 11:05:45 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 11:05:45 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 11:05:45 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 11:05:45 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 11:05:45 - Filter 'authenticationFilter' configured for use
2025-01-08 11:05:46 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 11:05:46 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 11:05:46 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-08 11:05:46 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 11:05:46 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-08 11:05:46 - Tomcat started on port 8080 (http) with context path '/'
2025-01-08 11:05:46 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ticket-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ticket
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:05:46 - initializing Kafka metrics collector
2025-01-08 11:05:46 - Kafka version: 3.9.0
2025-01-08 11:05:46 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:05:46 - Kafka startTimeMs: 1736309146919
2025-01-08 11:05:46 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Subscribed to topic(s): ticket-cancel
2025-01-08 11:05:46 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:05:46 - initializing Kafka metrics collector
2025-01-08 11:05:46 - Kafka version: 3.9.0
2025-01-08 11:05:46 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:05:46 - Kafka startTimeMs: 1736309146936
2025-01-08 11:05:46 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-08 11:05:46 - Started airlineServerApplication in 7.832 seconds (process running for 8.253)
2025-01-08 11:05:46 - airlineServerApplication started
2025-01-08 11:05:47 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:05:47 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:05:47 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:05:47 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:05:47 - [Consumer clientId=consumer-email-group-2, groupId=email-group] (Re-)joining group
2025-01-08 11:05:47 - [Consumer clientId=consumer-ticket-1, groupId=ticket] (Re-)joining group
2025-01-08 11:05:48 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-2-2273e595-93d8-4062-9fe0-e18fa2a89407
2025-01-08 11:05:48 - [Consumer clientId=consumer-email-group-2, groupId=email-group] (Re-)joining group
2025-01-08 11:05:48 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Request joining group due to: need to re-join with the given member-id: consumer-ticket-1-ce793ee4-51e4-4c8c-afba-bdf197cfecad
2025-01-08 11:05:48 - [Consumer clientId=consumer-ticket-1, groupId=ticket] (Re-)joining group
2025-01-08 11:05:48 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Successfully joined group with generation Generation{generationId=133, memberId='consumer-email-group-2-2273e595-93d8-4062-9fe0-e18fa2a89407', protocol='range'}
2025-01-08 11:05:49 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Successfully synced group in generation Generation{generationId=133, memberId='consumer-email-group-2-2273e595-93d8-4062-9fe0-e18fa2a89407', protocol='range'}
2025-01-08 11:05:49 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Notifying assignor about the new Assignment(partitions=[])
2025-01-08 11:05:49 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Adding newly assigned partitions: 
2025-01-08 11:05:49 - email-group: partitions assigned: []
2025-01-08 11:05:51 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Successfully joined group with generation Generation{generationId=7, memberId='consumer-ticket-1-ce793ee4-51e4-4c8c-afba-bdf197cfecad', protocol='range'}
2025-01-08 11:05:51 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Finished assignment for group at generation 7: {consumer-ticket-1-ce793ee4-51e4-4c8c-afba-bdf197cfecad=Assignment(partitions=[ticket-cancel-0])}
2025-01-08 11:05:51 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Successfully synced group in generation Generation{generationId=7, memberId='consumer-ticket-1-ce793ee4-51e4-4c8c-afba-bdf197cfecad', protocol='range'}
2025-01-08 11:05:51 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Notifying assignor about the new Assignment(partitions=[ticket-cancel-0])
2025-01-08 11:05:51 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Adding newly assigned partitions: ticket-cancel-0
2025-01-08 11:05:52 - Setting offset for partition ticket-cancel-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 11:05:52 - ticket: partitions assigned: [ticket-cancel-0]
2025-01-08 11:05:53 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-08 11:05:53 - Initializing Servlet 'dispatcherServlet'
2025-01-08 11:05:53 - Completed initialization in 2 ms
2025-01-08 11:05:53 - Securing POST /api/ticket
2025-01-08 11:05:53 - Secured POST /api/ticket
2025-01-08 11:05:53 - Start booking ticket with request: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@2aa0c898
2025-01-08 11:05:55 - Ticket booking successful. Ticket ID: 5a195cac9df74a50853678fe6248a546
2025-01-08 11:05:56 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:06:02 - Securing POST /api/ticket/5a195cac9df74a50853678fe6248a546/confirm
2025-01-08 11:06:02 - Secured POST /api/ticket/5a195cac9df74a50853678fe6248a546/confirm
2025-01-08 11:06:02 - Confirming ticket with ticketId=5a195cac9df74a50853678fe6248a546
2025-01-08 11:06:02 - Ticket booked. Ticket: com.airline.domain.ticket.model.Ticket@14022e51
2025-01-08 11:06:03 - Ticket with ticketId=5a195cac9df74a50853678fe6248a546 update available seats successfully for trainScheduleId=504b1c7c7b7b4a7cb2874cb8a57efdbb.
2025-01-08 11:06:08 - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [dqhdev.io.vn:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = airlineServer-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-01-08 11:06:08 - initializing Kafka metrics collector
2025-01-08 11:06:08 - [Producer clientId=airlineServer-producer-1] Instantiated an idempotent producer.
2025-01-08 11:06:08 - Kafka version: 3.9.0
2025-01-08 11:06:08 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:06:08 - Kafka startTimeMs: 1736309168665
2025-01-08 11:06:09 - [Producer clientId=airlineServer-producer-1] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:06:09 - [Producer clientId=airlineServer-producer-1] ProducerId set to 9 with epoch 0
2025-01-08 11:06:09 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:07:00 - Securing POST /api/ticket/5a195cac9df74a50853678fe6248a546/confirm
2025-01-08 11:07:00 - Secured POST /api/ticket/5a195cac9df74a50853678fe6248a546/confirm
2025-01-08 11:07:00 - Confirming ticket with ticketId=5a195cac9df74a50853678fe6248a546
2025-01-08 11:07:00 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:07:11 - Securing POST /api/ticket/5a195cac9df74a50853678fe6248a546/confirm
2025-01-08 11:07:11 - Secured POST /api/ticket/5a195cac9df74a50853678fe6248a546/confirm
2025-01-08 11:07:11 - Confirming ticket with ticketId=5a195cac9df74a50853678fe6248a546
2025-01-08 11:07:11 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:07:15 - Securing POST /api/ticket
2025-01-08 11:07:15 - Secured POST /api/ticket
2025-01-08 11:07:16 - Start booking ticket with request: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@74b94785
2025-01-08 11:07:19 - Ticket booking successful. Ticket ID: 105cf65dec794efb86adb686f4ef462e
2025-01-08 11:07:20 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:07:27 - Securing POST /api/ticket/105cf65dec794efb86adb686f4ef462e/confirm
2025-01-08 11:07:27 - Secured POST /api/ticket/105cf65dec794efb86adb686f4ef462e/confirm
2025-01-08 11:07:27 - Confirming ticket with ticketId=105cf65dec794efb86adb686f4ef462e
2025-01-08 11:07:27 - Ticket booked. Ticket: com.airline.domain.ticket.model.Ticket@1428e883
2025-01-08 11:07:29 - Ticket with ticketId=105cf65dec794efb86adb686f4ef462e update available seats successfully for trainScheduleId=504b1c7c7b7b4a7cb2874cb8a57efdbb.
2025-01-08 11:07:33 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:09:55 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Member consumer-email-group-2-2273e595-93d8-4062-9fe0-e18fa2a89407 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:09:55 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Revoke previously assigned partitions ticket-cancel-0
2025-01-08 11:09:55 - ticket: partitions revoked: [ticket-cancel-0]
2025-01-08 11:09:55 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:09:55 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:09:55 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:09:55 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Member consumer-ticket-1-ce793ee4-51e4-4c8c-afba-bdf197cfecad sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:09:55 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:09:55 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:09:55 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:09:55 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:09:55 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:09:55 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:09:55 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:10:43 - Starting airlineServerApplication using Java 23.0.1 with PID 10892 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 11:10:43 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 11:10:43 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 11:10:44 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 11:10:44 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 11:10:44 - Finished Spring Data repository scanning in 83 ms. Found 10 JPA repository interfaces.
2025-01-08 11:10:44 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 11:10:44 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 11:10:44 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:10:44 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:10:44 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:10:44 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:10:44 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:10:44 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:10:44 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:10:44 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:10:44 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:10:44 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:10:44 - Finished Spring Data repository scanning in 16 ms. Found 0 Redis repository interfaces.
2025-01-08 11:10:45 - Tomcat initialized with port 8080 (http)
2025-01-08 11:10:45 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 11:10:45 - Starting service [Tomcat]
2025-01-08 11:10:45 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 11:10:45 - Initializing Spring embedded WebApplicationContext
2025-01-08 11:10:45 - Root WebApplicationContext: initialization completed in 1197 ms
2025-01-08 11:10:45 - HikariPool-1 - Starting...
2025-01-08 11:10:47 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@655909e2
2025-01-08 11:10:47 - HikariPool-1 - Start completed.
2025-01-08 11:10:47 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 11:10:47 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 11:10:47 - HHH000026: Second-level cache disabled
2025-01-08 11:10:47 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 11:10:47 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 11:10:47 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 11:10:47 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 11:10:48 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 11:10:48 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 11:10:48 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 11:10:49 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 11:10:49 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 11:10:49 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 11:10:49 - Filter 'authenticationFilter' configured for use
2025-01-08 11:10:50 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 11:10:50 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 11:10:50 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-08 11:10:50 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 11:10:50 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-08 11:10:50 - Tomcat started on port 8080 (http) with context path '/'
2025-01-08 11:10:50 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ticket-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ticket
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:10:50 - initializing Kafka metrics collector
2025-01-08 11:10:50 - Kafka version: 3.9.0
2025-01-08 11:10:50 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:10:50 - Kafka startTimeMs: 1736309450687
2025-01-08 11:10:50 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Subscribed to topic(s): ticket-cancel
2025-01-08 11:10:50 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:10:50 - initializing Kafka metrics collector
2025-01-08 11:10:50 - Kafka version: 3.9.0
2025-01-08 11:10:50 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:10:50 - Kafka startTimeMs: 1736309450705
2025-01-08 11:10:50 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-08 11:10:50 - Started airlineServerApplication in 7.057 seconds (process running for 7.418)
2025-01-08 11:10:50 - airlineServerApplication started
2025-01-08 11:10:51 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:10:51 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:10:51 - [Consumer clientId=consumer-ticket-1, groupId=ticket] (Re-)joining group
2025-01-08 11:10:51 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:10:51 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:10:51 - [Consumer clientId=consumer-email-group-2, groupId=email-group] (Re-)joining group
2025-01-08 11:10:53 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-2-f661ccf3-aa03-40e1-8242-2cc914c857c3
2025-01-08 11:10:53 - [Consumer clientId=consumer-email-group-2, groupId=email-group] (Re-)joining group
2025-01-08 11:10:53 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Request joining group due to: need to re-join with the given member-id: consumer-ticket-1-cec8313d-d8e6-4f8c-87b0-3dd86cef3038
2025-01-08 11:10:53 - [Consumer clientId=consumer-ticket-1, groupId=ticket] (Re-)joining group
2025-01-08 11:10:55 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Successfully joined group with generation Generation{generationId=135, memberId='consumer-email-group-2-f661ccf3-aa03-40e1-8242-2cc914c857c3', protocol='range'}
2025-01-08 11:10:55 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Successfully synced group in generation Generation{generationId=135, memberId='consumer-email-group-2-f661ccf3-aa03-40e1-8242-2cc914c857c3', protocol='range'}
2025-01-08 11:10:55 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Notifying assignor about the new Assignment(partitions=[])
2025-01-08 11:10:55 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Adding newly assigned partitions: 
2025-01-08 11:10:55 - email-group: partitions assigned: []
2025-01-08 11:10:56 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Successfully joined group with generation Generation{generationId=9, memberId='consumer-ticket-1-cec8313d-d8e6-4f8c-87b0-3dd86cef3038', protocol='range'}
2025-01-08 11:10:56 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Finished assignment for group at generation 9: {consumer-ticket-1-cec8313d-d8e6-4f8c-87b0-3dd86cef3038=Assignment(partitions=[ticket-cancel-0])}
2025-01-08 11:10:56 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Successfully synced group in generation Generation{generationId=9, memberId='consumer-ticket-1-cec8313d-d8e6-4f8c-87b0-3dd86cef3038', protocol='range'}
2025-01-08 11:10:56 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Notifying assignor about the new Assignment(partitions=[ticket-cancel-0])
2025-01-08 11:10:56 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Adding newly assigned partitions: ticket-cancel-0
2025-01-08 11:10:57 - Setting offset for partition ticket-cancel-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 11:10:57 - ticket: partitions assigned: [ticket-cancel-0]
2025-01-08 11:11:07 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-08 11:11:07 - Initializing Servlet 'dispatcherServlet'
2025-01-08 11:11:07 - Completed initialization in 1 ms
2025-01-08 11:11:07 - Securing POST /api/ticket
2025-01-08 11:11:07 - Secured POST /api/ticket
2025-01-08 11:11:09 - Start booking ticket with request: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@4054fde4
2025-01-08 11:11:12 - Ticket booking successful. Ticket ID: 217201521e114805984462c865c33968
2025-01-08 11:11:14 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:11:19 - Securing POST /api/ticket/217201521e114805984462c865c33968/confirm
2025-01-08 11:11:19 - Secured POST /api/ticket/217201521e114805984462c865c33968/confirm
2025-01-08 11:11:19 - Confirming ticket with ticketId=217201521e114805984462c865c33968
2025-01-08 11:11:21 - Ticket booked. Ticket: com.airline.domain.ticket.model.Ticket@462929b2
2025-01-08 11:11:22 - Ticket with ticketId=217201521e114805984462c865c33968 update available seats successfully for trainScheduleId=504b1c7c7b7b4a7cb2874cb8a57efdbb.
2025-01-08 11:11:30 - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [dqhdev.io.vn:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = airlineServer-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-01-08 11:11:30 - initializing Kafka metrics collector
2025-01-08 11:11:30 - [Producer clientId=airlineServer-producer-1] Instantiated an idempotent producer.
2025-01-08 11:11:30 - Kafka version: 3.9.0
2025-01-08 11:11:30 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:11:30 - Kafka startTimeMs: 1736309490324
2025-01-08 11:11:30 - [Producer clientId=airlineServer-producer-1] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:11:30 - [Producer clientId=airlineServer-producer-1] ProducerId set to 10 with epoch 0
2025-01-08 11:11:31 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:13:40 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Member consumer-email-group-2-f661ccf3-aa03-40e1-8242-2cc914c857c3 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:13:40 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Revoke previously assigned partitions ticket-cancel-0
2025-01-08 11:13:40 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:13:40 - ticket: partitions revoked: [ticket-cancel-0]
2025-01-08 11:13:40 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:13:40 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:13:40 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Member consumer-ticket-1-cec8313d-d8e6-4f8c-87b0-3dd86cef3038 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:13:40 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:13:40 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:13:40 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:13:40 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:13:40 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:13:40 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:13:40 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:22:31 - Starting airlineServerApplication using Java 23.0.1 with PID 9316 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 11:22:31 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 11:22:31 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 11:22:31 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 11:22:31 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 11:22:31 - Finished Spring Data repository scanning in 80 ms. Found 10 JPA repository interfaces.
2025-01-08 11:22:31 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 11:22:31 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 11:22:31 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:22:31 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:22:31 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:22:31 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:22:31 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:22:31 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:22:31 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:22:31 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:22:31 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:22:31 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:22:31 - Finished Spring Data repository scanning in 17 ms. Found 0 Redis repository interfaces.
2025-01-08 11:22:32 - Tomcat initialized with port 8080 (http)
2025-01-08 11:22:32 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 11:22:32 - Starting service [Tomcat]
2025-01-08 11:22:32 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 11:22:32 - Initializing Spring embedded WebApplicationContext
2025-01-08 11:22:32 - Root WebApplicationContext: initialization completed in 1157 ms
2025-01-08 11:22:32 - HikariPool-1 - Starting...
2025-01-08 11:22:34 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@32f308c6
2025-01-08 11:22:34 - HikariPool-1 - Start completed.
2025-01-08 11:22:34 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 11:22:34 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 11:22:34 - HHH000026: Second-level cache disabled
2025-01-08 11:22:34 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 11:22:34 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 11:22:34 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 11:22:34 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 11:22:35 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 11:22:35 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 11:22:35 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 11:22:36 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 11:22:36 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 11:22:36 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 11:22:36 - Filter 'authenticationFilter' configured for use
2025-01-08 11:22:36 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 11:22:36 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 11:22:37 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration': Injection of autowired dependencies failed
2025-01-08 11:22:37 - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 11:22:37 - HikariPool-1 - Shutdown initiated...
2025-01-08 11:22:37 - HikariPool-1 - Shutdown completed.
2025-01-08 11:22:37 - Stopping service [Tomcat]
2025-01-08 11:22:37 - 

Error starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled.
2025-01-08 11:22:37 - Application run failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration': Injection of autowired dependencies failed
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:515)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1435)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:600)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.instantiateSingleton(DefaultListableBeanFactory.java:1122)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingleton(DefaultListableBeanFactory.java:1093)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:1030)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:987)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:627)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.airline.AirLineServerApplication.main(airlineServerApplication.java:11)
Caused by: java.lang.RuntimeException: Could not postProcess org.springframework.security.config.annotation.web.builders.WebSecurity@5ebe1552 of type class org.springframework.security.config.annotation.web.builders.WebSecurity
	at org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor.postProcess(AutowireBeanFactoryObjectPostProcessor.java:71)
	at org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration.setFilterChainProxySecurityConfigurer(WebSecurityConfiguration.java:148)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:854)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:146)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:509)
	... 19 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'mvcHandlerMappingIntrospectorRequestTransformer': Cannot resolve reference to bean 'mvcHandlerMappingIntrospector' while setting constructor argument
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:377)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:135)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:691)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:206)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1371)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1208)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:224)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveNamedBean(DefaultListableBeanFactory.java:1484)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveNamedBean(DefaultListableBeanFactory.java:1445)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveBean(DefaultListableBeanFactory.java:516)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory$1.getIfUnique(DefaultListableBeanFactory.java:468)
	at org.springframework.security.config.annotation.web.builders.WebSecurity.setApplicationContext(WebSecurity.java:420)
	at org.springframework.context.support.ApplicationContextAwareProcessor.invokeAwareInterfaces(ApplicationContextAwareProcessor.java:110)
	at org.springframework.context.support.ApplicationContextAwareProcessor.postProcessBeforeInitialization(ApplicationContextAwareProcessor.java:85)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:423)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1794)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:413)
	at org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor.initializeBeanIfNeeded(AutowireBeanFactoryObjectPostProcessor.java:98)
	at org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor.postProcess(AutowireBeanFactoryObjectPostProcessor.java:67)
	... 25 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'mvcHandlerMappingIntrospector' defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration$EnableWebMvcConfiguration.class]: Error creating bean with name 'requestMappingHandlerMapping' defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration$EnableWebMvcConfiguration.class]: Ambiguous mapping. Cannot map 'helloWord' method 
com.airline.presentation.HelloWord#send()
to {POST [/email]}: There is already 'helloWord' bean method
com.airline.presentation.HelloWord#email() mapped.
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1802)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:601)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:365)
	... 48 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'requestMappingHandlerMapping' defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration$EnableWebMvcConfiguration.class]: Ambiguous mapping. Cannot map 'helloWord' method 
com.airline.presentation.HelloWord#send()
to {POST [/email]}: There is already 'helloWord' bean method
com.airline.presentation.HelloWord#email() mapped.
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1802)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:601)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:695)
	at org.springframework.context.support.AbstractApplicationContext.getBeansOfType(AbstractApplicationContext.java:1426)
	at org.springframework.beans.factory.BeanFactoryUtils.beansOfTypeIncludingAncestors(BeanFactoryUtils.java:368)
	at org.springframework.web.servlet.handler.HandlerMappingIntrospector.initHandlerMappings(HandlerMappingIntrospector.java:135)
	at org.springframework.web.servlet.handler.HandlerMappingIntrospector.afterPropertiesSet(HandlerMappingIntrospector.java:123)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1849)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1798)
	... 55 common frames omitted
Caused by: java.lang.IllegalStateException: Ambiguous mapping. Cannot map 'helloWord' method 
com.airline.presentation.HelloWord#send()
to {POST [/email]}: There is already 'helloWord' bean method
com.airline.presentation.HelloWord#email() mapped.
	at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry.validateMethodMapping(AbstractHandlerMethodMapping.java:675)
	at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry.register(AbstractHandlerMethodMapping.java:637)
	at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.registerHandlerMethod(AbstractHandlerMethodMapping.java:331)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping.registerHandlerMethod(RequestMappingHandlerMapping.java:509)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping.registerHandlerMethod(RequestMappingHandlerMapping.java:84)
	at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.lambda$detectHandlerMethods$2(AbstractHandlerMethodMapping.java:298)
	at java.base/java.util.LinkedHashMap.forEach(LinkedHashMap.java:987)
	at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.detectHandlerMethods(AbstractHandlerMethodMapping.java:296)
	at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.processCandidateBean(AbstractHandlerMethodMapping.java:265)
	at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.initHandlerMethods(AbstractHandlerMethodMapping.java:224)
	at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.afterPropertiesSet(AbstractHandlerMethodMapping.java:212)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping.afterPropertiesSet(RequestMappingHandlerMapping.java:239)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1849)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1798)
	... 68 common frames omitted
2025-01-08 11:23:01 - Starting airlineServerApplication using Java 23.0.1 with PID 11636 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 11:23:01 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 11:23:01 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 11:23:01 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 11:23:01 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 11:23:01 - Finished Spring Data repository scanning in 85 ms. Found 10 JPA repository interfaces.
2025-01-08 11:23:01 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 11:23:01 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 11:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:23:01 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:23:01 - Finished Spring Data repository scanning in 17 ms. Found 0 Redis repository interfaces.
2025-01-08 11:23:02 - Tomcat initialized with port 8080 (http)
2025-01-08 11:23:02 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 11:23:02 - Starting service [Tomcat]
2025-01-08 11:23:02 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 11:23:02 - Initializing Spring embedded WebApplicationContext
2025-01-08 11:23:02 - Root WebApplicationContext: initialization completed in 1203 ms
2025-01-08 11:23:02 - HikariPool-1 - Starting...
2025-01-08 11:23:04 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@32f308c6
2025-01-08 11:23:04 - HikariPool-1 - Start completed.
2025-01-08 11:23:04 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 11:23:04 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 11:23:04 - HHH000026: Second-level cache disabled
2025-01-08 11:23:04 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 11:23:04 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 11:23:04 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 11:23:04 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 11:23:05 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 11:23:05 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 11:23:05 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 11:23:06 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 11:23:06 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 11:23:06 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 11:23:06 - Filter 'authenticationFilter' configured for use
2025-01-08 11:23:06 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 11:23:06 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 11:23:07 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-08 11:23:07 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 11:23:07 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-08 11:23:07 - Tomcat started on port 8080 (http) with context path '/'
2025-01-08 11:23:07 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:23:07 - initializing Kafka metrics collector
2025-01-08 11:23:07 - Kafka version: 3.9.0
2025-01-08 11:23:07 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:23:07 - Kafka startTimeMs: 1736310187500
2025-01-08 11:23:07 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-08 11:23:07 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ticket-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ticket
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:23:07 - initializing Kafka metrics collector
2025-01-08 11:23:07 - Kafka version: 3.9.0
2025-01-08 11:23:07 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:23:07 - Kafka startTimeMs: 1736310187523
2025-01-08 11:23:07 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Subscribed to topic(s): ticket-cancel
2025-01-08 11:23:07 - Started airlineServerApplication in 6.661 seconds (process running for 7.039)
2025-01-08 11:23:07 - airlineServerApplication started
2025-01-08 11:23:08 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:23:08 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:23:08 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 11:23:08 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:23:08 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:23:08 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 11:23:08 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-1-dcf6c662-ca14-47f8-afa4-2ebee76da80c
2025-01-08 11:23:08 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 11:23:08 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: need to re-join with the given member-id: consumer-ticket-2-2da69831-63a6-4744-8aad-ff31a3b25051
2025-01-08 11:23:08 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 11:23:10 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully joined group with generation Generation{generationId=137, memberId='consumer-email-group-1-dcf6c662-ca14-47f8-afa4-2ebee76da80c', protocol='range'}
2025-01-08 11:23:10 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully synced group in generation Generation{generationId=137, memberId='consumer-email-group-1-dcf6c662-ca14-47f8-afa4-2ebee76da80c', protocol='range'}
2025-01-08 11:23:10 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Notifying assignor about the new Assignment(partitions=[])
2025-01-08 11:23:10 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Adding newly assigned partitions: 
2025-01-08 11:23:10 - email-group: partitions assigned: []
2025-01-08 11:23:12 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully joined group with generation Generation{generationId=11, memberId='consumer-ticket-2-2da69831-63a6-4744-8aad-ff31a3b25051', protocol='range'}
2025-01-08 11:23:12 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Finished assignment for group at generation 11: {consumer-ticket-2-2da69831-63a6-4744-8aad-ff31a3b25051=Assignment(partitions=[ticket-cancel-0])}
2025-01-08 11:23:12 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully synced group in generation Generation{generationId=11, memberId='consumer-ticket-2-2da69831-63a6-4744-8aad-ff31a3b25051', protocol='range'}
2025-01-08 11:23:12 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Notifying assignor about the new Assignment(partitions=[ticket-cancel-0])
2025-01-08 11:23:12 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Adding newly assigned partitions: ticket-cancel-0
2025-01-08 11:23:12 - Setting offset for partition ticket-cancel-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 11:23:12 - ticket: partitions assigned: [ticket-cancel-0]
2025-01-08 11:23:13 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-08 11:23:13 - Initializing Servlet 'dispatcherServlet'
2025-01-08 11:23:13 - Completed initialization in 1 ms
2025-01-08 11:23:13 - Securing GET /emaill
2025-01-08 11:23:13 - Secured GET /emaill
2025-01-08 11:23:13 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:23:13 - Securing GET /error
2025-01-08 11:23:13 - Secured GET /error
2025-01-08 11:23:13 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:23:16 - Securing POST /emaill
2025-01-08 11:23:16 - Secured POST /emaill
2025-01-08 11:23:16 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:23:16 - Securing POST /error
2025-01-08 11:23:16 - Secured POST /error
2025-01-08 11:23:16 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:23:25 - Securing POST /emailL
2025-01-08 11:23:25 - Secured POST /emailL
2025-01-08 11:23:25 - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [dqhdev.io.vn:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = airlineServer-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-01-08 11:23:25 - initializing Kafka metrics collector
2025-01-08 11:23:25 - [Producer clientId=airlineServer-producer-1] Instantiated an idempotent producer.
2025-01-08 11:23:25 - Kafka version: 3.9.0
2025-01-08 11:23:25 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:23:25 - Kafka startTimeMs: 1736310205508
2025-01-08 11:23:26 - [Producer clientId=airlineServer-producer-1] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:23:26 - [Producer clientId=airlineServer-producer-1] ProducerId set to 11 with epoch 0
2025-01-08 11:23:26 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:25:47 - Securing POST /emailL
2025-01-08 11:25:47 - Secured POST /emailL
2025-01-08 11:25:47 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:26:08 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Member consumer-email-group-1-dcf6c662-ca14-47f8-afa4-2ebee76da80c sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:26:08 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Revoke previously assigned partitions ticket-cancel-0
2025-01-08 11:26:08 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:26:08 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:26:08 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:26:08 - ticket: partitions revoked: [ticket-cancel-0]
2025-01-08 11:26:08 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Member consumer-ticket-2-2da69831-63a6-4744-8aad-ff31a3b25051 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:26:08 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:26:08 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:26:08 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:26:08 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:26:08 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:26:08 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:26:08 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:27:06 - Starting airlineServerApplication using Java 23.0.1 with PID 13424 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 11:27:06 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 11:27:06 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 11:27:06 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 11:27:06 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 11:27:06 - Finished Spring Data repository scanning in 80 ms. Found 10 JPA repository interfaces.
2025-01-08 11:27:06 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 11:27:06 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 11:27:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:27:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:27:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:27:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:27:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:27:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:27:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:27:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:27:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:27:06 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:27:06 - Finished Spring Data repository scanning in 19 ms. Found 0 Redis repository interfaces.
2025-01-08 11:27:07 - Tomcat initialized with port 8080 (http)
2025-01-08 11:27:07 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 11:27:07 - Starting service [Tomcat]
2025-01-08 11:27:07 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 11:27:07 - Initializing Spring embedded WebApplicationContext
2025-01-08 11:27:07 - Root WebApplicationContext: initialization completed in 1206 ms
2025-01-08 11:27:07 - HikariPool-1 - Starting...
2025-01-08 11:27:09 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@445058e8
2025-01-08 11:27:09 - HikariPool-1 - Start completed.
2025-01-08 11:27:09 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 11:27:09 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 11:27:09 - HHH000026: Second-level cache disabled
2025-01-08 11:27:09 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 11:27:09 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 11:27:09 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 11:27:09 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 11:27:10 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 11:27:10 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 11:27:10 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 11:27:11 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 11:27:11 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 11:27:11 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 11:27:11 - Filter 'authenticationFilter' configured for use
2025-01-08 11:27:11 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 11:27:11 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 11:27:12 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-08 11:27:12 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 11:27:12 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-08 11:27:12 - Tomcat started on port 8080 (http) with context path '/'
2025-01-08 11:27:12 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ticket-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ticket
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:27:12 - initializing Kafka metrics collector
2025-01-08 11:27:12 - Kafka version: 3.9.0
2025-01-08 11:27:12 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:27:12 - Kafka startTimeMs: 1736310432608
2025-01-08 11:27:12 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Subscribed to topic(s): ticket-cancel
2025-01-08 11:27:12 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:27:12 - initializing Kafka metrics collector
2025-01-08 11:27:12 - Kafka version: 3.9.0
2025-01-08 11:27:12 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:27:12 - Kafka startTimeMs: 1736310432623
2025-01-08 11:27:12 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-08 11:27:12 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:27:12 - initializing Kafka metrics collector
2025-01-08 11:27:12 - Kafka version: 3.9.0
2025-01-08 11:27:12 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:27:12 - Kafka startTimeMs: 1736310432630
2025-01-08 11:27:12 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Subscribed to topic(s): test
2025-01-08 11:27:12 - Started airlineServerApplication in 6.732 seconds (process running for 7.104)
2025-01-08 11:27:12 - airlineServerApplication started
2025-01-08 11:27:13 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:27:13 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:27:13 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:27:13 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:27:13 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:27:13 - [Consumer clientId=consumer-ticket-1, groupId=ticket] (Re-)joining group
2025-01-08 11:27:13 - [Consumer clientId=consumer-email-group-3, groupId=email-group] (Re-)joining group
2025-01-08 11:27:13 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:27:13 - [Consumer clientId=consumer-email-group-2, groupId=email-group] (Re-)joining group
2025-01-08 11:27:14 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-2-54f18535-da8b-464f-bce8-593517841423
2025-01-08 11:27:14 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-3-33301e70-fe0b-4aee-8ee5-ab07392ac985
2025-01-08 11:27:14 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Request joining group due to: need to re-join with the given member-id: consumer-ticket-1-3395945d-55bc-491f-81e9-908c039be090
2025-01-08 11:27:14 - [Consumer clientId=consumer-email-group-2, groupId=email-group] (Re-)joining group
2025-01-08 11:27:14 - [Consumer clientId=consumer-ticket-1, groupId=ticket] (Re-)joining group
2025-01-08 11:27:14 - [Consumer clientId=consumer-email-group-3, groupId=email-group] (Re-)joining group
2025-01-08 11:27:16 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Successfully joined group with generation Generation{generationId=139, memberId='consumer-email-group-3-33301e70-fe0b-4aee-8ee5-ab07392ac985', protocol='range'}
2025-01-08 11:27:16 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Successfully joined group with generation Generation{generationId=139, memberId='consumer-email-group-2-54f18535-da8b-464f-bce8-593517841423', protocol='range'}
2025-01-08 11:27:16 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Successfully synced group in generation Generation{generationId=139, memberId='consumer-email-group-2-54f18535-da8b-464f-bce8-593517841423', protocol='range'}
2025-01-08 11:27:16 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Successfully synced group in generation Generation{generationId=139, memberId='consumer-email-group-3-33301e70-fe0b-4aee-8ee5-ab07392ac985', protocol='range'}
2025-01-08 11:27:16 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Notifying assignor about the new Assignment(partitions=[test-0])
2025-01-08 11:27:16 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Notifying assignor about the new Assignment(partitions=[])
2025-01-08 11:27:16 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Adding newly assigned partitions: 
2025-01-08 11:27:16 - email-group: partitions assigned: []
2025-01-08 11:27:16 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Adding newly assigned partitions: test-0
2025-01-08 11:27:16 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Found no committed offset for partition test-0
2025-01-08 11:27:16 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Found no committed offset for partition test-0
2025-01-08 11:27:17 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Successfully joined group with generation Generation{generationId=13, memberId='consumer-ticket-1-3395945d-55bc-491f-81e9-908c039be090', protocol='range'}
2025-01-08 11:27:17 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Finished assignment for group at generation 13: {consumer-ticket-1-3395945d-55bc-491f-81e9-908c039be090=Assignment(partitions=[ticket-cancel-0])}
2025-01-08 11:27:17 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Successfully synced group in generation Generation{generationId=13, memberId='consumer-ticket-1-3395945d-55bc-491f-81e9-908c039be090', protocol='range'}
2025-01-08 11:27:17 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Notifying assignor about the new Assignment(partitions=[ticket-cancel-0])
2025-01-08 11:27:17 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Adding newly assigned partitions: ticket-cancel-0
2025-01-08 11:27:17 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Resetting offset for partition test-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}.
2025-01-08 11:27:18 - email-group: partitions assigned: [test-0]
2025-01-08 11:27:18 - Setting offset for partition ticket-cancel-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 11:27:18 - ticket: partitions assigned: [ticket-cancel-0]
2025-01-08 11:27:19 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-08 11:27:19 - Initializing Servlet 'dispatcherServlet'
2025-01-08 11:27:19 - Completed initialization in 2 ms
2025-01-08 11:27:19 - Securing POST /emailL
2025-01-08 11:27:19 - Secured POST /emailL
2025-01-08 11:27:19 - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [dqhdev.io.vn:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = airlineServer-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-01-08 11:27:19 - initializing Kafka metrics collector
2025-01-08 11:27:19 - [Producer clientId=airlineServer-producer-1] Instantiated an idempotent producer.
2025-01-08 11:27:19 - Kafka version: 3.9.0
2025-01-08 11:27:19 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:27:19 - Kafka startTimeMs: 1736310439175
2025-01-08 11:27:19 - [Producer clientId=airlineServer-producer-1] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:27:19 - [Producer clientId=airlineServer-producer-1] ProducerId set to 12 with epoch 0
2025-01-08 11:27:20 - Received test message hii
2025-01-08 11:27:20 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:27:29 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Member consumer-email-group-2-54f18535-da8b-464f-bce8-593517841423 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:27:29 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Revoke previously assigned partitions ticket-cancel-0
2025-01-08 11:27:29 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Revoke previously assigned partitions test-0
2025-01-08 11:27:29 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:27:29 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:27:29 - email-group: partitions revoked: [test-0]
2025-01-08 11:27:29 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:27:29 - ticket: partitions revoked: [ticket-cancel-0]
2025-01-08 11:27:29 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Member consumer-email-group-3-33301e70-fe0b-4aee-8ee5-ab07392ac985 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:27:29 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Member consumer-ticket-1-3395945d-55bc-491f-81e9-908c039be090 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:27:29 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:27:29 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:27:29 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:27:29 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:27:29 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:27:29 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:27:29 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:27:29 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:27:29 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:27:29 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:27:29 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:27:29 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:28:00 - Starting airlineServerApplication using Java 23.0.1 with PID 23256 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 11:28:00 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 11:28:00 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 11:28:00 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 11:28:00 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 11:28:00 - Finished Spring Data repository scanning in 98 ms. Found 10 JPA repository interfaces.
2025-01-08 11:28:00 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 11:28:00 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 11:28:00 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:00 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:00 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:00 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:00 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:00 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:00 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:00 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:00 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:00 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:00 - Finished Spring Data repository scanning in 22 ms. Found 0 Redis repository interfaces.
2025-01-08 11:28:01 - Tomcat initialized with port 8080 (http)
2025-01-08 11:28:01 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 11:28:01 - Starting service [Tomcat]
2025-01-08 11:28:01 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 11:28:01 - Initializing Spring embedded WebApplicationContext
2025-01-08 11:28:01 - Root WebApplicationContext: initialization completed in 1312 ms
2025-01-08 11:28:01 - HikariPool-1 - Starting...
2025-01-08 11:28:03 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@25d9291a
2025-01-08 11:28:03 - HikariPool-1 - Start completed.
2025-01-08 11:28:03 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 11:28:03 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 11:28:03 - HHH000026: Second-level cache disabled
2025-01-08 11:28:03 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 11:28:03 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 11:28:03 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 11:28:03 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 11:28:04 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 11:28:04 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 11:28:04 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 11:28:05 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 11:28:05 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 11:28:05 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 11:28:05 - Filter 'authenticationFilter' configured for use
2025-01-08 11:28:06 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 11:28:06 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 11:28:06 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-08 11:28:06 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 11:28:06 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-08 11:28:06 - Tomcat started on port 8080 (http) with context path '/'
2025-01-08 11:28:06 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:28:06 - initializing Kafka metrics collector
2025-01-08 11:28:06 - Kafka version: 3.9.0
2025-01-08 11:28:06 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:28:06 - Kafka startTimeMs: 1736310486724
2025-01-08 11:28:06 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Subscribed to topic(s): test
2025-01-08 11:28:06 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:28:06 - initializing Kafka metrics collector
2025-01-08 11:28:06 - Kafka version: 3.9.0
2025-01-08 11:28:06 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:28:06 - Kafka startTimeMs: 1736310486739
2025-01-08 11:28:06 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-08 11:28:06 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ticket-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ticket
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:28:06 - initializing Kafka metrics collector
2025-01-08 11:28:06 - Kafka version: 3.9.0
2025-01-08 11:28:06 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:28:06 - Kafka startTimeMs: 1736310486747
2025-01-08 11:28:06 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Subscribed to topic(s): ticket-cancel
2025-01-08 11:28:06 - Started airlineServerApplication in 6.986 seconds (process running for 7.399)
2025-01-08 11:28:06 - airlineServerApplication started
2025-01-08 11:28:08 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:28:08 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:28:08 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:28:08 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:28:08 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 11:28:08 - [Consumer clientId=consumer-email-group-2, groupId=email-group] (Re-)joining group
2025-01-08 11:28:08 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:28:08 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:28:08 - [Consumer clientId=consumer-ticket-3, groupId=ticket] (Re-)joining group
2025-01-08 11:28:09 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Request joining group due to: need to re-join with the given member-id: consumer-ticket-3-217455a6-cb2a-4183-98ad-a294933e164b
2025-01-08 11:28:09 - [Consumer clientId=consumer-ticket-3, groupId=ticket] (Re-)joining group
2025-01-08 11:28:09 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-2-37e6fd02-6e30-4c9b-bea9-e99b5692c246
2025-01-08 11:28:09 - [Consumer clientId=consumer-email-group-2, groupId=email-group] (Re-)joining group
2025-01-08 11:28:09 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-1-c14e0d84-08d2-4e76-b20f-1e5ec1d50aaa
2025-01-08 11:28:09 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 11:28:10 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully joined group with generation Generation{generationId=141, memberId='consumer-email-group-1-c14e0d84-08d2-4e76-b20f-1e5ec1d50aaa', protocol='range'}
2025-01-08 11:28:10 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Successfully joined group with generation Generation{generationId=141, memberId='consumer-email-group-2-37e6fd02-6e30-4c9b-bea9-e99b5692c246', protocol='range'}
2025-01-08 11:28:10 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully synced group in generation Generation{generationId=141, memberId='consumer-email-group-1-c14e0d84-08d2-4e76-b20f-1e5ec1d50aaa', protocol='range'}
2025-01-08 11:28:10 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Notifying assignor about the new Assignment(partitions=[test-0])
2025-01-08 11:28:10 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Adding newly assigned partitions: test-0
2025-01-08 11:28:10 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Successfully synced group in generation Generation{generationId=141, memberId='consumer-email-group-2-37e6fd02-6e30-4c9b-bea9-e99b5692c246', protocol='range'}
2025-01-08 11:28:10 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Notifying assignor about the new Assignment(partitions=[])
2025-01-08 11:28:10 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Adding newly assigned partitions: 
2025-01-08 11:28:10 - email-group: partitions assigned: []
2025-01-08 11:28:10 - Setting offset for partition test-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 11:28:10 - email-group: partitions assigned: [test-0]
2025-01-08 11:28:12 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-08 11:28:12 - Initializing Servlet 'dispatcherServlet'
2025-01-08 11:28:12 - Completed initialization in 2 ms
2025-01-08 11:28:12 - Securing POST /emailL
2025-01-08 11:28:12 - Secured POST /emailL
2025-01-08 11:28:12 - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [dqhdev.io.vn:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = airlineServer-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-01-08 11:28:12 - initializing Kafka metrics collector
2025-01-08 11:28:12 - [Producer clientId=airlineServer-producer-1] Instantiated an idempotent producer.
2025-01-08 11:28:12 - Kafka version: 3.9.0
2025-01-08 11:28:12 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:28:12 - Kafka startTimeMs: 1736310492453
2025-01-08 11:28:12 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Successfully joined group with generation Generation{generationId=15, memberId='consumer-ticket-3-217455a6-cb2a-4183-98ad-a294933e164b', protocol='range'}
2025-01-08 11:28:12 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Finished assignment for group at generation 15: {consumer-ticket-3-217455a6-cb2a-4183-98ad-a294933e164b=Assignment(partitions=[ticket-cancel-0])}
2025-01-08 11:28:12 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Successfully synced group in generation Generation{generationId=15, memberId='consumer-ticket-3-217455a6-cb2a-4183-98ad-a294933e164b', protocol='range'}
2025-01-08 11:28:12 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Notifying assignor about the new Assignment(partitions=[ticket-cancel-0])
2025-01-08 11:28:12 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Adding newly assigned partitions: ticket-cancel-0
2025-01-08 11:28:13 - [Producer clientId=airlineServer-producer-1] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:28:13 - [Producer clientId=airlineServer-producer-1] ProducerId set to 13 with epoch 0
2025-01-08 11:28:13 - Setting offset for partition ticket-cancel-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 11:28:13 - ticket: partitions assigned: [ticket-cancel-0]
2025-01-08 11:28:13 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:28:14 - Received test message com.airline.infrastructure.dataTransferObject.request.EmailRequest@5d349c54
2025-01-08 11:28:32 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Member consumer-email-group-2-37e6fd02-6e30-4c9b-bea9-e99b5692c246 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:28:32 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Revoke previously assigned partitions ticket-cancel-0
2025-01-08 11:28:32 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Revoke previously assigned partitions test-0
2025-01-08 11:28:32 - ticket: partitions revoked: [ticket-cancel-0]
2025-01-08 11:28:32 - email-group: partitions revoked: [test-0]
2025-01-08 11:28:32 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:28:32 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:28:32 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Member consumer-ticket-3-217455a6-cb2a-4183-98ad-a294933e164b sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:28:32 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:28:32 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Member consumer-email-group-1-c14e0d84-08d2-4e76-b20f-1e5ec1d50aaa sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:28:32 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:28:32 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:28:32 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:28:32 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:28:32 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:28:32 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:28:32 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:28:32 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:28:32 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:28:32 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:28:32 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:28:32 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:28:33 - Metrics scheduler closed
2025-01-08 11:28:33 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-08 11:28:33 - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-01-08 11:28:33 - Metrics reporters closed
2025-01-08 11:28:35 - Starting airlineServerApplication using Java 23.0.1 with PID 9928 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 11:28:35 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 11:28:35 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 11:28:36 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 11:28:36 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 11:28:36 - Finished Spring Data repository scanning in 98 ms. Found 10 JPA repository interfaces.
2025-01-08 11:28:36 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 11:28:36 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 11:28:36 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:36 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:36 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:36 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:36 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:36 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:36 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:36 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:36 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:36 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:28:36 - Finished Spring Data repository scanning in 20 ms. Found 0 Redis repository interfaces.
2025-01-08 11:28:36 - Tomcat initialized with port 8080 (http)
2025-01-08 11:28:36 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 11:28:36 - Starting service [Tomcat]
2025-01-08 11:28:36 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 11:28:36 - Initializing Spring embedded WebApplicationContext
2025-01-08 11:28:36 - Root WebApplicationContext: initialization completed in 1266 ms
2025-01-08 11:28:36 - HikariPool-1 - Starting...
2025-01-08 11:28:38 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@fe08eaf
2025-01-08 11:28:38 - HikariPool-1 - Start completed.
2025-01-08 11:28:38 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 11:28:38 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 11:28:38 - HHH000026: Second-level cache disabled
2025-01-08 11:28:39 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 11:28:39 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 11:28:39 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 11:28:39 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 11:28:40 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 11:28:40 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 11:28:40 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 11:28:40 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 11:28:40 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 11:28:40 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 11:28:40 - Filter 'authenticationFilter' configured for use
2025-01-08 11:28:41 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 11:28:41 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 11:28:41 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-08 11:28:41 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 11:28:42 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-08 11:28:42 - Tomcat started on port 8080 (http) with context path '/'
2025-01-08 11:28:42 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:28:42 - initializing Kafka metrics collector
2025-01-08 11:28:42 - Kafka version: 3.9.0
2025-01-08 11:28:42 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:28:42 - Kafka startTimeMs: 1736310522230
2025-01-08 11:28:42 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-08 11:28:42 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:28:42 - initializing Kafka metrics collector
2025-01-08 11:28:42 - Kafka version: 3.9.0
2025-01-08 11:28:42 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:28:42 - Kafka startTimeMs: 1736310522244
2025-01-08 11:28:42 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Subscribed to topic(s): test
2025-01-08 11:28:42 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ticket-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ticket
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:28:42 - initializing Kafka metrics collector
2025-01-08 11:28:42 - Kafka version: 3.9.0
2025-01-08 11:28:42 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:28:42 - Kafka startTimeMs: 1736310522254
2025-01-08 11:28:42 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Subscribed to topic(s): ticket-cancel
2025-01-08 11:28:42 - Started airlineServerApplication in 7.215 seconds (process running for 7.617)
2025-01-08 11:28:42 - airlineServerApplication started
2025-01-08 11:28:43 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:28:43 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:28:43 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:28:43 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:28:43 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:28:43 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:28:43 - [Consumer clientId=consumer-ticket-3, groupId=ticket] (Re-)joining group
2025-01-08 11:28:43 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 11:28:43 - [Consumer clientId=consumer-email-group-2, groupId=email-group] (Re-)joining group
2025-01-08 11:28:44 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-2-1ac5d156-e4e8-4867-8a7a-715a720a3983
2025-01-08 11:28:44 - [Consumer clientId=consumer-email-group-2, groupId=email-group] (Re-)joining group
2025-01-08 11:28:44 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-1-e0619af5-8c8b-4916-b199-bd9e810ffdd8
2025-01-08 11:28:44 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 11:28:44 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Request joining group due to: need to re-join with the given member-id: consumer-ticket-3-4a0d65c3-ff0c-4f71-8cb7-905abbd40401
2025-01-08 11:28:44 - [Consumer clientId=consumer-ticket-3, groupId=ticket] (Re-)joining group
2025-01-08 11:28:46 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Successfully joined group with generation Generation{generationId=143, memberId='consumer-email-group-2-1ac5d156-e4e8-4867-8a7a-715a720a3983', protocol='range'}
2025-01-08 11:28:46 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully joined group with generation Generation{generationId=143, memberId='consumer-email-group-1-e0619af5-8c8b-4916-b199-bd9e810ffdd8', protocol='range'}
2025-01-08 11:28:46 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Successfully synced group in generation Generation{generationId=143, memberId='consumer-email-group-2-1ac5d156-e4e8-4867-8a7a-715a720a3983', protocol='range'}
2025-01-08 11:28:46 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Notifying assignor about the new Assignment(partitions=[test-0])
2025-01-08 11:28:46 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Adding newly assigned partitions: test-0
2025-01-08 11:28:46 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully synced group in generation Generation{generationId=143, memberId='consumer-email-group-1-e0619af5-8c8b-4916-b199-bd9e810ffdd8', protocol='range'}
2025-01-08 11:28:46 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Notifying assignor about the new Assignment(partitions=[])
2025-01-08 11:28:46 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Adding newly assigned partitions: 
2025-01-08 11:28:46 - email-group: partitions assigned: []
2025-01-08 11:28:46 - Setting offset for partition test-0 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 11:28:46 - email-group: partitions assigned: [test-0]
2025-01-08 11:28:47 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Successfully joined group with generation Generation{generationId=17, memberId='consumer-ticket-3-4a0d65c3-ff0c-4f71-8cb7-905abbd40401', protocol='range'}
2025-01-08 11:28:47 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Finished assignment for group at generation 17: {consumer-ticket-3-4a0d65c3-ff0c-4f71-8cb7-905abbd40401=Assignment(partitions=[ticket-cancel-0])}
2025-01-08 11:28:47 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Successfully synced group in generation Generation{generationId=17, memberId='consumer-ticket-3-4a0d65c3-ff0c-4f71-8cb7-905abbd40401', protocol='range'}
2025-01-08 11:28:47 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Notifying assignor about the new Assignment(partitions=[ticket-cancel-0])
2025-01-08 11:28:47 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Adding newly assigned partitions: ticket-cancel-0
2025-01-08 11:28:47 - Setting offset for partition ticket-cancel-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 11:28:47 - ticket: partitions assigned: [ticket-cancel-0]
2025-01-08 11:28:50 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-08 11:28:50 - Initializing Servlet 'dispatcherServlet'
2025-01-08 11:28:50 - Completed initialization in 1 ms
2025-01-08 11:28:50 - Securing POST /emailL
2025-01-08 11:28:50 - Secured POST /emailL
2025-01-08 11:28:50 - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [dqhdev.io.vn:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = airlineServer-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-01-08 11:28:50 - initializing Kafka metrics collector
2025-01-08 11:28:50 - [Producer clientId=airlineServer-producer-1] Instantiated an idempotent producer.
2025-01-08 11:28:50 - Kafka version: 3.9.0
2025-01-08 11:28:50 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:28:50 - Kafka startTimeMs: 1736310530579
2025-01-08 11:28:51 - [Producer clientId=airlineServer-producer-1] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:28:51 - [Producer clientId=airlineServer-producer-1] ProducerId set to 14 with epoch 0
2025-01-08 11:28:51 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:28:51 - Received test message com.airline.infrastructure.dataTransferObject.request.EmailRequest@325ad917
2025-01-08 11:28:51 - Preparing to send email to: dqhit999@gmail.com
2025-01-08 11:28:56 - Email sent successfully to: dqhit999@gmail.com
2025-01-08 11:30:06 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Member consumer-email-group-1-e0619af5-8c8b-4916-b199-bd9e810ffdd8 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:30:06 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Revoke previously assigned partitions test-0
2025-01-08 11:30:06 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:30:06 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Revoke previously assigned partitions ticket-cancel-0
2025-01-08 11:30:06 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:30:06 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:30:06 - ticket: partitions revoked: [ticket-cancel-0]
2025-01-08 11:30:06 - email-group: partitions revoked: [test-0]
2025-01-08 11:30:06 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Member consumer-ticket-3-4a0d65c3-ff0c-4f71-8cb7-905abbd40401 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:30:06 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:30:06 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Member consumer-email-group-2-1ac5d156-e4e8-4867-8a7a-715a720a3983 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:30:06 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:30:06 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:30:06 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:30:06 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:30:06 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:30:06 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:30:06 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:30:06 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:30:06 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:30:06 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:30:06 - [Consumer clientId=consumer-ticket-3, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:30:09 - Starting airlineServerApplication using Java 23.0.1 with PID 5308 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 11:30:09 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 11:30:09 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 11:30:09 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 11:30:09 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 11:30:09 - Finished Spring Data repository scanning in 85 ms. Found 10 JPA repository interfaces.
2025-01-08 11:30:10 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 11:30:10 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 11:30:10 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:30:10 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:30:10 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:30:10 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:30:10 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:30:10 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:30:10 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:30:10 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:30:10 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:30:10 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 11:30:10 - Finished Spring Data repository scanning in 18 ms. Found 0 Redis repository interfaces.
2025-01-08 11:30:10 - Tomcat initialized with port 8080 (http)
2025-01-08 11:30:10 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 11:30:10 - Starting service [Tomcat]
2025-01-08 11:30:10 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 11:30:10 - Initializing Spring embedded WebApplicationContext
2025-01-08 11:30:10 - Root WebApplicationContext: initialization completed in 1173 ms
2025-01-08 11:30:10 - HikariPool-1 - Starting...
2025-01-08 11:30:12 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@6630dd28
2025-01-08 11:30:12 - HikariPool-1 - Start completed.
2025-01-08 11:30:12 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 11:30:12 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 11:30:12 - HHH000026: Second-level cache disabled
2025-01-08 11:30:13 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 11:30:13 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 11:30:13 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 11:30:13 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 11:30:13 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 11:30:13 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 11:30:14 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 11:30:14 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 11:30:14 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 11:30:14 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 11:30:14 - Filter 'authenticationFilter' configured for use
2025-01-08 11:30:15 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 11:30:15 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 11:30:15 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-08 11:30:15 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 11:30:15 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-08 11:30:15 - Tomcat started on port 8080 (http) with context path '/'
2025-01-08 11:30:15 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:30:15 - initializing Kafka metrics collector
2025-01-08 11:30:15 - Kafka version: 3.9.0
2025-01-08 11:30:15 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:30:15 - Kafka startTimeMs: 1736310615908
2025-01-08 11:30:15 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-08 11:30:15 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ticket-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ticket
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:30:15 - initializing Kafka metrics collector
2025-01-08 11:30:15 - Kafka version: 3.9.0
2025-01-08 11:30:15 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:30:15 - Kafka startTimeMs: 1736310615923
2025-01-08 11:30:15 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Subscribed to topic(s): ticket-cancel
2025-01-08 11:30:15 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 11:30:15 - initializing Kafka metrics collector
2025-01-08 11:30:15 - Kafka version: 3.9.0
2025-01-08 11:30:15 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:30:15 - Kafka startTimeMs: 1736310615932
2025-01-08 11:30:15 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Subscribed to topic(s): test
2025-01-08 11:30:15 - Started airlineServerApplication in 6.943 seconds (process running for 7.296)
2025-01-08 11:30:15 - airlineServerApplication started
2025-01-08 11:30:16 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:30:16 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:30:16 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 11:30:16 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:30:16 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:30:16 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:30:16 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 11:30:16 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 11:30:16 - [Consumer clientId=consumer-email-group-3, groupId=email-group] (Re-)joining group
2025-01-08 11:30:17 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: need to re-join with the given member-id: consumer-ticket-2-b3ecad25-2711-43dd-9e69-2f43fe641c18
2025-01-08 11:30:17 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-1-d8c3d047-82f6-4cef-bb36-cc241df6b231
2025-01-08 11:30:17 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 11:30:17 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 11:30:17 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-3-ba85ce10-fe2b-40b2-b149-aef840cf9d64
2025-01-08 11:30:17 - [Consumer clientId=consumer-email-group-3, groupId=email-group] (Re-)joining group
2025-01-08 11:30:19 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully joined group with generation Generation{generationId=145, memberId='consumer-email-group-1-d8c3d047-82f6-4cef-bb36-cc241df6b231', protocol='range'}
2025-01-08 11:30:19 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Successfully joined group with generation Generation{generationId=145, memberId='consumer-email-group-3-ba85ce10-fe2b-40b2-b149-aef840cf9d64', protocol='range'}
2025-01-08 11:30:19 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Successfully synced group in generation Generation{generationId=145, memberId='consumer-email-group-3-ba85ce10-fe2b-40b2-b149-aef840cf9d64', protocol='range'}
2025-01-08 11:30:19 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Notifying assignor about the new Assignment(partitions=[test-0])
2025-01-08 11:30:19 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Adding newly assigned partitions: test-0
2025-01-08 11:30:19 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully synced group in generation Generation{generationId=145, memberId='consumer-email-group-1-d8c3d047-82f6-4cef-bb36-cc241df6b231', protocol='range'}
2025-01-08 11:30:19 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Notifying assignor about the new Assignment(partitions=[])
2025-01-08 11:30:19 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Adding newly assigned partitions: 
2025-01-08 11:30:19 - email-group: partitions assigned: []
2025-01-08 11:30:19 - Setting offset for partition test-0 to the committed offset FetchPosition{offset=3, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 11:30:19 - email-group: partitions assigned: [test-0]
2025-01-08 11:30:20 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully joined group with generation Generation{generationId=19, memberId='consumer-ticket-2-b3ecad25-2711-43dd-9e69-2f43fe641c18', protocol='range'}
2025-01-08 11:30:20 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Finished assignment for group at generation 19: {consumer-ticket-2-b3ecad25-2711-43dd-9e69-2f43fe641c18=Assignment(partitions=[ticket-cancel-0])}
2025-01-08 11:30:20 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully synced group in generation Generation{generationId=19, memberId='consumer-ticket-2-b3ecad25-2711-43dd-9e69-2f43fe641c18', protocol='range'}
2025-01-08 11:30:20 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Notifying assignor about the new Assignment(partitions=[ticket-cancel-0])
2025-01-08 11:30:20 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Adding newly assigned partitions: ticket-cancel-0
2025-01-08 11:30:21 - Setting offset for partition ticket-cancel-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 11:30:21 - ticket: partitions assigned: [ticket-cancel-0]
2025-01-08 11:31:36 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-08 11:31:36 - Initializing Servlet 'dispatcherServlet'
2025-01-08 11:31:36 - Completed initialization in 2 ms
2025-01-08 11:31:36 - Securing POST /api/ticket
2025-01-08 11:31:36 - Secured POST /api/ticket
2025-01-08 11:31:37 - Start booking ticket with request: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@2102b73b
2025-01-08 11:31:38 - Ticket booking successful. Ticket ID: 2db9d3094895492f82d215ccf9a41dce
2025-01-08 11:31:39 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:31:44 - Securing POST /api/ticket/2db9d3094895492f82d215ccf9a41dce/confirm
2025-01-08 11:31:44 - Secured POST /api/ticket/2db9d3094895492f82d215ccf9a41dce/confirm
2025-01-08 11:31:44 - Confirming ticket with ticketId=2db9d3094895492f82d215ccf9a41dce
2025-01-08 11:31:44 - Ticket booked. Ticket: com.airline.domain.ticket.model.Ticket@46a5eec5
2025-01-08 11:31:46 - Ticket with ticketId=2db9d3094895492f82d215ccf9a41dce update available seats successfully for trainScheduleId=504b1c7c7b7b4a7cb2874cb8a57efdbb.
2025-01-08 11:31:53 - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [dqhdev.io.vn:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = airlineServer-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-01-08 11:31:53 - initializing Kafka metrics collector
2025-01-08 11:31:53 - [Producer clientId=airlineServer-producer-1] Instantiated an idempotent producer.
2025-01-08 11:31:53 - Kafka version: 3.9.0
2025-01-08 11:31:53 - Kafka commitId: 84caaa6e9da06435
2025-01-08 11:31:53 - Kafka startTimeMs: 1736310713428
2025-01-08 11:31:54 - [Producer clientId=airlineServer-producer-1] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 11:31:54 - [Producer clientId=airlineServer-producer-1] ProducerId set to 15 with epoch 0
2025-01-08 11:31:54 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 11:31:55 - Received test message com.airline.infrastructure.dataTransferObject.request.EmailRequest@448ff7e4
2025-01-08 11:31:55 - Preparing to send email to: dqhit999@gmail.com
2025-01-08 11:32:00 - Email sent successfully to: dqhit999@gmail.com
2025-01-08 11:32:40 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Member consumer-email-group-1-d8c3d047-82f6-4cef-bb36-cc241df6b231 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:32:40 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Revoke previously assigned partitions test-0
2025-01-08 11:32:40 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Revoke previously assigned partitions ticket-cancel-0
2025-01-08 11:32:40 - ticket: partitions revoked: [ticket-cancel-0]
2025-01-08 11:32:40 - email-group: partitions revoked: [test-0]
2025-01-08 11:32:40 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:32:40 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:32:40 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:32:40 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Member consumer-email-group-3-ba85ce10-fe2b-40b2-b149-aef840cf9d64 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:32:40 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Member consumer-ticket-2-b3ecad25-2711-43dd-9e69-2f43fe641c18 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 11:32:40 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:32:40 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:32:40 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:32:40 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:32:40 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:32:40 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 11:32:40 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:32:40 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:32:40 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 11:32:40 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:32:40 - [Consumer clientId=consumer-email-group-3, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 11:32:40 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 16:14:58 - Starting airlineServerApplication using Java 23.0.1 with PID 11124 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 16:14:58 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 16:14:58 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 16:14:59 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 16:14:59 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 16:14:59 - Finished Spring Data repository scanning in 132 ms. Found 10 JPA repository interfaces.
2025-01-08 16:14:59 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 16:14:59 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 16:14:59 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:14:59 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:14:59 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:14:59 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:14:59 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:14:59 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:14:59 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:14:59 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:14:59 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:14:59 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:14:59 - Finished Spring Data repository scanning in 29 ms. Found 0 Redis repository interfaces.
2025-01-08 16:15:00 - Tomcat initialized with port 8080 (http)
2025-01-08 16:15:00 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 16:15:00 - Starting service [Tomcat]
2025-01-08 16:15:00 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 16:15:00 - Initializing Spring embedded WebApplicationContext
2025-01-08 16:15:00 - Root WebApplicationContext: initialization completed in 2144 ms
2025-01-08 16:15:00 - HikariPool-1 - Starting...
2025-01-08 16:15:03 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@32f308c6
2025-01-08 16:15:03 - HikariPool-1 - Start completed.
2025-01-08 16:15:03 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 16:15:03 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 16:15:03 - HHH000026: Second-level cache disabled
2025-01-08 16:15:04 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 16:15:04 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 16:15:04 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 16:15:04 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 16:15:05 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 16:15:05 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 16:15:05 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 16:15:06 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 16:15:06 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 16:15:06 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 16:15:06 - Filter 'authenticationFilter' configured for use
2025-01-08 16:15:07 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 16:15:07 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 16:15:07 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-08 16:15:07 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 16:15:08 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-08 16:15:08 - Tomcat started on port 8080 (http) with context path '/'
2025-01-08 16:15:08 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 16:15:08 - initializing Kafka metrics collector
2025-01-08 16:15:08 - Kafka version: 3.9.0
2025-01-08 16:15:08 - Kafka commitId: 84caaa6e9da06435
2025-01-08 16:15:08 - Kafka startTimeMs: 1736327708282
2025-01-08 16:15:08 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-08 16:15:08 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ticket-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ticket
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 16:15:08 - initializing Kafka metrics collector
2025-01-08 16:15:08 - Kafka version: 3.9.0
2025-01-08 16:15:08 - Kafka commitId: 84caaa6e9da06435
2025-01-08 16:15:08 - Kafka startTimeMs: 1736327708307
2025-01-08 16:15:08 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Subscribed to topic(s): ticket-cancel
2025-01-08 16:15:08 - Started airlineServerApplication in 10.384 seconds (process running for 11.184)
2025-01-08 16:15:08 - airlineServerApplication started
2025-01-08 16:15:09 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 16:15:09 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 16:15:09 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 16:15:10 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 16:15:10 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: need to re-join with the given member-id: consumer-ticket-2-db954c30-55d7-4e7e-b7b0-0b878caad650
2025-01-08 16:15:10 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 16:15:11 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 16:15:11 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 16:15:11 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-1-914e8457-7b64-4662-9973-1a991b799fd0
2025-01-08 16:15:11 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 16:15:12 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully joined group with generation Generation{generationId=149, memberId='consumer-email-group-1-914e8457-7b64-4662-9973-1a991b799fd0', protocol='range'}
2025-01-08 16:15:12 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully synced group in generation Generation{generationId=149, memberId='consumer-email-group-1-914e8457-7b64-4662-9973-1a991b799fd0', protocol='range'}
2025-01-08 16:15:12 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Notifying assignor about the new Assignment(partitions=[])
2025-01-08 16:15:12 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Adding newly assigned partitions: 
2025-01-08 16:15:12 - email-group: partitions assigned: []
2025-01-08 16:15:13 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully joined group with generation Generation{generationId=21, memberId='consumer-ticket-2-db954c30-55d7-4e7e-b7b0-0b878caad650', protocol='range'}
2025-01-08 16:15:13 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Finished assignment for group at generation 21: {consumer-ticket-2-db954c30-55d7-4e7e-b7b0-0b878caad650=Assignment(partitions=[ticket-cancel-0])}
2025-01-08 16:15:13 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully synced group in generation Generation{generationId=21, memberId='consumer-ticket-2-db954c30-55d7-4e7e-b7b0-0b878caad650', protocol='range'}
2025-01-08 16:15:13 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Notifying assignor about the new Assignment(partitions=[ticket-cancel-0])
2025-01-08 16:15:13 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Adding newly assigned partitions: ticket-cancel-0
2025-01-08 16:15:14 - Setting offset for partition ticket-cancel-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 16:15:14 - ticket: partitions assigned: [ticket-cancel-0]
2025-01-08 16:15:20 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-08 16:15:20 - Initializing Servlet 'dispatcherServlet'
2025-01-08 16:15:20 - Completed initialization in 1 ms
2025-01-08 16:15:20 - Securing POST /api/ticket
2025-01-08 16:15:20 - Secured POST /api/ticket
2025-01-08 16:15:20 - Start booking ticket with request: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@34995d9b
2025-01-08 16:15:22 - Ticket creating successful. Ticket ID: 605701d168a94938a3daa002bf22d4ac
2025-01-08 16:15:24 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 16:15:43 - Securing POST /api/ticket
2025-01-08 16:15:43 - Secured POST /api/ticket
2025-01-08 16:15:43 - Start booking ticket with request: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@73478b12
2025-01-08 16:15:44 - Ticket creating successful. Ticket ID: e3073cf7454a4a49907777ec1560e98e
2025-01-08 16:15:46 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 16:15:52 - Securing POST /api/ticket/e3073cf7454a4a49907777ec1560e98e/confirm
2025-01-08 16:15:52 - Secured POST /api/ticket/e3073cf7454a4a49907777ec1560e98e/confirm
2025-01-08 16:15:52 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 16:15:52 - Securing POST /error
2025-01-08 16:15:52 - Secured POST /error
2025-01-08 16:15:52 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 16:16:14 - Securing POST /api/ticket/e3073cf7454a4a49907777ec1560e98e/confirm
2025-01-08 16:16:14 - Secured POST /api/ticket/e3073cf7454a4a49907777ec1560e98e/confirm
2025-01-08 16:16:14 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 16:16:14 - Securing POST /error
2025-01-08 16:16:14 - Secured POST /error
2025-01-08 16:16:14 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 16:17:02 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Member consumer-email-group-1-914e8457-7b64-4662-9973-1a991b799fd0 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 16:17:02 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Revoke previously assigned partitions ticket-cancel-0
2025-01-08 16:17:02 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 16:17:02 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 16:17:02 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 16:17:02 - ticket: partitions revoked: [ticket-cancel-0]
2025-01-08 16:17:02 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Member consumer-ticket-2-db954c30-55d7-4e7e-b7b0-0b878caad650 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 16:17:02 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 16:17:02 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 16:17:02 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 16:17:02 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 16:17:02 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 16:17:02 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 16:17:02 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 16:17:12 - Starting airlineServerApplication using Java 23.0.1 with PID 4524 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 16:17:12 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 16:17:12 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 16:17:13 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 16:17:13 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 16:17:13 - Finished Spring Data repository scanning in 127 ms. Found 10 JPA repository interfaces.
2025-01-08 16:17:13 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 16:17:13 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 16:17:13 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:17:13 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:17:13 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:17:13 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:17:13 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:17:13 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:17:13 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:17:13 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:17:13 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:17:13 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:17:13 - Finished Spring Data repository scanning in 25 ms. Found 0 Redis repository interfaces.
2025-01-08 16:17:14 - Tomcat initialized with port 8080 (http)
2025-01-08 16:17:14 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 16:17:14 - Starting service [Tomcat]
2025-01-08 16:17:14 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 16:17:14 - Initializing Spring embedded WebApplicationContext
2025-01-08 16:17:14 - Root WebApplicationContext: initialization completed in 2005 ms
2025-01-08 16:17:14 - HikariPool-1 - Starting...
2025-01-08 16:17:17 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@2419fe6f
2025-01-08 16:17:17 - HikariPool-1 - Start completed.
2025-01-08 16:17:17 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 16:17:17 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 16:17:17 - HHH000026: Second-level cache disabled
2025-01-08 16:17:17 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 16:17:18 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 16:17:18 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 16:17:18 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 16:34:28 - Starting airlineServerApplication using Java 23.0.1 with PID 19776 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 16:34:28 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 16:34:28 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 16:34:29 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 16:34:29 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 16:34:29 - Finished Spring Data repository scanning in 110 ms. Found 10 JPA repository interfaces.
2025-01-08 16:34:29 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 16:34:29 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 16:34:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:34:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:34:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:34:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:34:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:34:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:34:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:34:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:34:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:34:29 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:34:29 - Finished Spring Data repository scanning in 20 ms. Found 0 Redis repository interfaces.
2025-01-08 16:34:30 - Tomcat initialized with port 8080 (http)
2025-01-08 16:34:30 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 16:34:30 - Starting service [Tomcat]
2025-01-08 16:34:30 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 16:34:30 - Initializing Spring embedded WebApplicationContext
2025-01-08 16:34:30 - Root WebApplicationContext: initialization completed in 1673 ms
2025-01-08 16:34:30 - HikariPool-1 - Starting...
2025-01-08 16:34:32 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@5abbb273
2025-01-08 16:34:32 - HikariPool-1 - Start completed.
2025-01-08 16:34:32 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 16:34:32 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 16:34:32 - HHH000026: Second-level cache disabled
2025-01-08 16:34:33 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 16:34:33 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 16:34:33 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 16:34:33 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 16:34:34 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 16:34:34 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 16:34:34 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 16:34:35 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 16:34:35 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 16:34:35 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 16:34:35 - Filter 'authenticationFilter' configured for use
2025-01-08 16:34:36 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 16:34:36 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 16:34:36 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-08 16:34:36 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 16:34:36 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-08 16:34:36 - Tomcat started on port 8080 (http) with context path '/'
2025-01-08 16:34:37 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 16:34:37 - initializing Kafka metrics collector
2025-01-08 16:34:37 - Kafka version: 3.9.0
2025-01-08 16:34:37 - Kafka commitId: 84caaa6e9da06435
2025-01-08 16:34:37 - Kafka startTimeMs: 1736328877148
2025-01-08 16:34:37 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-08 16:34:37 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ticket-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ticket
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 16:34:37 - initializing Kafka metrics collector
2025-01-08 16:34:37 - Kafka version: 3.9.0
2025-01-08 16:34:37 - Kafka commitId: 84caaa6e9da06435
2025-01-08 16:34:37 - Kafka startTimeMs: 1736328877172
2025-01-08 16:34:37 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Subscribed to topic(s): ticket-cancel
2025-01-08 16:34:37 - Started airlineServerApplication in 9.207 seconds (process running for 9.782)
2025-01-08 16:34:37 - airlineServerApplication started
2025-01-08 16:34:38 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 16:34:38 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 16:34:38 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 16:34:38 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 16:34:38 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 16:34:38 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 16:34:39 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-1-7dfb8ec4-cdfd-4a8b-ada9-0cfdba37eb10
2025-01-08 16:34:39 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: need to re-join with the given member-id: consumer-ticket-2-c8d597df-b218-4aa5-9d85-dcd20e8336d6
2025-01-08 16:34:39 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 16:34:39 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 16:34:39 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully joined group with generation Generation{generationId=151, memberId='consumer-email-group-1-7dfb8ec4-cdfd-4a8b-ada9-0cfdba37eb10', protocol='range'}
2025-01-08 16:34:39 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully synced group in generation Generation{generationId=151, memberId='consumer-email-group-1-7dfb8ec4-cdfd-4a8b-ada9-0cfdba37eb10', protocol='range'}
2025-01-08 16:34:39 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Notifying assignor about the new Assignment(partitions=[email-topic-0])
2025-01-08 16:34:39 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Adding newly assigned partitions: email-topic-0
2025-01-08 16:34:40 - Setting offset for partition email-topic-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 16:34:40 - email-group: partitions assigned: [email-topic-0]
2025-01-08 16:34:42 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully joined group with generation Generation{generationId=23, memberId='consumer-ticket-2-c8d597df-b218-4aa5-9d85-dcd20e8336d6', protocol='range'}
2025-01-08 16:34:42 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Finished assignment for group at generation 23: {consumer-ticket-2-c8d597df-b218-4aa5-9d85-dcd20e8336d6=Assignment(partitions=[ticket-cancel-0])}
2025-01-08 16:34:42 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully synced group in generation Generation{generationId=23, memberId='consumer-ticket-2-c8d597df-b218-4aa5-9d85-dcd20e8336d6', protocol='range'}
2025-01-08 16:34:42 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Notifying assignor about the new Assignment(partitions=[ticket-cancel-0])
2025-01-08 16:34:42 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Adding newly assigned partitions: ticket-cancel-0
2025-01-08 16:34:42 - Setting offset for partition ticket-cancel-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 16:34:42 - ticket: partitions assigned: [ticket-cancel-0]
2025-01-08 16:34:42 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-08 16:34:42 - Initializing Servlet 'dispatcherServlet'
2025-01-08 16:34:42 - Completed initialization in 1 ms
2025-01-08 16:34:42 - Securing POST /api/ticket
2025-01-08 16:34:42 - Secured POST /api/ticket
2025-01-08 16:34:42 - Start booking ticket with request: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@7906f0b8
2025-01-08 16:34:44 - Ticket creating successful. Ticket ID: 805095e0ff1a4df98c9de03bd90d4878
2025-01-08 16:34:46 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 16:34:51 - Securing POST /api/ticket/805095e0ff1a4df98c9de03bd90d4878/confirm
2025-01-08 16:34:51 - Secured POST /api/ticket/805095e0ff1a4df98c9de03bd90d4878/confirm
2025-01-08 16:34:51 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 16:34:51 - Securing POST /error
2025-01-08 16:34:51 - Secured POST /error
2025-01-08 16:34:51 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 16:35:06 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Revoke previously assigned partitions ticket-cancel-0
2025-01-08 16:35:06 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Revoke previously assigned partitions email-topic-0
2025-01-08 16:35:06 - ticket: partitions revoked: [ticket-cancel-0]
2025-01-08 16:35:06 - email-group: partitions revoked: [email-topic-0]
2025-01-08 16:35:06 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Member consumer-email-group-1-7dfb8ec4-cdfd-4a8b-ada9-0cfdba37eb10 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 16:35:06 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Member consumer-ticket-2-c8d597df-b218-4aa5-9d85-dcd20e8336d6 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 16:35:06 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 16:35:06 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 16:35:06 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 16:35:06 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 16:35:06 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 16:35:06 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 16:35:06 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 16:35:06 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 16:35:06 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 16:35:06 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 16:35:10 - Starting airlineServerApplication using Java 23.0.1 with PID 20632 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 16:35:10 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 16:35:10 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 16:35:11 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 16:35:11 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 16:35:11 - Finished Spring Data repository scanning in 152 ms. Found 10 JPA repository interfaces.
2025-01-08 16:35:11 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 16:35:11 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 16:35:11 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:35:11 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:35:11 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:35:11 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:35:11 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:35:11 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:35:11 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:35:11 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:35:11 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:35:11 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:35:11 - Finished Spring Data repository scanning in 29 ms. Found 0 Redis repository interfaces.
2025-01-08 16:35:12 - Tomcat initialized with port 8080 (http)
2025-01-08 16:35:12 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 16:35:12 - Starting service [Tomcat]
2025-01-08 16:35:12 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 16:35:12 - Initializing Spring embedded WebApplicationContext
2025-01-08 16:35:12 - Root WebApplicationContext: initialization completed in 2145 ms
2025-01-08 16:35:12 - HikariPool-1 - Starting...
2025-01-08 16:35:15 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@3c97f5e9
2025-01-08 16:35:15 - HikariPool-1 - Start completed.
2025-01-08 16:35:15 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 16:35:15 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 16:35:15 - HHH000026: Second-level cache disabled
2025-01-08 16:35:15 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 16:35:16 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 16:35:16 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 16:35:16 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 16:35:17 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 16:35:17 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 16:35:18 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 16:35:18 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 16:35:18 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 16:35:18 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 16:35:19 - Filter 'authenticationFilter' configured for use
2025-01-08 16:35:20 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 16:35:20 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 16:35:20 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-08 16:35:20 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 16:35:21 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-08 16:35:21 - Tomcat started on port 8080 (http) with context path '/'
2025-01-08 16:35:21 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 16:35:21 - initializing Kafka metrics collector
2025-01-08 16:35:21 - Kafka version: 3.9.0
2025-01-08 16:35:21 - Kafka commitId: 84caaa6e9da06435
2025-01-08 16:35:21 - Kafka startTimeMs: 1736328921379
2025-01-08 16:35:21 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-08 16:35:21 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ticket-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ticket
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 16:35:21 - initializing Kafka metrics collector
2025-01-08 16:35:21 - Kafka version: 3.9.0
2025-01-08 16:35:21 - Kafka commitId: 84caaa6e9da06435
2025-01-08 16:35:21 - Kafka startTimeMs: 1736328921428
2025-01-08 16:35:21 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Subscribed to topic(s): ticket-cancel
2025-01-08 16:35:21 - Started airlineServerApplication in 11.472 seconds (process running for 12.535)
2025-01-08 16:35:21 - airlineServerApplication started
2025-01-08 16:35:22 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 16:35:22 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 16:35:22 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 16:35:22 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 16:35:22 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 16:35:22 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 16:35:22 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-08 16:35:22 - Initializing Servlet 'dispatcherServlet'
2025-01-08 16:35:22 - Completed initialization in 1 ms
2025-01-08 16:35:22 - Securing POST /api/ticket/805095e0ff1a4df98c9de03bd90d4878/confirm
2025-01-08 16:35:22 - Secured POST /api/ticket/805095e0ff1a4df98c9de03bd90d4878/confirm
2025-01-08 16:35:22 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 16:35:22 - Securing POST /error
2025-01-08 16:35:22 - Secured POST /error
2025-01-08 16:35:22 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 16:35:23 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: need to re-join with the given member-id: consumer-ticket-2-fdb2d106-8c64-4d6b-b8c1-0429bfda56ed
2025-01-08 16:35:23 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 16:35:23 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-1-4d420878-a937-4a6a-878c-89896076e456
2025-01-08 16:35:23 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 16:35:24 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully joined group with generation Generation{generationId=153, memberId='consumer-email-group-1-4d420878-a937-4a6a-878c-89896076e456', protocol='range'}
2025-01-08 16:35:24 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully synced group in generation Generation{generationId=153, memberId='consumer-email-group-1-4d420878-a937-4a6a-878c-89896076e456', protocol='range'}
2025-01-08 16:35:24 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Notifying assignor about the new Assignment(partitions=[email-topic-0])
2025-01-08 16:35:24 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Adding newly assigned partitions: email-topic-0
2025-01-08 16:35:25 - Setting offset for partition email-topic-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 16:35:25 - email-group: partitions assigned: [email-topic-0]
2025-01-08 16:35:26 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully joined group with generation Generation{generationId=25, memberId='consumer-ticket-2-fdb2d106-8c64-4d6b-b8c1-0429bfda56ed', protocol='range'}
2025-01-08 16:35:26 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Finished assignment for group at generation 25: {consumer-ticket-2-fdb2d106-8c64-4d6b-b8c1-0429bfda56ed=Assignment(partitions=[ticket-cancel-0])}
2025-01-08 16:35:26 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully synced group in generation Generation{generationId=25, memberId='consumer-ticket-2-fdb2d106-8c64-4d6b-b8c1-0429bfda56ed', protocol='range'}
2025-01-08 16:35:26 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Notifying assignor about the new Assignment(partitions=[ticket-cancel-0])
2025-01-08 16:35:26 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Adding newly assigned partitions: ticket-cancel-0
2025-01-08 16:35:27 - Setting offset for partition ticket-cancel-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 16:35:27 - ticket: partitions assigned: [ticket-cancel-0]
2025-01-08 16:35:31 - Securing POST /api/ticket/805095e0ff1a4df98c9de03bd90d4878/confirm
2025-01-08 16:35:31 - Secured POST /api/ticket/805095e0ff1a4df98c9de03bd90d4878/confirm
2025-01-08 16:35:31 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 16:35:31 - Securing POST /error
2025-01-08 16:35:31 - Secured POST /error
2025-01-08 16:35:31 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 16:35:45 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Revoke previously assigned partitions email-topic-0
2025-01-08 16:35:45 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Revoke previously assigned partitions ticket-cancel-0
2025-01-08 16:35:45 - email-group: partitions revoked: [email-topic-0]
2025-01-08 16:35:45 - ticket: partitions revoked: [ticket-cancel-0]
2025-01-08 16:35:45 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Member consumer-email-group-1-4d420878-a937-4a6a-878c-89896076e456 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 16:35:45 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Member consumer-ticket-2-fdb2d106-8c64-4d6b-b8c1-0429bfda56ed sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 16:35:45 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 16:35:45 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 16:35:45 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 16:35:45 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 16:35:45 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 16:35:45 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 16:35:45 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 16:35:45 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 16:35:45 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 16:35:45 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 16:36:46 - Starting airlineServerApplication using Java 23.0.1 with PID 17412 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 16:36:46 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 16:36:46 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 16:36:47 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 16:36:47 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 16:36:47 - Finished Spring Data repository scanning in 106 ms. Found 10 JPA repository interfaces.
2025-01-08 16:36:47 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 16:36:47 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 16:36:47 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:36:47 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:36:47 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:36:47 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:36:47 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:36:47 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:36:47 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:36:47 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:36:47 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:36:47 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 16:36:47 - Finished Spring Data repository scanning in 23 ms. Found 0 Redis repository interfaces.
2025-01-08 16:36:48 - Tomcat initialized with port 8080 (http)
2025-01-08 16:36:48 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 16:36:48 - Starting service [Tomcat]
2025-01-08 16:36:48 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 16:36:48 - Initializing Spring embedded WebApplicationContext
2025-01-08 16:36:48 - Root WebApplicationContext: initialization completed in 1698 ms
2025-01-08 16:36:48 - HikariPool-1 - Starting...
2025-01-08 16:36:51 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@655909e2
2025-01-08 16:36:51 - HikariPool-1 - Start completed.
2025-01-08 16:36:51 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 16:36:51 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 16:36:51 - HHH000026: Second-level cache disabled
2025-01-08 16:36:51 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 16:36:51 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 16:36:51 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 16:36:51 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 16:36:52 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 16:36:52 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 16:36:52 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 16:36:53 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 16:36:53 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 16:36:53 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 16:36:53 - Filter 'authenticationFilter' configured for use
2025-01-08 16:36:54 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 16:36:54 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 16:36:54 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-08 16:36:54 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 16:36:55 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-08 16:36:55 - Tomcat started on port 8080 (http) with context path '/'
2025-01-08 16:36:55 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 16:36:55 - initializing Kafka metrics collector
2025-01-08 16:36:55 - Kafka version: 3.9.0
2025-01-08 16:36:55 - Kafka commitId: 84caaa6e9da06435
2025-01-08 16:36:55 - Kafka startTimeMs: 1736329015259
2025-01-08 16:36:55 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-08 16:36:55 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ticket-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ticket
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 16:36:55 - initializing Kafka metrics collector
2025-01-08 16:36:55 - Kafka version: 3.9.0
2025-01-08 16:36:55 - Kafka commitId: 84caaa6e9da06435
2025-01-08 16:36:55 - Kafka startTimeMs: 1736329015289
2025-01-08 16:36:55 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Subscribed to topic(s): ticket-cancel
2025-01-08 16:36:55 - Started airlineServerApplication in 9.086 seconds (process running for 9.657)
2025-01-08 16:36:55 - airlineServerApplication started
2025-01-08 16:36:56 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-08 16:36:56 - Initializing Servlet 'dispatcherServlet'
2025-01-08 16:36:56 - Completed initialization in 2 ms
2025-01-08 16:36:56 - Securing POST /api/ticket/create
2025-01-08 16:36:56 - Secured POST /api/ticket/create
2025-01-08 16:36:56 - Start booking ticket with request: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@16dec42d
2025-01-08 16:36:56 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 16:36:56 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 16:36:56 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 16:36:56 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 16:36:56 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 16:36:56 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 16:36:57 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-1-f7a344a1-d453-4e0e-9892-b23e7b582274
2025-01-08 16:36:57 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 16:36:57 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: need to re-join with the given member-id: consumer-ticket-2-813730e8-7994-424d-8ee4-20d464bbdfd1
2025-01-08 16:36:57 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 16:36:57 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully joined group with generation Generation{generationId=155, memberId='consumer-email-group-1-f7a344a1-d453-4e0e-9892-b23e7b582274', protocol='range'}
2025-01-08 16:36:57 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully synced group in generation Generation{generationId=155, memberId='consumer-email-group-1-f7a344a1-d453-4e0e-9892-b23e7b582274', protocol='range'}
2025-01-08 16:36:57 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Notifying assignor about the new Assignment(partitions=[])
2025-01-08 16:36:57 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Adding newly assigned partitions: 
2025-01-08 16:36:57 - email-group: partitions assigned: []
2025-01-08 16:36:57 - Ticket creating successful. Ticket ID: 39ba7b8ec57448e68323c56185267a4f
2025-01-08 16:37:00 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully joined group with generation Generation{generationId=27, memberId='consumer-ticket-2-813730e8-7994-424d-8ee4-20d464bbdfd1', protocol='range'}
2025-01-08 16:37:00 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Finished assignment for group at generation 27: {consumer-ticket-2-813730e8-7994-424d-8ee4-20d464bbdfd1=Assignment(partitions=[ticket-cancel-0])}
2025-01-08 16:37:00 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully synced group in generation Generation{generationId=27, memberId='consumer-ticket-2-813730e8-7994-424d-8ee4-20d464bbdfd1', protocol='range'}
2025-01-08 16:37:00 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Notifying assignor about the new Assignment(partitions=[ticket-cancel-0])
2025-01-08 16:37:00 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Adding newly assigned partitions: ticket-cancel-0
2025-01-08 16:37:00 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 16:37:00 - Setting offset for partition ticket-cancel-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 16:37:01 - ticket: partitions assigned: [ticket-cancel-0]
2025-01-08 16:37:10 - Securing POST /api/ticket/39ba7b8ec57448e68323c56185267a4f/book
2025-01-08 16:37:10 - Secured POST /api/ticket/39ba7b8ec57448e68323c56185267a4f/book
2025-01-08 16:37:10 - Confirming ticket with ticketId=39ba7b8ec57448e68323c56185267a4f
2025-01-08 16:37:11 - Ticket booked. Ticket: com.airline.domain.ticket.model.Ticket@83a684e
2025-01-08 16:37:12 - Ticket with ticketId=39ba7b8ec57448e68323c56185267a4f update available seats successfully for trainScheduleId=504b1c7c7b7b4a7cb2874cb8a57efdbb.
2025-01-08 16:37:18 - topic: email-topic message: com.airline.infrastructure.dataTransferObject.request.EmailRequest@3a17c92c
2025-01-08 16:37:18 - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [dqhdev.io.vn:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = airlineServer-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-01-08 16:37:18 - initializing Kafka metrics collector
2025-01-08 16:37:18 - [Producer clientId=airlineServer-producer-1] Instantiated an idempotent producer.
2025-01-08 16:37:18 - Kafka version: 3.9.0
2025-01-08 16:37:18 - Kafka commitId: 84caaa6e9da06435
2025-01-08 16:37:18 - Kafka startTimeMs: 1736329038475
2025-01-08 16:37:19 - [Producer clientId=airlineServer-producer-1] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 16:37:19 - [Producer clientId=airlineServer-producer-1] ProducerId set to 16 with epoch 0
2025-01-08 16:37:19 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 16:38:32 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Member consumer-email-group-1-f7a344a1-d453-4e0e-9892-b23e7b582274 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 16:38:32 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Revoke previously assigned partitions ticket-cancel-0
2025-01-08 16:38:32 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 16:38:32 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 16:38:32 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 16:38:32 - ticket: partitions revoked: [ticket-cancel-0]
2025-01-08 16:38:32 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Member consumer-ticket-2-813730e8-7994-424d-8ee4-20d464bbdfd1 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 16:38:32 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 16:38:32 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 16:38:32 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 16:38:32 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 16:38:32 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 16:38:32 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 16:38:32 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 20:09:50 - Starting airlineServerApplication using Java 23.0.1 with PID 20728 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 20:09:50 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 20:09:50 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 20:09:51 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 20:09:51 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 20:09:51 - Finished Spring Data repository scanning in 99 ms. Found 10 JPA repository interfaces.
2025-01-08 20:09:51 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 20:09:51 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 20:09:51 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:09:51 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:09:51 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:09:51 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:09:51 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:09:51 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:09:51 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:09:51 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:09:51 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:09:51 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:09:51 - Finished Spring Data repository scanning in 19 ms. Found 0 Redis repository interfaces.
2025-01-08 20:09:51 - Tomcat initialized with port 8080 (http)
2025-01-08 20:09:51 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 20:09:51 - Starting service [Tomcat]
2025-01-08 20:09:51 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 20:09:51 - Initializing Spring embedded WebApplicationContext
2025-01-08 20:09:51 - Root WebApplicationContext: initialization completed in 1621 ms
2025-01-08 20:09:51 - HikariPool-1 - Starting...
2025-01-08 20:09:53 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 20:09:53 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 20:09:53 - HHH000026: Second-level cache disabled
2025-01-08 20:09:53 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 20:09:53 - HikariPool-1 - Starting...
2025-01-08 20:09:54 - SQL Error: 0, SQLState: 08S01
2025-01-08 20:09:54 - Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
2025-01-08 20:09:54 - HHH000342: Could not obtain connection to query metadata
org.hibernate.exception.JDBCConnectionException: unable to obtain isolated JDBC connection [Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.] [n/a]
	at org.hibernate.exception.internal.SQLStateConversionDelegate.convert(SQLStateConversionDelegate.java:100)
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:58)
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:108)
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:94)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcIsolationDelegate.delegateWork(JdbcIsolationDelegate.java:116)
	at org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator.getJdbcEnvironmentUsingJdbcMetadata(JdbcEnvironmentInitiator.java:320)
	at org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator.initiateService(JdbcEnvironmentInitiator.java:129)
	at org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator.initiateService(JdbcEnvironmentInitiator.java:81)
	at org.hibernate.boot.registry.internal.StandardServiceRegistryImpl.initiateService(StandardServiceRegistryImpl.java:130)
	at org.hibernate.service.internal.AbstractServiceRegistryImpl.createService(AbstractServiceRegistryImpl.java:263)
	at org.hibernate.service.internal.AbstractServiceRegistryImpl.initializeService(AbstractServiceRegistryImpl.java:238)
	at org.hibernate.service.internal.AbstractServiceRegistryImpl.getService(AbstractServiceRegistryImpl.java:215)
	at org.hibernate.boot.model.relational.Database.<init>(Database.java:45)
	at org.hibernate.boot.internal.InFlightMetadataCollectorImpl.getDatabase(InFlightMetadataCollectorImpl.java:226)
	at org.hibernate.boot.internal.InFlightMetadataCollectorImpl.<init>(InFlightMetadataCollectorImpl.java:194)
	at org.hibernate.boot.model.process.spi.MetadataBuildingProcess.complete(MetadataBuildingProcess.java:171)
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.metadata(EntityManagerFactoryBuilderImpl.java:1431)
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:1502)
	at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:66)
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:390)
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:419)
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:400)
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.afterPropertiesSet(LocalContainerEntityManagerFactoryBean.java:366)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1849)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1798)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:601)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:365)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:135)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:691)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:513)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1351)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:365)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:135)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1701)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1450)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:600)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:254)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1626)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1514)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:913)
	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:240)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1371)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1208)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:254)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1626)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1514)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:913)
	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:240)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1371)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1208)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:254)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1626)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1514)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:913)
	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:240)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1371)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1208)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:254)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1626)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1514)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:913)
	at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:240)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1371)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1208)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:563)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:523)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:336)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:288)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:334)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204)
	at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:211)
	at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addAsRegistrationBean(ServletContextInitializerBeans.java:174)
	at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addAsRegistrationBean(ServletContextInitializerBeans.java:169)
	at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addAdaptableBeans(ServletContextInitializerBeans.java:154)
	at org.springframework.boot.web.servlet.ServletContextInitializerBeans.<init>(ServletContextInitializerBeans.java:87)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.getServletContextInitializerBeans(ServletWebServerApplicationContext.java:266)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.selfInitialize(ServletWebServerApplicationContext.java:240)
	at org.springframework.boot.web.embedded.tomcat.TomcatStarter.onStartup(TomcatStarter.java:52)
	at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:4426)
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:164)
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1203)
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1193)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75)
	at java.base/java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:148)
	at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:749)
	at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:772)
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:164)
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1203)
	at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1193)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75)
	at java.base/java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:148)
	at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:749)
	at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:203)
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:164)
	at org.apache.catalina.core.StandardService.startInternal(StandardService.java:415)
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:164)
	at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:870)
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:164)
	at org.apache.catalina.startup.Tomcat.start(Tomcat.java:437)
	at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize(TomcatWebServer.java:128)
	at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.<init>(TomcatWebServer.java:107)
	at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getTomcatWebServer(TomcatServletWebServerFactory.java:516)
	at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getWebServer(TomcatServletWebServerFactory.java:222)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:188)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:162)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:621)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.airline.AirLineServerApplication.main(airlineServerApplication.java:11)
Caused by: com.mysql.cj.jdbc.exceptions.CommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
	at com.mysql.cj.jdbc.exceptions.SQLError.createCommunicationsException(SQLError.java:165)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:55)
	at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:837)
	at com.mysql.cj.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:420)
	at com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:238)
	at com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:180)
	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:137)
	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:360)
	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:202)
	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:461)
	at com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:550)
	at com.zaxxer.hikari.pool.HikariPool.<init>(HikariPool.java:98)
	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:111)
	at org.hibernate.engine.jdbc.connections.internal.DatasourceConnectionProviderImpl.getConnection(DatasourceConnectionProviderImpl.java:126)
	at org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator$ConnectionProviderJdbcConnectionAccess.obtainConnection(JdbcEnvironmentInitiator.java:467)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcIsolationDelegate.delegateWork(JdbcIsolationDelegate.java:61)
	... 149 common frames omitted
Caused by: com.mysql.cj.exceptions.CJCommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:501)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:485)
	at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:52)
	at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:95)
	at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:140)
	at com.mysql.cj.exceptions.ExceptionFactory.createCommunicationsException(ExceptionFactory.java:156)
	at com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:79)
	at com.mysql.cj.NativeSession.connect(NativeSession.java:142)
	at com.mysql.cj.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:961)
	at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:825)
	... 162 common frames omitted
Caused by: java.net.UnknownHostException: dqhdev.io.vn
	at java.base/java.net.InetAddress$CachedLookup.get(InetAddress.java:998)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1807)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1676)
	at com.mysql.cj.protocol.StandardSocketFactory.connect(StandardSocketFactory.java:121)
	at com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:53)
	... 165 common frames omitted
2025-01-08 20:09:54 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 20:09:54 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 20:09:54 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (null)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 20:09:55 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 20:09:55 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 20:09:55 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 20:09:56 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 20:09:56 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 20:09:56 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 20:09:56 - Filter 'authenticationFilter' configured for use
2025-01-08 20:09:56 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 20:09:56 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 20:09:57 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-08 20:09:57 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 20:09:57 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-08 20:09:57 - Tomcat started on port 8080 (http) with context path '/'
2025-01-08 20:09:57 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 20:09:57 - initializing Kafka metrics collector
2025-01-08 20:09:57 - Couldn't resolve server dqhdev.io.vn:9092 from bootstrap.servers as DNS resolution failed for dqhdev.io.vn
2025-01-08 20:09:57 - Metrics scheduler closed
2025-01-08 20:09:57 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-08 20:09:57 - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-01-08 20:09:57 - Metrics reporters closed
2025-01-08 20:09:57 - App info kafka.consumer for consumer-email-group-1 unregistered
2025-01-08 20:09:57 - Commencing graceful shutdown. Waiting for active requests to complete
2025-01-08 20:09:57 - Pausing ProtocolHandler ["http-nio-8080"]
2025-01-08 20:09:57 - Graceful shutdown complete
2025-01-08 20:09:57 - Stopping ProtocolHandler ["http-nio-8080"]
2025-01-08 20:09:57 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'
2025-01-08 20:09:57 - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 20:09:57 - 

Error starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled.
2025-01-08 20:09:57 - Application run failed
org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:326)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:510)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:295)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:240)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:1006)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:630)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:752)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.airline.AirLineServerApplication.main(airlineServerApplication.java:11)
Caused by: org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer.<init>(ClassicKafkaConsumer.java:270)
	at org.apache.kafka.clients.consumer.internals.ConsumerDelegateCreator.create(ConsumerDelegateCreator.java:65)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:600)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:595)
	at org.springframework.kafka.core.DefaultKafkaConsumerFactory$ExtendedKafkaConsumer.<init>(DefaultKafkaConsumerFactory.java:498)
	at org.springframework.kafka.core.DefaultKafkaConsumerFactory.createRawConsumer(DefaultKafkaConsumerFactory.java:453)
	at org.springframework.kafka.core.DefaultKafkaConsumerFactory.createKafkaConsumer(DefaultKafkaConsumerFactory.java:430)
	at org.springframework.kafka.core.DefaultKafkaConsumerFactory.createConsumerWithAdjustedProperties(DefaultKafkaConsumerFactory.java:407)
	at org.springframework.kafka.core.DefaultKafkaConsumerFactory.createKafkaConsumer(DefaultKafkaConsumerFactory.java:374)
	at org.springframework.kafka.core.DefaultKafkaConsumerFactory.createConsumer(DefaultKafkaConsumerFactory.java:335)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.<init>(KafkaMessageListenerContainer.java:874)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer.doStart(KafkaMessageListenerContainer.java:385)
	at org.springframework.kafka.listener.AbstractMessageListenerContainer.start(AbstractMessageListenerContainer.java:520)
	at org.springframework.kafka.listener.ConcurrentMessageListenerContainer.doStart(ConcurrentMessageListenerContainer.java:264)
	at org.springframework.kafka.listener.AbstractMessageListenerContainer.start(AbstractMessageListenerContainer.java:520)
	at org.springframework.kafka.config.KafkaListenerEndpointRegistry.startIfNecessary(KafkaListenerEndpointRegistry.java:436)
	at org.springframework.kafka.config.KafkaListenerEndpointRegistry.start(KafkaListenerEndpointRegistry.java:382)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:323)
	... 13 common frames omitted
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:104)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:63)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:59)
	at org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer.<init>(ClassicKafkaConsumer.java:189)
	... 30 common frames omitted
2025-01-08 20:12:44 - Starting airlineServerApplication using Java 23.0.1 with PID 11244 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 20:12:44 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 20:12:44 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 20:12:45 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 20:12:45 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 20:12:45 - Finished Spring Data repository scanning in 84 ms. Found 10 JPA repository interfaces.
2025-01-08 20:12:45 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 20:12:45 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 20:12:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:12:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:12:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:12:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:12:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:12:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:12:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:12:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:12:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:12:45 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:12:45 - Finished Spring Data repository scanning in 18 ms. Found 0 Redis repository interfaces.
2025-01-08 20:12:45 - Tomcat initialized with port 8080 (http)
2025-01-08 20:12:45 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 20:12:45 - Starting service [Tomcat]
2025-01-08 20:12:45 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 20:12:45 - Initializing Spring embedded WebApplicationContext
2025-01-08 20:12:45 - Root WebApplicationContext: initialization completed in 1413 ms
2025-01-08 20:12:45 - HikariPool-1 - Starting...
2025-01-08 20:12:48 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@41059616
2025-01-08 20:12:48 - HikariPool-1 - Start completed.
2025-01-08 20:12:48 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 20:12:48 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 20:12:48 - HHH000026: Second-level cache disabled
2025-01-08 20:12:48 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 20:12:48 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 20:12:48 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 20:12:48 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 20:12:49 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 20:12:49 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 20:12:49 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 20:12:50 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 20:12:50 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 20:12:50 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 20:12:50 - Filter 'authenticationFilter' configured for use
2025-01-08 20:12:50 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 20:12:50 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 20:12:50 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-08 20:12:50 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 20:12:51 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-08 20:12:51 - Tomcat started on port 8080 (http) with context path '/'
2025-01-08 20:12:51 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ticket-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ticket
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 20:12:51 - initializing Kafka metrics collector
2025-01-08 20:12:51 - Kafka version: 3.9.0
2025-01-08 20:12:51 - Kafka commitId: 84caaa6e9da06435
2025-01-08 20:12:51 - Kafka startTimeMs: 1736341971426
2025-01-08 20:12:51 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Subscribed to topic(s): ticket-cancel
2025-01-08 20:12:51 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 20:12:51 - initializing Kafka metrics collector
2025-01-08 20:12:51 - Kafka version: 3.9.0
2025-01-08 20:12:51 - Kafka commitId: 84caaa6e9da06435
2025-01-08 20:12:51 - Kafka startTimeMs: 1736341971444
2025-01-08 20:12:51 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-08 20:12:51 - Started airlineServerApplication in 7.636 seconds (process running for 8.114)
2025-01-08 20:12:51 - airlineServerApplication started
2025-01-08 20:12:52 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 20:12:52 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 20:12:52 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 20:12:52 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 20:12:52 - [Consumer clientId=consumer-ticket-1, groupId=ticket] (Re-)joining group
2025-01-08 20:12:52 - [Consumer clientId=consumer-email-group-2, groupId=email-group] (Re-)joining group
2025-01-08 20:12:53 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-2-e0779da6-87ec-4b09-885c-61c1e5c0ad0a
2025-01-08 20:12:53 - [Consumer clientId=consumer-email-group-2, groupId=email-group] (Re-)joining group
2025-01-08 20:12:53 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Request joining group due to: need to re-join with the given member-id: consumer-ticket-1-79667604-2598-42ca-bc25-043ecf5235f8
2025-01-08 20:12:53 - [Consumer clientId=consumer-ticket-1, groupId=ticket] (Re-)joining group
2025-01-08 20:12:56 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Successfully joined group with generation Generation{generationId=157, memberId='consumer-email-group-2-e0779da6-87ec-4b09-885c-61c1e5c0ad0a', protocol='range'}
2025-01-08 20:12:56 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Successfully joined group with generation Generation{generationId=29, memberId='consumer-ticket-1-79667604-2598-42ca-bc25-043ecf5235f8', protocol='range'}
2025-01-08 20:12:56 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Finished assignment for group at generation 29: {consumer-ticket-1-79667604-2598-42ca-bc25-043ecf5235f8=Assignment(partitions=[ticket-cancel-0])}
2025-01-08 20:12:56 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Successfully synced group in generation Generation{generationId=157, memberId='consumer-email-group-2-e0779da6-87ec-4b09-885c-61c1e5c0ad0a', protocol='range'}
2025-01-08 20:12:56 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Successfully synced group in generation Generation{generationId=29, memberId='consumer-ticket-1-79667604-2598-42ca-bc25-043ecf5235f8', protocol='range'}
2025-01-08 20:12:56 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Notifying assignor about the new Assignment(partitions=[])
2025-01-08 20:12:56 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Notifying assignor about the new Assignment(partitions=[ticket-cancel-0])
2025-01-08 20:12:56 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Adding newly assigned partitions: 
2025-01-08 20:12:56 - email-group: partitions assigned: []
2025-01-08 20:12:56 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Adding newly assigned partitions: ticket-cancel-0
2025-01-08 20:12:56 - Setting offset for partition ticket-cancel-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 20:12:57 - ticket: partitions assigned: [ticket-cancel-0]
2025-01-08 20:13:10 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-08 20:13:10 - Initializing Servlet 'dispatcherServlet'
2025-01-08 20:13:10 - Completed initialization in 1 ms
2025-01-08 20:13:10 - Securing POST /api/ticket/create
2025-01-08 20:13:10 - Secured POST /api/ticket/create
2025-01-08 20:13:10 - Received request to create ticket: com.airline.application.ticket.dataTransferObject.request.TicketBookingRequest@16dec42d
2025-01-08 20:13:13 - Ticket creating successful. Ticket ID: 8cf36319626c48c38d40a6e12a5a9899
2025-01-08 20:13:16 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 20:13:24 - Securing POST /api/ticket/8cf36319626c48c38d40a6e12a5a9899/book
2025-01-08 20:13:24 - Secured POST /api/ticket/8cf36319626c48c38d40a6e12a5a9899/book
2025-01-08 20:13:24 - Received request to book ticket. Ticket ID: 8cf36319626c48c38d40a6e12a5a9899, Request: com.airline.application.ticket.dataTransferObject.request.TicketBookRequest@6a9ad7d1, IP: 0:0:0:0:0:0:0:1
2025-01-08 20:13:24 - Ticket booked. Ticket: com.airline.domain.ticket.model.Ticket@72051da7
2025-01-08 20:13:27 - Ticket with ticketId=8cf36319626c48c38d40a6e12a5a9899 update available seats successfully for trainScheduleId=504b1c7c7b7b4a7cb2874cb8a57efdbb.
2025-01-08 20:13:36 - topic: email-topic message: com.airline.infrastructure.dataTransferObject.request.EmailRequest@162ebab3
2025-01-08 20:13:36 - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [dqhdev.io.vn:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = airlineServer-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-01-08 20:13:36 - initializing Kafka metrics collector
2025-01-08 20:13:36 - [Producer clientId=airlineServer-producer-1] Instantiated an idempotent producer.
2025-01-08 20:13:36 - Kafka version: 3.9.0
2025-01-08 20:13:36 - Kafka commitId: 84caaa6e9da06435
2025-01-08 20:13:36 - Kafka startTimeMs: 1736342016918
2025-01-08 20:13:37 - [Producer clientId=airlineServer-producer-1] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 20:13:37 - [Producer clientId=airlineServer-producer-1] ProducerId set to 17 with epoch 0
2025-01-08 20:13:37 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 20:19:00 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Member consumer-email-group-2-e0779da6-87ec-4b09-885c-61c1e5c0ad0a sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 20:19:00 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Revoke previously assigned partitions ticket-cancel-0
2025-01-08 20:19:00 - ticket: partitions revoked: [ticket-cancel-0]
2025-01-08 20:19:00 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 20:19:00 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 20:19:00 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 20:19:00 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Member consumer-ticket-1-79667604-2598-42ca-bc25-043ecf5235f8 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 20:19:00 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 20:19:00 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 20:19:00 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 20:19:00 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 20:19:00 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 20:19:00 - [Consumer clientId=consumer-email-group-2, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 20:19:00 - [Consumer clientId=consumer-ticket-1, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 20:45:15 - Starting airlineServerApplication using Java 23.0.1 with PID 25576 (F:\project personal\TrainApp\airlineServer\build\classes\java\main started by Hi Windows 11 Home in F:\project personal\TrainApp\airlineServer)
2025-01-08 20:45:15 - Running with Spring Boot v3.4.0, Spring v6.2.0
2025-01-08 20:45:15 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 20:45:16 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 20:45:16 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 20:45:16 - Finished Spring Data repository scanning in 103 ms. Found 10 JPA repository interfaces.
2025-01-08 20:45:16 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 20:45:16 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 20:45:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.TokenEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:45:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.account.repository.UserEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:45:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.payment.repository.PaymentEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:45:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.AirportEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:45:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.station.repository.StationRouteEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:45:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.test.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:45:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.ticket.repository.TicketEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:45:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:45:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:45:16 - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.airline.infrastructure.persistence.train.repository.TrainScheduleStopEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-08 20:45:16 - Finished Spring Data repository scanning in 23 ms. Found 0 Redis repository interfaces.
2025-01-08 20:45:17 - Tomcat initialized with port 8080 (http)
2025-01-08 20:45:17 - Initializing ProtocolHandler ["http-nio-8080"]
2025-01-08 20:45:17 - Starting service [Tomcat]
2025-01-08 20:45:17 - Starting Servlet engine: [Apache Tomcat/10.1.33]
2025-01-08 20:45:17 - Initializing Spring embedded WebApplicationContext
2025-01-08 20:45:17 - Root WebApplicationContext: initialization completed in 1543 ms
2025-01-08 20:45:17 - HikariPool-1 - Starting...
2025-01-08 20:45:19 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@545604a9
2025-01-08 20:45:19 - HikariPool-1 - Start completed.
2025-01-08 20:45:19 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 20:45:19 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 20:45:19 - HHH000026: Second-level cache disabled
2025-01-08 20:45:19 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 20:45:20 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 20:45:20 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 20:45:20 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 20:45:21 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 20:45:21 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 20:45:21 - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-01-08 20:45:21 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.OncePerRequestFilter.doFilter(jakarta.servlet.ServletRequest,jakarta.servlet.ServletResponse,jakarta.servlet.FilterChain) throws jakarta.servlet.ServletException,java.io.IOException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 20:45:21 - Unable to proxy interface-implementing method [public final void org.springframework.web.filter.GenericFilterBean.init(jakarta.servlet.FilterConfig) throws jakarta.servlet.ServletException] because it is marked as final, consider using interface-based JDK proxies instead.
2025-01-08 20:45:21 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 20:45:21 - Filter 'authenticationFilter' configured for use
2025-01-08 20:45:22 - Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
2025-01-08 20:45:22 - Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
2025-01-08 20:45:22 - One of the patterns in [**] is missing a leading slash. This is discouraged; please include the leading slash in all your request matcher patterns. In future versions of Spring Security, leaving out the leading slash will result in an exception.
2025-01-08 20:45:22 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, LogoutFilter, AuthenticationFilter$$SpringCGLIB$$0, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 20:45:23 - Starting ProtocolHandler ["http-nio-8080"]
2025-01-08 20:45:23 - Tomcat started on port 8080 (http) with context path '/'
2025-01-08 20:45:23 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-email-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = email-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 20:45:23 - initializing Kafka metrics collector
2025-01-08 20:45:23 - Kafka version: 3.9.0
2025-01-08 20:45:23 - Kafka commitId: 84caaa6e9da06435
2025-01-08 20:45:23 - Kafka startTimeMs: 1736343923289
2025-01-08 20:45:23 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Subscribed to topic(s): email-topic
2025-01-08 20:45:23 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [dqhdev.io.vn:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ticket-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ticket
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-08 20:45:23 - initializing Kafka metrics collector
2025-01-08 20:45:23 - Kafka version: 3.9.0
2025-01-08 20:45:23 - Kafka commitId: 84caaa6e9da06435
2025-01-08 20:45:23 - Kafka startTimeMs: 1736343923307
2025-01-08 20:45:23 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Subscribed to topic(s): ticket-cancel
2025-01-08 20:45:23 - Started airlineServerApplication in 7.934 seconds (process running for 8.38)
2025-01-08 20:45:23 - airlineServerApplication started
2025-01-08 20:45:24 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 20:45:24 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 20:45:24 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 20:45:24 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Cluster ID: Frg36A0TTZaxTQ_nXW5xEA
2025-01-08 20:45:24 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Discovered group coordinator 147.93.29.117:9092 (id: 2147483646 rack: null)
2025-01-08 20:45:24 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 20:45:24 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: need to re-join with the given member-id: consumer-email-group-1-a7d5efe8-e0c3-4e3e-bed4-d558431ffe4b
2025-01-08 20:45:24 - [Consumer clientId=consumer-email-group-1, groupId=email-group] (Re-)joining group
2025-01-08 20:45:24 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: need to re-join with the given member-id: consumer-ticket-2-d696db0e-4e02-4a7a-a743-33c6defc0b17
2025-01-08 20:45:24 - [Consumer clientId=consumer-ticket-2, groupId=ticket] (Re-)joining group
2025-01-08 20:45:26 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully joined group with generation Generation{generationId=159, memberId='consumer-email-group-1-a7d5efe8-e0c3-4e3e-bed4-d558431ffe4b', protocol='range'}
2025-01-08 20:45:26 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Successfully synced group in generation Generation{generationId=159, memberId='consumer-email-group-1-a7d5efe8-e0c3-4e3e-bed4-d558431ffe4b', protocol='range'}
2025-01-08 20:45:26 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Notifying assignor about the new Assignment(partitions=[])
2025-01-08 20:45:26 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Adding newly assigned partitions: 
2025-01-08 20:45:26 - email-group: partitions assigned: []
2025-01-08 20:45:27 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully joined group with generation Generation{generationId=31, memberId='consumer-ticket-2-d696db0e-4e02-4a7a-a743-33c6defc0b17', protocol='range'}
2025-01-08 20:45:27 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Finished assignment for group at generation 31: {consumer-ticket-2-d696db0e-4e02-4a7a-a743-33c6defc0b17=Assignment(partitions=[ticket-cancel-0])}
2025-01-08 20:45:28 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Successfully synced group in generation Generation{generationId=31, memberId='consumer-ticket-2-d696db0e-4e02-4a7a-a743-33c6defc0b17', protocol='range'}
2025-01-08 20:45:28 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Notifying assignor about the new Assignment(partitions=[ticket-cancel-0])
2025-01-08 20:45:28 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Adding newly assigned partitions: ticket-cancel-0
2025-01-08 20:45:28 - Setting offset for partition ticket-cancel-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[147.93.29.117:9092 (id: 1 rack: null)], epoch=0}}
2025-01-08 20:45:28 - ticket: partitions assigned: [ticket-cancel-0]
2025-01-08 20:45:42 - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-01-08 20:45:42 - Initializing Servlet 'dispatcherServlet'
2025-01-08 20:45:42 - Completed initialization in 1 ms
2025-01-08 20:45:42 - Securing POST /api/account/register
2025-01-08 20:45:42 - Secured POST /api/account/register
2025-01-08 20:45:43 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 20:46:14 - Securing POST /api/account/register
2025-01-08 20:46:14 - Secured POST /api/account/register
2025-01-08 20:46:17 - Set SecurityContextHolder to anonymous SecurityContext
2025-01-08 20:46:27 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Member consumer-email-group-1-a7d5efe8-e0c3-4e3e-bed4-d558431ffe4b sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 20:46:27 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Revoke previously assigned partitions ticket-cancel-0
2025-01-08 20:46:27 - ticket: partitions revoked: [ticket-cancel-0]
2025-01-08 20:46:27 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 20:46:27 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 20:46:27 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 20:46:27 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Member consumer-ticket-2-d696db0e-4e02-4a7a-a743-33c6defc0b17 sending LeaveGroup request to coordinator 147.93.29.117:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-01-08 20:46:27 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 20:46:27 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 20:46:27 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Unsubscribed all topics or patterns and assigned partitions
2025-01-08 20:46:27 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 20:46:27 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-08 20:46:27 - [Consumer clientId=consumer-ticket-2, groupId=ticket] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 20:46:27 - [Consumer clientId=consumer-email-group-1, groupId=email-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-08 21:35:50 - 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/Users/Hi%20Windows%2011%20Home/.gradle/caches/modules-2/files-2.1/org.json/json/20230227/7a0d4aca76513d8ce81f9b044ce8126b84809ad8/json-20230227.jar!/org/json/JSONObject.class
	jar:file:/C:/Users/Hi%20Windows%2011%20Home/.gradle/caches/modules-2/files-2.1/com.vaadin.external.google/android-json/0.0.20131108.vaadin1/fa26d351fe62a6a17f5cda1287c1c6110dec413f/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2025-01-08 21:35:50 - Starting AirLineServerApplicationTests using Java 23.0.1 with PID 18232 (started by Hi Windows 11 Home in F:\project personal\TravelokaServer)
2025-01-08 21:35:50 - No active profile set, falling back to 1 default profile: "default"
2025-01-08 21:35:51 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 21:35:51 - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-08 21:35:51 - Finished Spring Data repository scanning in 9 ms. Found 0 JPA repository interfaces.
2025-01-08 21:35:51 - Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-08 21:35:51 - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-08 21:35:51 - Finished Spring Data repository scanning in 0 ms. Found 0 Redis repository interfaces.
2025-01-08 21:35:51 - HikariPool-1 - Starting...
2025-01-08 21:35:55 - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@1a01ffff
2025-01-08 21:35:55 - HikariPool-1 - Start completed.
2025-01-08 21:35:55 - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-08 21:35:55 - HHH000412: Hibernate ORM core version 6.6.2.Final
2025-01-08 21:35:55 - HHH000026: Second-level cache disabled
2025-01-08 21:35:55 - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-08 21:35:55 - HHH90000025: MySQL8Dialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-01-08 21:35:55 - HHH90000026: MySQL8Dialect has been deprecated; use org.hibernate.dialect.MySQLDialect instead
2025-01-08 21:35:55 - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 8.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-01-08 21:35:55 - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-01-08 21:35:55 - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 21:35:56 - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-01-08 21:35:56 - 

Using generated security password: 2983bf10-dd49-403d-af9c-8b4cce125158

This generated password is for development use only. Your security configuration must be updated before running your application in production.

2025-01-08 21:35:56 - Global AuthenticationManager configured with UserDetailsService bean with name inMemoryUserDetailsManager
2025-01-08 21:35:57 - Will secure any request with filters: DisableEncodeUrlFilter, WebAsyncManagerIntegrationFilter, SecurityContextHolderFilter, HeaderWriterFilter, CsrfFilter, LogoutFilter, UsernamePasswordAuthenticationFilter, DefaultResourcesFilter, DefaultLoginPageGeneratingFilter, DefaultLogoutPageGeneratingFilter, BasicAuthenticationFilter, RequestCacheAwareFilter, SecurityContextHolderAwareRequestFilter, AnonymousAuthenticationFilter, ExceptionTranslationFilter, AuthorizationFilter
2025-01-08 21:35:57 - Started AirLineServerApplicationTests in 6.434 seconds (process running for 7.378)
2025-01-08 21:35:57 - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-01-08 21:35:57 - HikariPool-1 - Shutdown initiated...
2025-01-08 21:35:59 - HikariPool-1 - Shutdown completed.
